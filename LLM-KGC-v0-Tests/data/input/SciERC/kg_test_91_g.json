{
  "iri": "Paper-91",
  "title": "ECCV_2016_110_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-91-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-91-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-91-Section-1-Paragraph-1-Sentence-1",
              "text": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets ."
            },
            {
              "iri": "Paper-91-Section-1-Paragraph-1-Sentence-2",
              "text": "Unfortunately , creating large datasets with pixel-level labels has been extremely costly due to the amount of human effort required ."
            },
            {
              "iri": "Paper-91-Section-1-Paragraph-1-Sentence-3",
              "text": "In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0007538795471191406,
    40.192431688308716,
    47.003779888153076,
    44.84923005104065,
    0.018288850784301758,
    0.00011920928955078125,
    0.0001399517059326172,
    128.58871984481812,
    122.87971305847168,
    2.407273769378662,
    33.40644693374634,
    0.007628202438354492,
    0.00013518333435058594,
    44.49370861053467,
    0.0014688968658447266,
    0.016670942306518555,
    0.0015108585357666016,
    3.3553121089935303,
    0.0015938282012939453,
    0.0003190040588378906,
    304.017817735672,
    5.219995975494385,
    85.1940758228302,
    1.717829942703247,
    0.0003120899200439453,
    0.0050580501556396484
  ],
  "nodes": {
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "this paper",
      "aliases": [
        "this paper"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This paper presents a novel approach for rapidly generating pixel-accurate semantic label maps from images sourced from modern computer games, addressing the challenges of creating large datasets with pixel-level annotations in computer vision.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "this paper",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        }
      ],
      "relevance": 0.88232421875
    },
    "Entity-creating_large_datasets_with_pixel-level_label": {
      "node_id": "creating_large_datasets_with_pixel-level_label",
      "disambiguation_index": 0,
      "label": "creating large datasets with pixel-level labels",
      "aliases": [
        "creating large datasets with pixel-level labels"
      ],
      "types": [
        "process",
        "dataset"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Creating large datasets with pixel-level labels refers to the process of generating extensive collections of images annotated with detailed semantic labels at the pixel level, which is essential for training high-capacity models in computer vision but is often hindered by the significant human effort and cost involved.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-2",
          "local_name": "creating large datasets with pixel-level labels",
          "local_types": [
            "process",
            "dataset"
          ],
          "iri": "Entity-creating_large_datasets_with_pixel-level_label-Mention-1"
        }
      ],
      "relevance": 0.79150390625
    },
    "Entity-image": {
      "node_id": "image",
      "disambiguation_index": 0,
      "label": "images",
      "aliases": [
        "images",
        "images extracted from modern computer games"
      ],
      "types": [
        "visual data",
        "computer game",
        "image",
        "images",
        "visual content",
        "computer games",
        "media"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'images' refers to visual data obtained from modern computer games, which are used to create pixel-accurate semantic label maps in the context of computer vision research.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "images",
          "local_types": [
            "media",
            "visual data",
            "visual content"
          ],
          "iri": "Entity-image-Mention-1"
        },
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "images extracted from modern computer games",
          "local_types": [
            "image",
            "images",
            "computer games",
            "computer game"
          ],
          "iri": "Entity-image-Mention-2"
        }
      ],
      "relevance": 0.78515625
    },
    "Entity-approach": {
      "node_id": "approach",
      "disambiguation_index": 0,
      "label": "approach",
      "aliases": [
        "approach",
        "an approach to rapidly creating pixel-accurate semantic label maps"
      ],
      "types": [
        "approach",
        "technique",
        "method"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'approach' refers to a method for quickly generating pixel-accurate semantic label maps from images sourced from modern computer games.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "approach",
          "local_types": [
            "method",
            "technique"
          ],
          "iri": "Entity-approach-Mention-1"
        },
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "an approach to rapidly creating pixel-accurate semantic label maps",
          "local_types": [
            "method",
            "approach"
          ],
          "iri": "Entity-approach-Mention-2"
        }
      ],
      "relevance": 0.765625
    },
    "Entity-pixel-accurate_semantic_label_map": {
      "node_id": "pixel-accurate_semantic_label_map",
      "disambiguation_index": 0,
      "label": "pixel-accurate semantic label maps",
      "aliases": [
        "pixel-accurate semantic label maps"
      ],
      "types": [
        "labeling",
        "data representation",
        "label",
        "image processing",
        "map"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pixel-accurate semantic label maps are detailed representations of images where each pixel is assigned a specific semantic category, enabling precise identification and classification of objects within the visual data.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "pixel-accurate semantic label maps",
          "local_types": [
            "labeling",
            "data representation",
            "label",
            "image processing",
            "map"
          ],
          "iri": "Entity-pixel-accurate_semantic_label_map-Mention-1"
        }
      ],
      "relevance": 0.73974609375
    },
    "Entity-recent_progress_in_computer_vision": {
      "node_id": "recent_progress_in_computer_vision",
      "disambiguation_index": 0,
      "label": "Recent progress in computer vision",
      "aliases": [
        "Recent progress in computer vision"
      ],
      "types": [
        "progress",
        "field"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Recent progress in computer vision refers to advancements in the field characterized by the development of high-capacity models that utilize large datasets for training, enabling improved performance in tasks such as image analysis and semantic labeling.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Recent progress in computer vision",
          "local_types": [
            "progress",
            "field"
          ],
          "iri": "Entity-recent_progress_in_computer_vision-Mention-1"
        }
      ],
      "relevance": 0.7138671875
    },
    "Entity-pixel-level_label": {
      "node_id": "pixel-level_label",
      "disambiguation_index": 0,
      "label": "pixel-level labels",
      "aliases": [
        "pixel-level labels"
      ],
      "types": [
        "label",
        "data annotation",
        "annotation",
        "labeling"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pixel-level labels are detailed annotations that assign a specific label to each individual pixel in an image, commonly used in image segmentation tasks to identify and classify different regions within the image.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-2",
          "local_name": "pixel-level labels",
          "local_types": [
            "label",
            "data annotation",
            "annotation",
            "labeling"
          ],
          "iri": "Entity-pixel-level_label-Mention-1"
        }
      ],
      "relevance": 0.67041015625
    },
    "Entity-human_effort": {
      "node_id": "human_effort",
      "disambiguation_index": 0,
      "label": "human effort",
      "aliases": [
        "human effort"
      ],
      "types": [
        "effort",
        "resource",
        "labor"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Human effort refers to the labor and resources expended by individuals to create large datasets with pixel-level labels, which is a costly process in the context of training high-capacity models in computer vision.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-2",
          "local_name": "human effort",
          "local_types": [
            "effort",
            "resource",
            "labor"
          ],
          "iri": "Entity-human_effort-Mention-1"
        }
      ],
      "relevance": 0.6552734375
    },
    "Entity-modern_computer_game": {
      "node_id": "modern_computer_game",
      "disambiguation_index": 0,
      "label": "modern computer games",
      "aliases": [
        "modern computer games"
      ],
      "types": [
        "video game",
        "entertainment software",
        "interactive media"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Modern computer games are interactive digital entertainment software designed for play on various platforms, characterized by their use of graphics, sound, and gameplay mechanics.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "modern computer games",
          "local_types": [
            "video game",
            "entertainment software",
            "interactive media"
          ],
          "iri": "Entity-modern_computer_game-Mention-1"
        }
      ],
      "relevance": 0.5849609375
    },
    "Entity-high-capacity_model": {
      "node_id": "high-capacity_model",
      "disambiguation_index": 0,
      "label": "high-capacity models",
      "aliases": [
        "high-capacity models"
      ],
      "types": [
        "artificial intelligence",
        "model",
        "machine learning model",
        "machine learning"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "High-capacity models are advanced machine learning architectures designed to handle complex tasks by leveraging large amounts of data and computational resources.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-1",
          "local_name": "high-capacity models",
          "local_types": [
            "artificial intelligence",
            "model",
            "machine learning model",
            "machine learning"
          ],
          "iri": "Entity-high-capacity_model-Mention-1"
        }
      ],
      "relevance": 0.560546875
    },
    "Entity-computer_vision": {
      "node_id": "computer_vision",
      "disambiguation_index": 0,
      "label": "computer vision",
      "aliases": [
        "computer vision"
      ],
      "types": [
        "field of study",
        "computer science",
        "technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Computer vision is a field of study within computer science that focuses on enabling machines to interpret and understand visual information from the world.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-1",
          "local_name": "computer vision",
          "local_types": [
            "field of study",
            "computer science",
            "technology"
          ],
          "iri": "Entity-computer_vision-Mention-1"
        }
      ],
      "relevance": 0.5546875
    },
    "Entity-large_datasets": {
      "node_id": "large_datasets",
      "disambiguation_index": 0,
      "label": "large datasets",
      "aliases": [
        "large datasets"
      ],
      "types": [
        "data",
        "dataset"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Large datasets refer to extensive collections of data that are used for analysis, training machine learning models, and conducting research across various fields.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-1",
          "local_name": "large datasets",
          "local_types": [
            "data",
            "dataset"
          ],
          "iri": "Entity-large_datasets-Mention-1"
        },
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-2",
          "local_name": "large datasets",
          "local_types": [
            "data",
            "dataset"
          ],
          "iri": "Entity-large_datasets-Mention-2"
        }
      ],
      "relevance": 0.55224609375
    },
    "Entity-computer_game": {
      "node_id": "computer_game",
      "disambiguation_index": 0,
      "label": "computer games",
      "aliases": [
        "computer games"
      ],
      "types": [
        "industry",
        "entertainment"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Computer games are interactive digital entertainment software designed for play on computers and gaming consoles, often involving graphics, sound, and user input.",
      "mentions": [
        {
          "reference": "Paper-91-Section-1-Paragraph-1-Sentence-3",
          "local_name": "computer games",
          "local_types": [
            "industry",
            "entertainment"
          ],
          "iri": "Entity-computer_game-Mention-1"
        }
      ],
      "relevance": 0.5380859375
    }
  },
  "summary": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets . Unfortunately , creating large datasets with pixel-level labels has been extremely costly due to the amount of human effort required . In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games .",
  "triples": [
    [
      "Entity-recent_progress_in_computer_vision",
      "Predicate-has_been_driven_by",
      "Entity-high-capacity_model"
    ],
    [
      "Entity-high-capacity_model",
      "Predicate-trained_on",
      "Entity-large_datasets"
    ],
    [
      "Entity-creating_large_datasets_with_pixel-level_label",
      "Predicate-requires",
      "Entity-human_effort"
    ],
    [
      "Entity-creating_large_datasets_with_pixel-level_label",
      "Predicate-is_costly_due_to",
      "Entity-human_effort"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-approach"
    ],
    [
      "Entity-approach",
      "Predicate-creates",
      "Entity-pixel-accurate_semantic_label_map"
    ],
    [
      "Entity-image",
      "Predicate-are_created_from",
      "Entity-modern_computer_game"
    ],
    [
      "Entity-approach",
      "Predicate-is_for",
      "Entity-image"
    ],
    [
      "Entity-image",
      "Predicate-are",
      "Entity-pixel-accurate_semantic_label_map"
    ]
  ],
  "triples_typing": [
    [
      "Entity-image",
      "skos:broader",
      "Entity-computer_game"
    ]
  ],
  "predicates": {
    "Predicate-has_been_driven_by": {
      "label": "has been driven by",
      "description": "The predicate 'has been driven by' indicates a causal or motivating relationship between the subject and the object, suggesting that the subject's development, progress, or state is significantly influenced or propelled by the object. It implies that the object serves as a key factor or force that contributes to the changes or advancements represented by the subject.",
      "disambiguation_index": 0
    },
    "Predicate-trained_on": {
      "label": "trained on",
      "description": "The predicate 'trained on' indicates a relationship where the subject, typically a model or system, undergoes a learning process using the data represented by the object. This implies that the subject utilizes the information, patterns, or examples contained in the object to improve its performance, capabilities, or understanding in a specific domain.",
      "disambiguation_index": 0
    },
    "Predicate-requires": {
      "label": "requires",
      "description": "The predicate 'requires' establishes a relationship between a subject and an object, indicating that the subject cannot be accomplished or completed without the presence or contribution of the object. It signifies a dependency where the subject necessitates the object as a fundamental component or resource for its execution or realization.",
      "disambiguation_index": 0
    },
    "Predicate-is_costly_due_to": {
      "label": "is costly due to",
      "description": "The predicate 'is costly due to' establishes a relationship between a subject and an object by indicating that the subject incurs significant expenses or resources as a direct result of the factors or conditions represented by the object. It highlights the causal link where the object explains the reasons behind the high costs associated with the subject.",
      "disambiguation_index": 0
    },
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates that the subject is introducing, showcasing, or delivering information, ideas, or findings related to the object. It establishes a relationship where the subject serves as a medium through which the object is communicated or made known to an audience.",
      "disambiguation_index": 0
    },
    "Predicate-creates": {
      "label": "creates",
      "description": "The predicate 'creates' indicates an action performed by the subject that results in the formation or generation of the object. It implies a transformative process where the subject actively produces or brings into existence the object, which can be a tangible or intangible entity.",
      "disambiguation_index": 0
    },
    "Predicate-are_created_from": {
      "label": "are created from",
      "description": "The predicate 'are created from' indicates a relationship where the subject is produced or generated as a result of the materials, concepts, or elements represented by the object. It implies a process of transformation or derivation, where the subject emerges as a new entity that is fundamentally linked to the object, which serves as the source or foundation for its creation.",
      "disambiguation_index": 0
    },
    "Predicate-is_for": {
      "label": "is for",
      "description": "The predicate 'is for' establishes a relationship of purpose or intended use between the subject and the object. It indicates that the subject serves a specific function or is designed to achieve a particular outcome related to the object.",
      "disambiguation_index": 0
    },
    "Predicate-are": {
      "label": "are",
      "description": "The predicate 'are' serves as a linking verb that connects the subject to the object, indicating that the subject possesses a certain quality, characteristic, or identity represented by the object. It establishes an equivalence or relationship between the two, suggesting that the subject can be defined or described in terms of the object.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' establishes a hierarchical relationship between the subject and the object, indicating that the subject is a more specific instance or category that falls under the wider category represented by the object. This relationship implies that the object encompasses a larger scope or set of concepts that includes the subject, thereby providing a context in which the subject can be understood as part of a broader classification.",
      "disambiguation_index": 0
    }
  }
}