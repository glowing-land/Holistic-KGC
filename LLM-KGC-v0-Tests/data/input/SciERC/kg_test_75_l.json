{
  "iri": "Paper-75",
  "title": "ECCV_2016_204_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-75-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-75-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-1",
              "text": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks ."
            },
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-2",
              "text": "Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification ."
            },
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-3",
              "text": "We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB- ."
            },
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-4",
              "text": "We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem ."
            },
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-5",
              "text": "We also derive an efficient non-linear extension of WARCA by using the kernel trick ."
            },
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-6",
              "text": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features ."
            },
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-7",
              "text": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently ."
            },
            {
              "iri": "Paper-75-Section-1-Paragraph-1-Sentence-8",
              "text": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0008032321929931641,
    22.330540418624878,
    30.269797325134277,
    27.141910076141357,
    0.037520408630371094,
    0.00010919570922851562,
    0.0001480579376220703,
    51.78401160240173,
    72.80712819099426,
    1.2592391967773438,
    78.57604050636292,
    0.014197349548339844,
    0.00022649765014648438,
    41.79811906814575,
    25.522794485092163,
    0.022318601608276367,
    1.1218883991241455,
    3.3100013732910156,
    7.252747297286987,
    8.178621768951416,
    41.92085409164429,
    1.9131996631622314,
    16.03496813774109,
    0.8444204330444336,
    0.0005490779876708984,
    0.013923406600952148
  ],
  "nodes": {
    "Entity-weighted_approximate_rank_component_analysis": {
      "node_id": "weighted_approximate_rank_component_analysis",
      "disambiguation_index": 0,
      "label": "Weighted Approximate Rank Component Analysis",
      "aliases": [
        "Weighted Approximate Rank Component Analysis",
        "Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-"
      ],
      "types": [
        "algorithm",
        "metric learning formulation"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "A novel metric learning formulation that minimizes a weighted rank loss to learn a Mahalanobis distance.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-3",
          "local_name": "Weighted Approximate Rank Component Analysis",
          "local_types": [
            "algorithm",
            "metric learning formulation"
          ],
          "iri": "Entity-weighted_approximate_rank_component_analysis-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-3",
          "local_name": "Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-",
          "local_types": [
            "algorithm",
            "metric learning formulation"
          ],
          "iri": "Entity-weighted_approximate_rank_component_analysis-Mention-2"
        }
      ],
      "relevance": 0.78515625
    },
    "Entity-our_goal": {
      "node_id": "our_goal",
      "disambiguation_index": 0,
      "label": "Our goal",
      "aliases": [
        "Our goal"
      ],
      "types": [
        "goal"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "To develop and optimize a metric learning formulation for computing a Mahalanobis distance that minimizes a loss function based on the weighted sum of precision at different ranks.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Our goal",
          "local_types": [
            "goal"
          ],
          "iri": "Entity-our_goal-Mention-1"
        }
      ],
      "relevance": 0.7294921875
    },
    "Entity-the_resulting_learning_problem": {
      "node_id": "the_resulting_learning_problem",
      "disambiguation_index": 0,
      "label": "the resulting learning problem",
      "aliases": [
        "the resulting learning problem"
      ],
      "types": [
        "problem",
        "learning task"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The process or task of developing an efficient and scalable optimization method to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of precision at different ranks.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "the resulting learning problem",
          "local_types": [
            "problem",
            "learning task"
          ],
          "iri": "Entity-the_resulting_learning_problem-Mention-1"
        }
      ],
      "relevance": 0.7177734375
    },
    "Entity-an_efficient_non-linear_extension_of_warca": {
      "node_id": "an_efficient_non-linear_extension_of_warca",
      "disambiguation_index": 0,
      "label": "an efficient non-linear extension of WARCA",
      "aliases": [
        "an efficient non-linear extension of WARCA"
      ],
      "types": [
        "algorithm",
        "WARCA_extension"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A novel algorithmic approach that extends Weighted Approximate Rank Component Analysis (WARCA) to incorporate non-linear transformations through the use of the kernel trick, enabling more effective metric learning and distance computation.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-5",
          "local_name": "an efficient non-linear extension of WARCA",
          "local_types": [
            "algorithm",
            "WARCA_extension"
          ],
          "iri": "Entity-an_efficient_non-linear_extension_of_warca-Mention-1"
        }
      ],
      "relevance": 0.70947265625
    },
    "Entity-warca": {
      "node_id": "warca",
      "disambiguation_index": 0,
      "label": "WARCA",
      "aliases": [
        "WARCA"
      ],
      "types": [
        "acronym",
        "method",
        "algorithm",
        "model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Weighted Approximate Rank Component Analysis, a novel metric learning formulation",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-3",
          "local_name": "WARCA",
          "local_types": [
            "algorithm",
            "acronym"
          ],
          "iri": "Entity-warca-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-5",
          "local_name": "WARCA",
          "local_types": [
            "method",
            "model",
            "algorithm"
          ],
          "iri": "Entity-warca-Mention-2"
        }
      ],
      "relevance": 0.69677734375
    },
    "Entity-loss_defined_on_the_weighted_sum_of_the_precision_at_different_rank": {
      "node_id": "loss_defined_on_the_weighted_sum_of_the_precision_at_different_rank",
      "disambiguation_index": 0,
      "label": "loss defined on the weighted sum of the precision at different ranks",
      "aliases": [
        "by minimizing a loss defined on the weighted sum of the precision at different ranks",
        "loss defined on the weighted sum of the precision at different ranks"
      ],
      "types": [
        "loss function",
        "algorithm"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A metric learning formulation that minimizes a loss function based on the weighted sum of precision at different ranks.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-1",
          "local_name": "loss defined on the weighted sum of the precision at different ranks",
          "local_types": [
            "loss function"
          ],
          "iri": "Entity-loss_defined_on_the_weighted_sum_of_the_precision_at_different_rank-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-1",
          "local_name": "by minimizing a loss defined on the weighted sum of the precision at different ranks",
          "local_types": [
            "algorithm",
            "loss function"
          ],
          "iri": "Entity-loss_defined_on_the_weighted_sum_of_the_precision_at_different_rank-Mention-2"
        }
      ],
      "relevance": 0.6201171875
    },
    "Entity-mahalanobis_distance": {
      "node_id": "mahalanobis_distance",
      "disambiguation_index": 0,
      "label": "Mahalanobis distance",
      "aliases": [
        "Mahalanobis distance",
        "a Mahalanobis distance"
      ],
      "types": [
        "distance",
        "distance metric",
        "Mahalanobis",
        "mathematical concept",
        "metric"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A statistical measure used in multivariate analysis, particularly in machine learning and data mining, to quantify the distance between two probability distributions.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-1",
          "local_name": "Mahalanobis distance",
          "local_types": [
            "mathematical concept",
            "metric",
            "distance metric"
          ],
          "iri": "Entity-mahalanobis_distance-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a Mahalanobis distance",
          "local_types": [
            "distance",
            "Mahalanobis"
          ],
          "iri": "Entity-mahalanobis_distance-Mention-2"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-low-rank_matrix_optimization": {
      "node_id": "low-rank_matrix_optimization",
      "disambiguation_index": 0,
      "label": "low-rank matrix optimization",
      "aliases": [
        "low-rank matrix optimization"
      ],
      "types": [
        "research area",
        "mathematical problem"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of optimizing a matrix to achieve a low rank, often involving mathematical techniques and algorithms.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "low-rank matrix optimization",
          "local_types": [
            "research area",
            "mathematical problem"
          ],
          "iri": "Entity-low-rank_matrix_optimization-Mention-1"
        }
      ],
      "relevance": 0.59326171875
    },
    "Entity-minimizing_a_weighted_rank_loss": {
      "node_id": "minimizing_a_weighted_rank_loss",
      "disambiguation_index": 0,
      "label": "minimizing a weighted rank loss",
      "aliases": [
        "minimizing a weighted rank loss"
      ],
      "types": [
        "criterion"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical optimization objective used to evaluate and compare the performance of different models or algorithms.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-2",
          "local_name": "minimizing a weighted rank loss",
          "local_types": [
            "criterion"
          ],
          "iri": "Entity-minimizing_a_weighted_rank_loss-Mention-1"
        }
      ],
      "relevance": 0.5927734375
    },
    "Entity-we_validate_this_new_method": {
      "node_id": "we_validate_this_new_method",
      "disambiguation_index": 0,
      "label": "We validate this new method",
      "aliases": [
        "We validate this new method"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The validation process for a novel metric learning formulation, specifically evaluating its performance on nine standard person re-identification datasets.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "We validate this new method",
          "local_types": [
            "research"
          ],
          "iri": "Entity-we_validate_this_new_method-Mention-1"
        }
      ],
      "relevance": 0.591796875
    },
    "Entity-matrix_rank_degeneration__non-isolated_minimum_in_the_low-rank_matrix_optimization": {
      "node_id": "matrix_rank_degeneration__non-isolated_minimum_in_the_low-rank_matrix_optimization",
      "disambiguation_index": 0,
      "label": "matrix rank degeneration & non-isolated minima in the low-rank matrix optimization",
      "aliases": [
        "We also address",
        "matrix rank degeneration & non-isolated minima in the low-rank matrix optimization",
        "a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization"
      ],
      "types": [
        "problem",
        "problem domain",
        "research",
        "optimization"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A problem of optimizing low-rank matrices while avoiding issues with matrix rank degeneration and non-isolated local minima.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "matrix rank degeneration & non-isolated minima in the low-rank matrix optimization",
          "local_types": [
            "problem",
            "problem domain"
          ],
          "iri": "Entity-matrix_rank_degeneration__non-isolated_minimum_in_the_low-rank_matrix_optimization-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "We also address",
          "local_types": [
            "research"
          ],
          "iri": "Entity-matrix_rank_degeneration__non-isolated_minimum_in_the_low-rank_matrix_optimization-Mention-2"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization",
          "local_types": [
            "problem",
            "optimization"
          ],
          "iri": "Entity-matrix_rank_degeneration__non-isolated_minimum_in_the_low-rank_matrix_optimization-Mention-3"
        }
      ],
      "relevance": 0.58544921875
    },
    "Entity-kernel_trick": {
      "node_id": "kernel_trick",
      "disambiguation_index": 0,
      "label": "kernel trick",
      "aliases": [
        "kernel trick",
        "the kernel trick"
      ],
      "types": [
        "technique",
        "mathematical technique",
        "mathematical concept",
        "method",
        "kernel_trick"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical method that transforms data into a higher-dimensional space to enable linear separability and facilitate machine learning algorithms.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-5",
          "local_name": "kernel trick",
          "local_types": [
            "mathematical concept",
            "technique",
            "mathematical technique",
            "method"
          ],
          "iri": "Entity-kernel_trick-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-5",
          "local_name": "the kernel trick",
          "local_types": [
            "technique",
            "kernel_trick"
          ],
          "iri": "Entity-kernel_trick-Mention-2"
        }
      ],
      "relevance": 0.576171875
    },
    "Entity-scalable_stochastic_gradient_descent": {
      "node_id": "scalable_stochastic_gradient_descent",
      "disambiguation_index": 0,
      "label": "scalable stochastic gradient descent",
      "aliases": [
        "a scalable stochastic gradient descent algorithm",
        "scalable stochastic gradient descent algorithm",
        "scalable stochastic gradient descent"
      ],
      "types": [
        "method",
        "algorithm",
        "optimization method",
        "machine learning technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A machine learning algorithm that uses stochastic gradient descent and can be scaled up to handle large datasets.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "scalable stochastic gradient descent",
          "local_types": [
            "algorithm",
            "machine learning technique"
          ],
          "iri": "Entity-scalable_stochastic_gradient_descent-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "scalable stochastic gradient descent algorithm",
          "local_types": [
            "optimization method"
          ],
          "iri": "Entity-scalable_stochastic_gradient_descent-Mention-2"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "a scalable stochastic gradient descent algorithm",
          "local_types": [
            "algorithm",
            "method"
          ],
          "iri": "Entity-scalable_stochastic_gradient_descent-Mention-3"
        }
      ],
      "relevance": 0.57080078125
    },
    "Entity-person_re-identification": {
      "node_id": "person_re-identification",
      "disambiguation_index": 0,
      "label": "person re-identification",
      "aliases": [
        "person re-identification",
        "many problems in computer vision such as person re-identification"
      ],
      "types": [
        "problem",
        "problem domain",
        "problem in computer vision",
        "computer vision application",
        "task",
        "problem in computer science",
        "re-identification",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of identifying and matching individuals across non-overlapping camera views or images.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-2",
          "local_name": "person re-identification",
          "local_types": [
            "problem",
            "problem domain",
            "problem in computer vision",
            "computer vision application",
            "task",
            "problem in computer science"
          ],
          "iri": "Entity-person_re-identification-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-2",
          "local_name": "many problems in computer vision such as person re-identification",
          "local_types": [
            "problem",
            "computer vision",
            "re-identification"
          ],
          "iri": "Entity-person_re-identification-Mention-2"
        }
      ],
      "relevance": 0.568359375
    },
    "Entity-kernel_space_embedding": {
      "node_id": "kernel_space_embedding",
      "disambiguation_index": 0,
      "label": "Kernel space embedding",
      "aliases": [
        "Kernel space embedding"
      ],
      "types": [
        "technique",
        "concept",
        "method",
        "algorithm"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A technique or method that maps high-dimensional data into a lower-dimensional space, enabling efficient processing and analysis.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-6",
          "local_name": "Kernel space embedding",
          "local_types": [
            "technique",
            "concept",
            "method",
            "algorithm"
          ],
          "iri": "Entity-kernel_space_embedding-Mention-1"
        }
      ],
      "relevance": 0.5556640625
    },
    "Entity-the_or-thonormality_of_the_learned_matrix": {
      "node_id": "the_or-thonormality_of_the_learned_matrix",
      "disambiguation_index": 0,
      "label": "the or-thonormality of the learned matrix",
      "aliases": [
        "the or-thonormality of the learned matrix"
      ],
      "types": [
        "property",
        "matrix property"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A property that ensures the learned matrix has an orthogonal basis and unit length, promoting efficient optimization in low-rank matrix problems.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "the or-thonormality of the learned matrix",
          "local_types": [
            "property",
            "matrix property"
          ],
          "iri": "Entity-the_or-thonormality_of_the_learned_matrix-Mention-1"
        }
      ],
      "relevance": 0.5546875
    },
    "Entity-matrix_rank_degeneration": {
      "node_id": "matrix_rank_degeneration",
      "disambiguation_index": 0,
      "label": "matrix rank degeneration",
      "aliases": [
        "matrix rank degeneration"
      ],
      "types": [
        "problem in linear algebra"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A phenomenon where a matrix's rank decreases, often occurring in linear algebra problems.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "matrix rank degeneration",
          "local_types": [
            "problem in linear algebra"
          ],
          "iri": "Entity-matrix_rank_degeneration-Mention-1"
        }
      ],
      "relevance": 0.5478515625
    },
    "Entity-the_training_and_prediction_cost_from_the_data_dimension": {
      "node_id": "the_training_and_prediction_cost_from_the_data_dimension",
      "disambiguation_index": 0,
      "label": "the training and prediction costs from the data dimension",
      "aliases": [
        "the training and prediction costs from the data dimension"
      ],
      "types": [
        "costs"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The costs associated with training a model using kernel space embedding, as well as making predictions based on that trained model.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-6",
          "local_name": "the training and prediction costs from the data dimension",
          "local_types": [
            "costs"
          ],
          "iri": "Entity-the_training_and_prediction_cost_from_the_data_dimension-Mention-1"
        }
      ],
      "relevance": 0.54736328125
    },
    "Entity-market-1501": {
      "node_id": "market-1501",
      "disambiguation_index": 0,
      "label": "Market-1501",
      "aliases": [
        "CUHK03",
        "Market-1501",
        "Market-1501 and CUHK03 datasets"
      ],
      "types": [
        "dataset",
        "dataset in computer vision",
        "data collection",
        "computer vision dataset"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A dataset for person re-identification in computer vision, containing images or data related to identifying individuals across different cameras.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "Market-1501",
          "local_types": [
            "dataset",
            "computer vision dataset"
          ],
          "iri": "Entity-market-1501-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "CUHK03",
          "local_types": [
            "dataset",
            "computer vision dataset"
          ],
          "iri": "Entity-market-1501-Mention-2"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "Market-1501 and CUHK03 datasets",
          "local_types": [
            "dataset in computer vision",
            "data collection",
            "dataset"
          ],
          "iri": "Entity-market-1501-Mention-3"
        }
      ],
      "relevance": 0.54296875
    },
    "Entity-stochastic_gradient_descent": {
      "node_id": "stochastic_gradient_descent",
      "disambiguation_index": 0,
      "label": "stochastic gradient descent",
      "aliases": [
        "stochastic gradient descent",
        "stochastic gradient descent algorithm"
      ],
      "types": [
        "algorithm",
        "optimization technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "An optimization technique that uses stochastic methods to iteratively update model parameters in order to minimize or maximize a loss function.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "stochastic gradient descent",
          "local_types": [
            "algorithm",
            "optimization technique"
          ],
          "iri": "Entity-stochastic_gradient_descent-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "stochastic gradient descent algorithm",
          "local_types": [
            "optimization technique"
          ],
          "iri": "Entity-stochastic_gradient_descent-Mention-2"
        }
      ],
      "relevance": 0.5361328125
    },
    "Entity-precision_at_different_rank": {
      "node_id": "precision_at_different_rank",
      "disambiguation_index": 0,
      "label": "precision at different ranks",
      "aliases": [
        "precision at different ranks"
      ],
      "types": [
        "evaluation metric",
        "metric",
        "evaluation measure"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A measure evaluating the accuracy or correctness of retrieved items, calculated for various ranking positions.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-1",
          "local_name": "precision at different ranks",
          "local_types": [
            "evaluation metric",
            "metric",
            "evaluation measure"
          ],
          "iri": "Entity-precision_at_different_rank-Mention-1"
        }
      ],
      "relevance": 0.53271484375
    },
    "Entity-nine_standard_person_re-identification_datasets": {
      "node_id": "nine_standard_person_re-identification_datasets",
      "disambiguation_index": 0,
      "label": "nine standard person re-identification datasets",
      "aliases": [
        "nine standard person re-identification datasets",
        "nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets"
      ],
      "types": [
        "datasets",
        "data collection",
        "dataset",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of standard person re-identification datasets, comprising nine sets of data used for evaluating and comparing algorithms.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "nine standard person re-identification datasets",
          "local_types": [
            "data collection",
            "dataset"
          ],
          "iri": "Entity-nine_standard_person_re-identification_datasets-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets",
          "local_types": [
            "datasets",
            "dataset",
            "data"
          ],
          "iri": "Entity-nine_standard_person_re-identification_datasets-Mention-2"
        }
      ],
      "relevance": 0.5302734375
    },
    "Entity-loss": {
      "node_id": "loss",
      "disambiguation_index": 0,
      "label": "loss",
      "aliases": [
        "loss"
      ],
      "types": [
        "evaluation criterion",
        "performance metric",
        "optimization problem"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A measure or penalty for suboptimal performance or deviation from an ideal outcome.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-1",
          "local_name": "loss",
          "local_types": [
            "evaluation criterion",
            "performance metric",
            "optimization problem"
          ],
          "iri": "Entity-loss-Mention-1"
        }
      ],
      "relevance": 0.52978515625
    },
    "Entity-non-isolated_minimum": {
      "node_id": "non-isolated_minimum",
      "disambiguation_index": 0,
      "label": "non-isolated minima",
      "aliases": [
        "non-isolated minima"
      ],
      "types": [
        "concept in optimization theory"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Local optima in low-rank matrix optimization problems where multiple solutions with similar values exist, requiring specialized regularization techniques for efficient convergence.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "non-isolated minima",
          "local_types": [
            "concept in optimization theory"
          ],
          "iri": "Entity-non-isolated_minimum-Mention-1"
        }
      ],
      "relevance": 0.5283203125
    },
    "Entity-learning_problem": {
      "node_id": "learning_problem",
      "disambiguation_index": 0,
      "label": "learning problem",
      "aliases": [
        "learning problem"
      ],
      "types": [
        "mathematical concept",
        "computational challenge"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A difficulty or obstacle in acquiring knowledge or skill",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "learning problem",
          "local_types": [
            "mathematical concept",
            "computational challenge"
          ],
          "iri": "Entity-learning_problem-Mention-1"
        }
      ],
      "relevance": 0.52783203125
    },
    "Entity-regularizer": {
      "node_id": "regularizer",
      "disambiguation_index": 0,
      "label": "regularizer",
      "aliases": [
        "regularizer"
      ],
      "types": [
        "algorithmic component",
        "optimization technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical technique used to control and modify the behavior of a function, algorithm, or optimization process.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "regularizer",
          "local_types": [
            "algorithmic component",
            "optimization technique"
          ],
          "iri": "Entity-regularizer-Mention-1"
        }
      ],
      "relevance": 0.488037109375
    },
    "Entity-current_state-of-the-art_method": {
      "node_id": "current_state-of-the-art_method",
      "disambiguation_index": 0,
      "label": "current state-of-the-art methods",
      "aliases": [
        "current state-of-the-art methods"
      ],
      "types": [
        "method"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "State-of-the-art approaches in person re-identification",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "current state-of-the-art methods",
          "local_types": [
            "method"
          ],
          "iri": "Entity-current_state-of-the-art_method-Mention-1"
        }
      ],
      "relevance": 0.485107421875
    },
    "Entity-prediction_cost": {
      "node_id": "prediction_cost",
      "disambiguation_index": 0,
      "label": "prediction costs",
      "aliases": [
        "prediction costs"
      ],
      "types": [
        "financial metric",
        "cost"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The cost of making predictions using arbitrary distance measures that are more suitable for feature characteristics.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-6",
          "local_name": "prediction costs",
          "local_types": [
            "financial metric",
            "cost"
          ],
          "iri": "Entity-prediction_cost-Mention-1"
        }
      ],
      "relevance": 0.478515625
    },
    "Entity-matrix": {
      "node_id": "matrix",
      "disambiguation_index": 0,
      "label": "matrix",
      "aliases": [
        "matrix"
      ],
      "types": [
        "mathematical concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A mathematical structure with rows and columns, often used to represent a set of linearly related variables.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-7",
          "local_name": "matrix",
          "local_types": [
            "mathematical concept"
          ],
          "iri": "Entity-matrix-Mention-1"
        }
      ],
      "relevance": 0.47509765625
    },
    "Entity-new_method": {
      "node_id": "new_method",
      "disambiguation_index": 0,
      "label": "new method",
      "aliases": [
        "new method"
      ],
      "types": [
        "research finding",
        "algorithm"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A novel approach or technique in a particular field, such as research finding or algorithm.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-8",
          "local_name": "new method",
          "local_types": [
            "research finding",
            "algorithm"
          ],
          "iri": "Entity-new_method-Mention-1"
        }
      ],
      "relevance": 0.46875
    },
    "Entity-data_dimension": {
      "node_id": "data_dimension",
      "disambiguation_index": 0,
      "label": "data dimension",
      "aliases": [
        "data dimension"
      ],
      "types": [
        "dimensionality",
        "metric"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A characteristic or attribute that defines the size, scope, or complexity of a dataset.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-6",
          "local_name": "data dimension",
          "local_types": [
            "dimensionality",
            "metric"
          ],
          "iri": "Entity-data_dimension-Mention-1"
        }
      ],
      "relevance": 0.46240234375
    },
    "Entity-computer_vision": {
      "node_id": "computer_vision",
      "disambiguation_index": 0,
      "label": "computer vision",
      "aliases": [
        "computer vision"
      ],
      "types": [
        "field",
        "field of study",
        "domain"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A field of study and domain concerned with enabling computers to interpret, understand, and describe visual information from images or videos.",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-2",
          "local_name": "computer vision",
          "local_types": [
            "field",
            "field of study",
            "domain"
          ],
          "iri": "Entity-computer_vision-Mention-1"
        }
      ],
      "relevance": 0.455078125
    },
    "Entity-we": {
      "node_id": "we",
      "disambiguation_index": 0,
      "label": "We",
      "aliases": [
        "We"
      ],
      "types": [
        "author"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The authors",
      "mentions": [
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-4",
          "local_name": "We",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we-Mention-1"
        },
        {
          "reference": "Paper-75-Section-1-Paragraph-1-Sentence-5",
          "local_name": "We",
          "local_types": [
            "author"
          ],
          "iri": "Entity-we-Mention-2"
        }
      ],
      "relevance": 0.372314453125
    }
  },
  "summary": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks . Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification . We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB- . We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem . We also derive an efficient non-linear extension of WARCA by using the kernel trick . Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features . We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently . We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
  "triples": [
    [
      "Entity-our_goal",
      "Predicate-is_to_learn_a",
      "Entity-mahalanobis_distance"
    ],
    [
      "Entity-minimizing_a_weighted_rank_loss",
      "Predicate-is_a_natural_criterion_for",
      "Entity-person_re-identification"
    ],
    [
      "Entity-minimizing_a_weighted_rank_loss",
      "Predicate-is_a_natural_criterion_for_many_problems_in_computer_vision_such_as_person_re-identification",
      "Entity-person_re-identification"
    ],
    [
      "Entity-we",
      "Predicate-derive",
      "Entity-scalable_stochastic_gradient_descent"
    ],
    [
      "Entity-scalable_stochastic_gradient_descent",
      "Predicate-has_an_algorithm_for",
      "Entity-the_resulting_learning_problem"
    ],
    [
      "Entity-we",
      "Predicate-derive",
      "Entity-an_efficient_non-linear_extension_of_warca"
    ],
    [
      "Entity-warca",
      "Predicate-extended_by_using",
      "Entity-kernel_trick"
    ],
    [
      "Entity-kernel_space_embedding",
      "Predicate-decouples",
      "Entity-the_training_and_prediction_cost_from_the_data_dimension"
    ],
    [
      "Entity-matrix_rank_degeneration__non-isolated_minimum_in_the_low-rank_matrix_optimization",
      "Predicate-address",
      "Entity-matrix_rank_degeneration__non-isolated_minimum_in_the_low-rank_matrix_optimization"
    ],
    [
      "Entity-our_goal",
      "Predicate-minimizes",
      "Entity-weighted_approximate_rank_component_analysis"
    ],
    [
      "Entity-our_goal",
      "Predicate-derive",
      "Entity-the_resulting_learning_problem"
    ],
    [
      "Entity-the_resulting_learning_problem",
      "Predicate-derive",
      "Entity-weighted_approximate_rank_component_analysis"
    ]
  ],
  "triples_typing": [
    [
      "Entity-person_re-identification",
      "skos:broader",
      "Entity-computer_vision"
    ],
    [
      "Entity-the_or-thonormality_of_the_learned_matrix",
      "skos:broader",
      "Entity-matrix"
    ]
  ],
  "predicates": {
    "Predicate-is_to_learn_a": {
      "label": "is to learn a",
      "description": "The predicate 'is to learn a' indicates that the subject has an intention or objective to acquire knowledge about or understand something represented by the object. The object is often a concept, method, technique, or framework that the subject aims to master or comprehend.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_natural_criterion_for": {
      "label": "is a natural criterion for",
      "description": "The predicate 'is a natural criterion for' indicates that the subject represents an inherent or instinctive standard or measure that is well-suited and intuitive for evaluating or judging the object. It suggests that the subject provides a fundamental or innate basis for assessing the object, often in a way that is easily understood or accepted by humans.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_natural_criterion_for_many_problems_in_computer_vision_such_as_person_re-identification": {
      "label": "is a natural criterion for many problems in computer vision such as person re-identification",
      "description": "This predicate indicates that the subject is an inherent or intuitive measure used to solve various issues within a specific domain (computer vision), and possibly extends to other related problems such as person re-identification.",
      "disambiguation_index": 0
    },
    "Predicate-derive": {
      "label": "derive",
      "description": "To derive means to obtain or generate something from a given source or foundation. In this sense, it implies an intellectual process of extracting, deducing, or inferring information, concepts, or principles from existing knowledge, theories, or data.",
      "disambiguation_index": 0
    },
    "Predicate-has_an_algorithm_for": {
      "label": "has an algorithm for",
      "description": "The predicate 'has an algorithm for' indicates that a given subject (in this case, scalable stochastic gradient descent) possesses or utilizes a specific method or approach to solve or address the specified object (the resulting learning problem). In general, it suggests a connection between the subject's capabilities and its application to tackle a particular challenge.",
      "disambiguation_index": 0
    },
    "Predicate-extended_by_using": {
      "label": "extended by using",
      "description": "The predicate 'extended by using' indicates that a subject (a concept or method) has been augmented or enhanced through the incorporation of another entity (the object), which serves as a means to achieve this extension. This relationship suggests an intentional and deliberate process of modification, where the original subject is modified or expanded upon in some way.",
      "disambiguation_index": 0
    },
    "Predicate-decouples": {
      "label": "decouples",
      "description": "The predicate 'decouples' indicates a relationship where the subject (a process or mechanism) separates or disconnects two entities (the object), typically to reduce complexity, improve performance, or enhance understanding. In this context, it suggests that the subject enables the training and prediction costs to be treated independently of the data dimension.",
      "disambiguation_index": 0
    },
    "Predicate-address": {
      "label": "address",
      "description": "The predicate 'address' indicates a relationship where the subject provides a direct or indirect reference, explanation, or treatment of the object. It suggests that the subject has a connection to the object, whether it be through description, analysis, discussion, or some other form of engagement.",
      "disambiguation_index": 0
    },
    "Predicate-minimizes": {
      "label": "minimizes",
      "description": "The predicate 'minimizes' indicates a relationship where the subject aims to reduce or decrease the magnitude of the object. It suggests that the subject's primary objective is to minimize the impact, importance, or influence of the object.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates that the subject concept is a specific instance or subcategory of the object concept. It represents an hierarchical relationship where the subject is more focused or specialized than the object, which encompasses it.",
      "disambiguation_index": 0
    }
  }
}