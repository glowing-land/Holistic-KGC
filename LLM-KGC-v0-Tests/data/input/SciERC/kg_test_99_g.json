{
  "iri": "Paper-99",
  "title": "CVPR_2003_30_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-99-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-99-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-1",
              "text": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-2",
              "text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-3",
              "text": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-4",
              "text": "Preliminary modeling and recognition results are presented ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0004909038543701172,
    51.584885120391846,
    59.81514000892639,
    45.26253914833069,
    0.037271976470947266,
    0.00013399124145507812,
    0.00015807151794433594,
    205.25472497940063,
    206.24054384231567,
    3.7680749893188477,
    32.87759470939636,
    0.009807109832763672,
    0.00017571449279785156,
    56.45316505432129,
    10.850834131240845,
    0.0280148983001709,
    0.0009899139404296875,
    4.48851203918457,
    0.5809218883514404,
    9.827916145324707,
    564.9300048351288,
    8.429267168045044,
    129.81593322753906,
    2.358844757080078,
    0.0004177093505859375,
    0.007688999176025391
  ],
  "nodes": {
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "This paper",
      "aliases": [
        "This paper",
        "this paper"
      ],
      "types": [
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "This paper introduces a new method for representing three-dimensional objects using affine-invariant image patches and their spatial relationships, facilitating the matching and reconstruction of 3D models from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "This paper",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        }
      ],
      "relevance": 0.8642578125
    },
    "Entity-approach": {
      "node_id": "approach",
      "disambiguation_index": 0,
      "label": "approach",
      "aliases": [
        "The proposed approach",
        "approach"
      ],
      "types": [
        "method",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The approach refers to a novel method for representing three-dimensional objects using affine-invariant image patches and their spatial relationships, which facilitates matching and reconstruction without the need for separate segmentation, making it suitable for cluttered scenes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "approach",
          "local_types": [
            "method",
            "technique"
          ],
          "iri": "Entity-approach-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "The proposed approach",
          "local_types": [
            "method"
          ],
          "iri": "Entity-approach-Mention-2"
        }
      ],
      "relevance": 0.81494140625
    },
    "Entity-a_novel_representation_for_three-dimensional_object": {
      "node_id": "a_novel_representation_for_three-dimensional_object",
      "disambiguation_index": 0,
      "label": "a novel representation for three-dimensional objects",
      "aliases": [
        "a novel representation for three-dimensional objects"
      ],
      "types": [
        "representation",
        "three-dimensional object"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A novel representation for three-dimensional objects refers to a method that utilizes affine-invariant image patches and their spatial relationships to effectively model and recognize three-dimensional shapes from multiple images without requiring separate segmentation.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a novel representation for three-dimensional objects",
          "local_types": [
            "representation",
            "three-dimensional object"
          ],
          "iri": "Entity-a_novel_representation_for_three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.8037109375
    },
    "Entity-group_of_patch": {
      "node_id": "group_of_patch",
      "disambiguation_index": 0,
      "label": "groups of patches",
      "aliases": [
        "groups of patches"
      ],
      "types": [
        "patch",
        "data structure",
        "group",
        "image processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Groups of patches refer to collections of affine-invariant image patches that are used in the context of three-dimensional object representation and recognition, where their spatial relationships and appearance are leveraged to facilitate matching and reconstruction from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "groups of patches",
          "local_types": [
            "patch",
            "data structure",
            "group",
            "image processing"
          ],
          "iri": "Entity-group_of_patch-Mention-1"
        }
      ],
      "relevance": 0.78076171875
    },
    "Entity-three-dimensional_affine_and_euclidean_model": {
      "node_id": "three-dimensional_affine_and_euclidean_model",
      "disambiguation_index": 0,
      "label": "three-dimensional affine and Euclidean models",
      "aliases": [
        "true three-dimensional affine and Euclidean models",
        "three-dimensional affine and Euclidean models"
      ],
      "types": [
        "three-dimensional",
        "3D model",
        "model",
        "mathematical model",
        "Euclidean",
        "affine"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Three-dimensional affine and Euclidean models refer to mathematical representations of 3D objects that maintain their geometric properties under affine transformations and Euclidean transformations, enabling accurate reconstruction and recognition from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "three-dimensional affine and Euclidean models",
          "local_types": [
            "3D model",
            "mathematical model"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "true three-dimensional affine and Euclidean models",
          "local_types": [
            "model",
            "three-dimensional",
            "Euclidean",
            "affine"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-2"
        }
      ],
      "relevance": 0.75244140625
    },
    "Entity-normalized_representation": {
      "node_id": "normalized_representation",
      "disambiguation_index": 0,
      "label": "normalized representation",
      "aliases": [
        "normalized representation"
      ],
      "types": [
        "representation",
        "data representation",
        "image processing",
        "normalized"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'normalized representation' refers to a method of standardizing the appearance of image patches in the context of three-dimensional object recognition and reconstruction, facilitating the matching process across multiple views.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "normalized representation",
          "local_types": [
            "representation",
            "data representation",
            "image processing",
            "normalized"
          ],
          "iri": "Entity-normalized_representation-Mention-1"
        }
      ],
      "relevance": 0.7392578125
    },
    "Entity-preliminary_modeling_and_recognition_result": {
      "node_id": "preliminary_modeling_and_recognition_result",
      "disambiguation_index": 0,
      "label": "Preliminary modeling and recognition results",
      "aliases": [
        "Preliminary modeling and recognition results"
      ],
      "types": [
        "modeling",
        "recognition",
        "research findings",
        "results",
        "computer vision",
        "result"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'Preliminary modeling and recognition results' refers to the initial findings and outcomes related to the modeling and recognition of three-dimensional objects using a novel representation based on affine-invariant image patches, as discussed in the paper.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Preliminary modeling and recognition results",
          "local_types": [
            "modeling",
            "recognition",
            "research findings",
            "results",
            "computer vision",
            "result"
          ],
          "iri": "Entity-preliminary_modeling_and_recognition_result-Mention-1"
        }
      ],
      "relevance": 0.736328125
    },
    "Entity-affine-invariant_image_patch": {
      "node_id": "affine-invariant_image_patch",
      "disambiguation_index": 0,
      "label": "affine-invariant image patches",
      "aliases": [
        "affine-invariant image patches"
      ],
      "types": [
        "image processing technique",
        "feature descriptor",
        "image feature",
        "affine-invariant",
        "image patch",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Affine-invariant image patches are localized regions of an image that maintain their characteristics under affine transformations, making them useful for robust feature extraction in computer vision applications.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "affine-invariant image patches",
          "local_types": [
            "image processing technique",
            "feature descriptor",
            "image feature",
            "affine-invariant",
            "image patch",
            "computer vision"
          ],
          "iri": "Entity-affine-invariant_image_patch-Mention-1"
        }
      ],
      "relevance": 0.73388671875
    },
    "Entity-multi-view_constraint": {
      "node_id": "multi-view_constraint",
      "disambiguation_index": 0,
      "label": "Multi-view constraints",
      "aliases": [
        "Multi-view constraints"
      ],
      "types": [
        "image processing",
        "concept",
        "constraint",
        "methodology",
        "multi-view",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Multi-view constraints refer to the relationships and conditions applied to groups of image patches in computer vision, which facilitate the matching and reconstruction of three-dimensional models from multiple images taken from different viewpoints.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "Multi-view constraints",
          "local_types": [
            "image processing",
            "concept",
            "constraint",
            "methodology",
            "multi-view",
            "computer vision"
          ],
          "iri": "Entity-multi-view_constraint-Mention-1"
        }
      ],
      "relevance": 0.728515625
    },
    "Entity-appearance": {
      "node_id": "appearance",
      "disambiguation_index": 0,
      "label": "appearance",
      "aliases": [
        "appearance"
      ],
      "types": [
        "appearance"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In this context, 'appearance' refers to a normalized representation of the visual characteristics of image patches used to facilitate the matching and reconstruction of three-dimensional models from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "appearance",
          "local_types": [
            "appearance"
          ],
          "iri": "Entity-appearance-Mention-1"
        }
      ],
      "relevance": 0.71337890625
    },
    "Entity-multiple_image": {
      "node_id": "multiple_image",
      "disambiguation_index": 0,
      "label": "multiple images",
      "aliases": [
        "multiple images"
      ],
      "types": [
        "image processing",
        "multiple",
        "image",
        "data type",
        "image data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'multiple images' refers to a collection of images used in the context of acquiring three-dimensional models and recognizing objects from various viewpoints, as described in the paper's approach to image processing and reconstruction.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "multiple images",
          "local_types": [
            "image processing",
            "multiple",
            "image",
            "data type",
            "image data"
          ],
          "iri": "Entity-multiple_image-Mention-1"
        }
      ],
      "relevance": 0.69287109375
    },
    "Entity-matching_and_reconstruction": {
      "node_id": "matching_and_reconstruction",
      "disambiguation_index": 0,
      "label": "matching and reconstruction",
      "aliases": [
        "matching and reconstruction"
      ],
      "types": [
        "image processing",
        "reconstruction",
        "process",
        "computer vision",
        "matching"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Matching and reconstruction refers to the process of aligning and reconstructing three-dimensional models from multiple two-dimensional images by utilizing multi-view constraints and normalized appearance representations.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "matching and reconstruction",
          "local_types": [
            "image processing",
            "reconstruction",
            "process",
            "computer vision",
            "matching"
          ],
          "iri": "Entity-matching_and_reconstruction-Mention-1"
        }
      ],
      "relevance": 0.6689453125
    },
    "Entity-recognition_result": {
      "node_id": "recognition_result",
      "disambiguation_index": 0,
      "label": "recognition results",
      "aliases": [
        "recognition results"
      ],
      "types": [
        "outcome",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'recognition results' refers to the initial outcomes of the proposed method for identifying and reconstructing three-dimensional objects from multiple images, demonstrating the effectiveness of the approach in recognizing objects in cluttered scenes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "recognition results",
          "local_types": [
            "outcome",
            "data"
          ],
          "iri": "Entity-recognition_result-Mention-1"
        }
      ],
      "relevance": 0.666015625
    },
    "Entity-modeling": {
      "node_id": "modeling",
      "disambiguation_index": 0,
      "label": "modeling",
      "aliases": [
        "modeling"
      ],
      "types": [
        "process",
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'modeling' refers to the process of creating representations of three-dimensional objects based on their appearance and spatial relationships, as demonstrated through preliminary results in the context of matching and recognition from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "modeling",
          "local_types": [
            "process",
            "methodology"
          ],
          "iri": "Entity-modeling-Mention-1"
        }
      ],
      "relevance": 0.6650390625
    },
    "Entity-cluttered_scene": {
      "node_id": "cluttered_scene",
      "disambiguation_index": 0,
      "label": "cluttered scenes",
      "aliases": [
        "cluttered scenes"
      ],
      "types": [
        "environment",
        "scene",
        "cluttered",
        "image context",
        "context"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Cluttered scenes refer to complex visual environments characterized by a high density of objects and details, which pose challenges for image processing and recognition tasks.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "cluttered scenes",
          "local_types": [
            "environment",
            "scene",
            "cluttered",
            "image context",
            "context"
          ],
          "iri": "Entity-cluttered_scene-Mention-1"
        }
      ],
      "relevance": 0.640625
    },
    "Entity-three-dimensional_object": {
      "node_id": "three-dimensional_object",
      "disambiguation_index": 0,
      "label": "three-dimensional objects",
      "aliases": [
        "three-dimensional objects"
      ],
      "types": [
        "3D model",
        "three-dimensional",
        "object",
        "geometric object",
        "geometric entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Three-dimensional objects are physical or abstract entities that possess length, width, and height, allowing them to occupy space and be represented in various forms such as models or geometric shapes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "three-dimensional objects",
          "local_types": [
            "3D model",
            "three-dimensional",
            "object",
            "geometric object",
            "geometric entity"
          ],
          "iri": "Entity-three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.6279296875
    },
    "Entity-segmentation_stage": {
      "node_id": "segmentation_stage",
      "disambiguation_index": 0,
      "label": "segmentation stage",
      "aliases": [
        "segmentation stage",
        "a separate segmentation stage"
      ],
      "types": [
        "stage",
        "image processing",
        "process",
        "segmentation",
        "computer vision",
        "step"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'segmentation stage' refers to a distinct phase in image processing where an image is divided into segments to simplify its representation, but in this paper, it is noted that the proposed method does not necessitate this phase.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "segmentation stage",
          "local_types": [
            "stage",
            "image processing",
            "process",
            "segmentation",
            "computer vision",
            "step"
          ],
          "iri": "Entity-segmentation_stage-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "a separate segmentation stage",
          "local_types": [
            "process",
            "segmentation"
          ],
          "iri": "Entity-segmentation_stage-Mention-2"
        }
      ],
      "relevance": 0.6162109375
    },
    "Entity-arbitrary_viewpoint": {
      "node_id": "arbitrary_viewpoint",
      "disambiguation_index": 0,
      "label": "arbitrary viewpoint",
      "aliases": [
        "arbitrary viewpoint"
      ],
      "types": [
        "concept",
        "viewpoint",
        "arbitrary",
        "perspective"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'arbitrary viewpoint' refers to any perspective or angle from which a photograph can be taken, allowing for the recognition and reconstruction of three-dimensional models without being constrained to a specific viewpoint.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "arbitrary viewpoint",
          "local_types": [
            "concept",
            "viewpoint",
            "arbitrary",
            "perspective"
          ],
          "iri": "Entity-arbitrary_viewpoint-Mention-1"
        }
      ],
      "relevance": 0.615234375
    },
    "Entity-single_photograph": {
      "node_id": "single_photograph",
      "disambiguation_index": 0,
      "label": "single photograph",
      "aliases": [
        "single photograph"
      ],
      "types": [
        "photograph",
        "single",
        "photography",
        "image",
        "data type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A single photograph is a standalone image captured by a camera, representing a moment in time and space, typically consisting of visual information that can be analyzed or processed.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "single photograph",
          "local_types": [
            "photograph",
            "single",
            "photography",
            "image",
            "data type"
          ],
          "iri": "Entity-single_photograph-Mention-1"
        }
      ],
      "relevance": 0.55322265625
    },
    "Entity-spatial_relationship": {
      "node_id": "spatial_relationship",
      "disambiguation_index": 0,
      "label": "spatial relationships",
      "aliases": [
        "spatial relationships"
      ],
      "types": [
        "geometric relationship",
        "relationship",
        "mathematical concept",
        "geometry",
        "spatial"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Spatial relationships refer to the ways in which objects are positioned and oriented in relation to one another in a given space, encompassing various geometric and mathematical concepts.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "spatial relationships",
          "local_types": [
            "geometric relationship",
            "relationship",
            "mathematical concept",
            "geometry",
            "spatial"
          ],
          "iri": "Entity-spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.53564453125
    },
    "Entity-paper": {
      "node_id": "paper",
      "disambiguation_index": 0,
      "label": "paper",
      "aliases": [
        "paper"
      ],
      "types": [
        "academic work",
        "research document"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A paper is a written work that presents research findings, theories, or analyses, typically in an academic or scholarly context.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "paper",
          "local_types": [
            "academic work",
            "research document"
          ],
          "iri": "Entity-paper-Mention-1"
        }
      ],
      "relevance": 0.457275390625
    }
  },
  "summary": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships . Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint . The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes . Preliminary modeling and recognition results are presented .",
  "triples": [
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-a_novel_representation_for_three-dimensional_object"
    ],
    [
      "Entity-a_novel_representation_for_three-dimensional_object",
      "Predicate-is_for",
      "Entity-three-dimensional_object"
    ],
    [
      "Entity-affine-invariant_image_patch",
      "Predicate-are_related_to",
      "Entity-spatial_relationship"
    ],
    [
      "Entity-multi-view_constraint",
      "Predicate-are_combined_with",
      "Entity-normalized_representation"
    ],
    [
      "Entity-normalized_representation",
      "Predicate-guides",
      "Entity-matching_and_reconstruction"
    ],
    [
      "Entity-matching_and_reconstruction",
      "Predicate-allow_the_acquisition_of",
      "Entity-three-dimensional_affine_and_euclidean_model"
    ],
    [
      "Entity-three-dimensional_affine_and_euclidean_model",
      "Predicate-are_recognized_in",
      "Entity-single_photograph"
    ],
    [
      "Entity-multiple_image",
      "Predicate-are_taken_from",
      "Entity-arbitrary_viewpoint"
    ],
    [
      "Entity-approach",
      "Predicate-does_not_require",
      "Entity-segmentation_stage"
    ],
    [
      "Entity-approach",
      "Predicate-is_applicable_to",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-preliminary_modeling_and_recognition_result",
      "Predicate-are_presented",
      "Entity-modeling"
    ],
    [
      "Entity-preliminary_modeling_and_recognition_result",
      "Predicate-are_presented",
      "Entity-recognition_result"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-approach"
    ]
  ],
  "triples_typing": [
    [
      "Entity-preliminary_modeling_and_recognition_result",
      "skos:broader",
      "Entity-modeling"
    ],
    [
      "Entity-a_novel_representation_for_three-dimensional_object",
      "skos:broader",
      "Entity-three-dimensional_object"
    ],
    [
      "Entity-three-dimensional_affine_and_euclidean_model",
      "skos:broader",
      "Entity-three-dimensional_object"
    ]
  ],
  "predicates": {
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates that the subject is introducing, showcasing, or offering something to the audience or reader, which is represented by the object. It implies a formal or structured delivery of information, findings, or concepts, often in a context where the subject aims to inform or persuade the audience about the significance or utility of the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_for": {
      "label": "is for",
      "description": "The predicate 'is for' establishes a relationship of purpose or intended use between the subject and the object, indicating that the subject serves, supports, or is designed to benefit the object in some way.",
      "disambiguation_index": 0
    },
    "Predicate-are_related_to": {
      "label": "are related to",
      "description": "The predicate 'are related to' indicates a connection or association between the subject and the object, suggesting that they share a significant link, influence, or relevance to one another within a particular context or domain. This relationship can encompass various forms of interaction, correlation, or dependency, highlighting how the subject and object inform, affect, or complement each other.",
      "disambiguation_index": 0
    },
    "Predicate-are_combined_with": {
      "label": "are combined with",
      "description": "The predicate 'are combined with' indicates a relationship where the subject and object are brought together or integrated to form a unified entity or concept. This combination suggests that the characteristics or functionalities of both the subject and object interact or enhance each other, resulting in a new or improved outcome.",
      "disambiguation_index": 0
    },
    "Predicate-guides": {
      "label": "guides",
      "description": "The predicate 'guides' indicates a directional influence or support provided by the subject towards the object, suggesting that the subject offers direction, advice, or a framework that assists in the process or understanding of the object. In this context, it implies that the subject plays a crucial role in facilitating or enhancing the effectiveness of the actions or concepts represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-allow_the_acquisition_of": {
      "label": "allow the acquisition of",
      "description": "The predicate 'allow the acquisition of' indicates that the subject facilitates or enables the process of obtaining or gaining possession of the object. It suggests a relationship where the actions or processes represented by the subject create conditions or opportunities for the object to be acquired, thus establishing a connection between the two elements.",
      "disambiguation_index": 0
    },
    "Predicate-are_recognized_in": {
      "label": "are recognized in",
      "description": "The predicate 'are recognized in' indicates a relationship where the subject is acknowledged or identified within the context of the object. It suggests that the subject has a notable presence or significance that is observable or discernible in the specified object, implying a connection or relevance between the two.",
      "disambiguation_index": 0
    },
    "Predicate-are_taken_from": {
      "label": "are taken from",
      "description": "The predicate 'are taken from' indicates a source or origin relationship between the subject and the object, suggesting that the subject derives or is obtained from the object. It implies that the subject is a result of a process or action that involves the object as its starting point or reference.",
      "disambiguation_index": 0
    },
    "Predicate-does_not_require": {
      "label": "does not require",
      "description": "The predicate 'does not require' indicates that the subject is capable of functioning or being effective without the necessity of the object. It implies that the relationship between the subject and the object is non-essential, meaning that the subject can operate independently of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-is_applicable_to": {
      "label": "is applicable to",
      "description": "The predicate 'is applicable to' establishes a relationship where the subject is relevant or suitable for the context or conditions represented by the object. It indicates that the subject can be effectively used, implemented, or considered in relation to the characteristics or requirements of the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_presented": {
      "label": "are presented",
      "description": "The predicate 'are presented' indicates that the subject is being shown, displayed, or introduced in a manner that conveys information or findings related to the object. It establishes a relationship where the subject serves as the source of information or results, while the object represents the context or specific aspect of that information being highlighted or discussed.",
      "disambiguation_index": 0
    },
    "Predicate-introduces": {
      "label": "introduces",
      "description": "The predicate 'introduces' signifies an action where the subject presents or brings forth the object, often in a context that aims to inform or familiarize the audience with the object. It implies a transition from a state of unawareness to awareness regarding the object, highlighting the subject's role in making the object known or accessible.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' establishes a hierarchical relationship between the subject and the object, indicating that the subject is a specific instance or subset of the more general concept represented by the object. This relationship suggests that the object encompasses a wider scope or category that includes the subject, thereby providing a context in which the subject can be understood as part of a larger framework.",
      "disambiguation_index": 0
    }
  }
}