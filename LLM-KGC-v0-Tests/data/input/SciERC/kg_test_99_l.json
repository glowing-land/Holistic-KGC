{
  "iri": "Paper-99",
  "title": "CVPR_2003_30_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-99-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-99-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-1",
              "text": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-2",
              "text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-3",
              "text": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes ."
            },
            {
              "iri": "Paper-99-Section-1-Paragraph-1-Sentence-4",
              "text": "Preliminary modeling and recognition results are presented ."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0005247592926025391,
    16.2173752784729,
    22.296691417694092,
    20.3231143951416,
    0.027443647384643555,
    0.00010085105895996094,
    0.0001399517059326172,
    45.00020480155945,
    47.13852548599243,
    1.0645062923431396,
    25.031749725341797,
    0.011578798294067383,
    0.00020170211791992188,
    23.699883222579956,
    2.4883201122283936,
    0.015015840530395508,
    1.0942203998565674,
    3.2476770877838135,
    7.101385116577148,
    8.39876651763916,
    44.660494327545166,
    1.9656047821044922,
    24.10328435897827,
    0.947014331817627,
    0.0006775856018066406,
    0.013395309448242188
  ],
  "nodes": {
    "Entity-the_proposed_approach": {
      "node_id": "the_proposed_approach",
      "disambiguation_index": 0,
      "label": "The proposed approach",
      "aliases": [
        "The proposed approach"
      ],
      "types": [
        "approach"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A novel representation for three-dimensional objects that combines affine-invariant image patches, spatial relationships, and multi-view constraints without requiring a separate segmentation stage.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "The proposed approach",
          "local_types": [
            "approach"
          ],
          "iri": "Entity-the_proposed_approach-Mention-1"
        }
      ],
      "relevance": 0.8369140625
    },
    "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship": {
      "node_id": "in_term_of_affine-invariant_image_patch_and_their_spatial_relationship",
      "disambiguation_index": 0,
      "label": "in terms of affine-invariant image patches and their spatial relationships",
      "aliases": [
        "in terms of affine-invariant image patches and their spatial relationships"
      ],
      "types": [
        "methodology",
        "image processing"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A methodological approach that represents three-dimensional objects using invariant image patches and their spatial connections.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "in terms of affine-invariant image patches and their spatial relationships",
          "local_types": [
            "methodology",
            "image processing"
          ],
          "iri": "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.80029296875
    },
    "Entity-affine-invariant_image_patch": {
      "node_id": "affine-invariant_image_patch",
      "disambiguation_index": 0,
      "label": "affine-invariant image patches",
      "aliases": [
        "affine-invariant image patches"
      ],
      "types": [
        "computer vision concept",
        "technique",
        "image processing",
        "image processing technique",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A set of image regions that remain unchanged under different viewpoints, used to represent and recognize 3D objects from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "affine-invariant image patches",
          "local_types": [
            "computer vision concept",
            "technique",
            "image processing",
            "image processing technique",
            "computer vision"
          ],
          "iri": "Entity-affine-invariant_image_patch-Mention-1"
        }
      ],
      "relevance": 0.76806640625
    },
    "Entity-applicable_to_cluttered_scene": {
      "node_id": "applicable_to_cluttered_scene",
      "disambiguation_index": 0,
      "label": "applicable to cluttered scenes",
      "aliases": [
        "applicable to cluttered scenes"
      ],
      "types": [
        "scene type",
        "cluttered scene"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A representation method for three-dimensional objects that can be used without requiring a separate segmentation step, suitable for recognizing objects from multiple images and single photographs taken from arbitrary viewpoints even when scenes are cluttered.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "applicable to cluttered scenes",
          "local_types": [
            "scene type",
            "cluttered scene"
          ],
          "iri": "Entity-applicable_to_cluttered_scene-Mention-1"
        }
      ],
      "relevance": 0.75
    },
    "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image": {
      "node_id": "acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image",
      "disambiguation_index": 0,
      "label": "acquisition of true three-dimensional affine and Euclidean models from multiple images",
      "aliases": [
        "acquisition of true three-dimensional affine and Euclidean models from multiple images",
        "the acquisition of true three-dimensional affine and Euclidean models from multiple images"
      ],
      "types": [
        "image",
        "3D model",
        "acquisition",
        "model acquisition",
        "model"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A method that reconstructs true three-dimensional affine and Euclidean models of objects from multiple images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "acquisition of true three-dimensional affine and Euclidean models from multiple images",
          "local_types": [
            "model acquisition",
            "3D model"
          ],
          "iri": "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "the acquisition of true three-dimensional affine and Euclidean models from multiple images",
          "local_types": [
            "acquisition",
            "model",
            "image"
          ],
          "iri": "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image-Mention-2"
        }
      ],
      "relevance": 0.74609375
    },
    "Entity-multi-view_constraint_associated_with_group_of_patch": {
      "node_id": "multi-view_constraint_associated_with_group_of_patch",
      "disambiguation_index": 0,
      "label": "Multi-view constraints associated with groups of patches",
      "aliases": [
        "Multi-view constraints associated with groups of patches"
      ],
      "types": [
        "constraint",
        "patch group"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A set of spatial relationships between image patch clusters that guide matching and reconstruction processes in three-dimensional object recognition.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "Multi-view constraints associated with groups of patches",
          "local_types": [
            "constraint",
            "patch group"
          ],
          "iri": "Entity-multi-view_constraint_associated_with_group_of_patch-Mention-1"
        }
      ],
      "relevance": 0.7421875
    },
    "Entity-three-dimensional_affine_and_euclidean_model": {
      "node_id": "three-dimensional_affine_and_euclidean_model",
      "disambiguation_index": 0,
      "label": "three-dimensional affine and Euclidean models",
      "aliases": [
        "three-dimensional affine and Euclidean models",
        "true three-dimensional affine and Euclidean models"
      ],
      "types": [
        "models",
        "3D model",
        "concept",
        "geometry",
        "model",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Three-dimensional geometric representations that combine both affine transformations (preserving angles) and Euclidean transformations (preserving distances)",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "three-dimensional affine and Euclidean models",
          "local_types": [
            "models",
            "3D model",
            "concept",
            "geometry",
            "model",
            "representation"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "true three-dimensional affine and Euclidean models",
          "local_types": [
            "model",
            "geometry"
          ],
          "iri": "Entity-three-dimensional_affine_and_euclidean_model-Mention-2"
        }
      ],
      "relevance": 0.73828125
    },
    "Entity-normalized_representation": {
      "node_id": "normalized_representation",
      "disambiguation_index": 0,
      "label": "normalized representation",
      "aliases": [
        "normalized representation"
      ],
      "types": [
        "technique",
        "algorithm",
        "image processing",
        "method",
        "pattern recognition",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method for combining multi-view constraints with the appearance of patches to guide matching, reconstruction, and recognition.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "normalized representation",
          "local_types": [
            "technique",
            "algorithm",
            "image processing",
            "method",
            "pattern recognition",
            "representation"
          ],
          "iri": "Entity-normalized_representation-Mention-1"
        }
      ],
      "relevance": 0.73291015625
    },
    "Entity-group_of_patch": {
      "node_id": "group_of_patch",
      "disambiguation_index": 0,
      "label": "groups of patches",
      "aliases": [
        "groups of patches"
      ],
      "types": [
        "patches",
        "group",
        "collection",
        "image processing",
        "data set",
        "patch",
        "grouping",
        "data structure",
        "concept",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Collections of image patches used to represent three-dimensional objects and guide matching and reconstruction processes in computer vision",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "groups of patches",
          "local_types": [
            "patches",
            "group",
            "collection",
            "image processing",
            "data set",
            "patch",
            "grouping",
            "data structure",
            "concept",
            "computer vision"
          ],
          "iri": "Entity-group_of_patch-Mention-1"
        }
      ],
      "relevance": 0.724609375
    },
    "Entity-affine-invariant_image_patch_and_their_spatial_relationship": {
      "node_id": "affine-invariant_image_patch_and_their_spatial_relationship",
      "disambiguation_index": 0,
      "label": "affine-invariant image patches and their spatial relationships",
      "aliases": [
        "affine-invariant image patches and their spatial relationships"
      ],
      "types": [
        "spatial relationship",
        "image patch"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Sets of images with similar features, connected by geometrically meaningful relationships.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "affine-invariant image patches and their spatial relationships",
          "local_types": [
            "spatial relationship",
            "image patch"
          ],
          "iri": "Entity-affine-invariant_image_patch_and_their_spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.72412109375
    },
    "Entity-guide_matching_and_reconstruction": {
      "node_id": "guide_matching_and_reconstruction",
      "disambiguation_index": 0,
      "label": "guide matching and reconstruction",
      "aliases": [
        "guide matching and reconstruction"
      ],
      "types": [
        "process",
        "reconstruction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A process that combines multi-view constraints with normalized patch appearance to facilitate the alignment of image patches across multiple views, enabling the construction of 3D models from images taken from arbitrary viewpoints.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "guide matching and reconstruction",
          "local_types": [
            "process",
            "reconstruction"
          ],
          "iri": "Entity-guide_matching_and_reconstruction-Mention-1"
        }
      ],
      "relevance": 0.71923828125
    },
    "Entity-appearance": {
      "node_id": "appearance",
      "disambiguation_index": 0,
      "label": "appearance",
      "aliases": [
        "appearance"
      ],
      "types": [
        "property",
        "image processing",
        "attribute",
        "visual feature",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A normalized representation of image patches' visual features used to guide matching and reconstruction in computer vision",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "appearance",
          "local_types": [
            "property",
            "image processing",
            "attribute",
            "visual feature",
            "computer vision"
          ],
          "iri": "Entity-appearance-Mention-1"
        }
      ],
      "relevance": 0.68115234375
    },
    "Entity-normalized_representation_of_their_appearance": {
      "node_id": "normalized_representation_of_their_appearance",
      "disambiguation_index": 0,
      "label": "normalized representation of their appearance",
      "aliases": [
        "normalized representation of their appearance",
        "a normalized representation of their appearance"
      ],
      "types": [
        "appearance",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "A mathematical model that represents the visual features or characteristics of three-dimensional objects, used to guide matching and reconstruction processes in computer vision.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "normalized representation of their appearance",
          "local_types": [
            "appearance",
            "representation"
          ],
          "iri": "Entity-normalized_representation_of_their_appearance-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "a normalized representation of their appearance",
          "local_types": [
            "representation",
            "appearance"
          ],
          "iri": "Entity-normalized_representation_of_their_appearance-Mention-2"
        }
      ],
      "relevance": 0.66748046875
    },
    "Entity-cluttered_scene": {
      "node_id": "cluttered_scene",
      "disambiguation_index": 0,
      "label": "cluttered scenes",
      "aliases": [
        "cluttered scenes"
      ],
      "types": [
        "environment",
        "scene",
        "scenes"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Three-dimensional environments or settings with complex, disorganized arrangements of objects.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "cluttered scenes",
          "local_types": [
            "environment",
            "scene",
            "scenes"
          ],
          "iri": "Entity-cluttered_scene-Mention-1"
        }
      ],
      "relevance": 0.65478515625
    },
    "Entity-novel_representation_for_three-dimensional_object": {
      "node_id": "novel_representation_for_three-dimensional_object",
      "disambiguation_index": 0,
      "label": "novel representation for three-dimensional objects",
      "aliases": [
        "novel representation for three-dimensional objects",
        "a novel representation for three-dimensional objects"
      ],
      "types": [
        "3D object",
        "representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method or technique used to depict or describe three-dimensional objects",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "novel representation for three-dimensional objects",
          "local_types": [
            "3D object",
            "representation"
          ],
          "iri": "Entity-novel_representation_for_three-dimensional_object-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "a novel representation for three-dimensional objects",
          "local_types": [
            "representation",
            "3D object"
          ],
          "iri": "Entity-novel_representation_for_three-dimensional_object-Mention-2"
        }
      ],
      "relevance": 0.64892578125
    },
    "Entity-multi-view_constraint": {
      "node_id": "multi-view_constraint",
      "disambiguation_index": 0,
      "label": "Multi-view constraints",
      "aliases": [
        "multi-view constraints",
        "Multi-view constraints"
      ],
      "types": [
        "algorithm",
        "image processing",
        "constraint",
        "method",
        "concept",
        "methodology",
        "computer vision"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A set of constraints that combines information from multiple views or perspectives to achieve a specific goal, such as matching, reconstruction, or recognition.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "Multi-view constraints",
          "local_types": [
            "algorithm",
            "image processing",
            "constraint",
            "method",
            "concept",
            "methodology",
            "computer vision"
          ],
          "iri": "Entity-multi-view_constraint-Mention-1"
        }
      ],
      "relevance": 0.6396484375
    },
    "Entity-single_photograph_taken_from_an_arbitrary_viewpoint": {
      "node_id": "single_photograph_taken_from_an_arbitrary_viewpoint",
      "disambiguation_index": 0,
      "label": "single photograph taken from an arbitrary viewpoint",
      "aliases": [
        "single photograph taken from an arbitrary viewpoint",
        "single photograph"
      ],
      "types": [
        "image",
        "image processing",
        "visual data",
        "data type",
        "computer vision",
        "photograph"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A two-dimensional visual representation captured from any angle or perspective.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "single photograph taken from an arbitrary viewpoint",
          "local_types": [
            "image",
            "image processing",
            "visual data",
            "data type",
            "computer vision",
            "photograph"
          ],
          "iri": "Entity-single_photograph_taken_from_an_arbitrary_viewpoint-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "single photograph",
          "local_types": [
            "data type",
            "image"
          ],
          "iri": "Entity-single_photograph_taken_from_an_arbitrary_viewpoint-Mention-2"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint": {
      "node_id": "recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint",
      "disambiguation_index": 0,
      "label": "recognition in a single photograph taken from an arbitrary viewpoint",
      "aliases": [
        "recognition in a single photograph taken from an arbitrary viewpoint",
        "their recognition in a single photograph taken from an arbitrary viewpoint"
      ],
      "types": [
        "photograph recognition",
        "viewpoint",
        "recognition",
        "process",
        "photograph"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of identifying or verifying something based on its appearance in a single image, regardless of the angle or perspective.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "recognition in a single photograph taken from an arbitrary viewpoint",
          "local_types": [
            "photograph recognition",
            "process"
          ],
          "iri": "Entity-recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "their recognition in a single photograph taken from an arbitrary viewpoint",
          "local_types": [
            "recognition",
            "photograph",
            "viewpoint"
          ],
          "iri": "Entity-recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint-Mention-2"
        }
      ],
      "relevance": 0.60986328125
    },
    "Entity-multiple_image": {
      "node_id": "multiple_image",
      "disambiguation_index": 0,
      "label": "multiple images",
      "aliases": [
        "multiple images"
      ],
      "types": [
        "image",
        "collection",
        "image processing",
        "data set",
        "images",
        "data type",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A set or collection of visual representations, typically photographs or digital images.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "multiple images",
          "local_types": [
            "image",
            "collection",
            "image processing",
            "data set",
            "images",
            "data type",
            "computer vision"
          ],
          "iri": "Entity-multiple_image-Mention-1"
        }
      ],
      "relevance": 0.60693359375
    },
    "Entity-three-dimensional_object": {
      "node_id": "three-dimensional_object",
      "disambiguation_index": 0,
      "label": "three-dimensional objects",
      "aliases": [
        "three-dimensional objects"
      ],
      "types": [
        "geometry",
        "objects",
        "3D model",
        "geometric shape",
        "object",
        "concept"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Three-dimensional geometric shapes or models that have length, width, and depth.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "three-dimensional objects",
          "local_types": [
            "geometry",
            "objects",
            "3D model",
            "geometric shape",
            "object",
            "concept"
          ],
          "iri": "Entity-three-dimensional_object-Mention-1"
        }
      ],
      "relevance": 0.60498046875
    },
    "Entity-matching_and_reconstruction": {
      "node_id": "matching_and_reconstruction",
      "disambiguation_index": 0,
      "label": "matching and reconstruction",
      "aliases": [
        "matching and reconstruction"
      ],
      "types": [
        "algorithm",
        "procedure",
        "process",
        "method",
        "computer vision"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A process or method that combines matching and reconstruction techniques to achieve a specific goal, often used in computer vision applications.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-2",
          "local_name": "matching and reconstruction",
          "local_types": [
            "algorithm",
            "procedure",
            "process",
            "method",
            "computer vision"
          ],
          "iri": "Entity-matching_and_reconstruction-Mention-1"
        }
      ],
      "relevance": 0.60400390625
    },
    "Entity-preliminary_modeling_and_recognition_result_are_presented": {
      "node_id": "preliminary_modeling_and_recognition_result_are_presented",
      "disambiguation_index": 0,
      "label": "Preliminary modeling and recognition results are presented",
      "aliases": [
        "recognition results are presented",
        "Preliminary modeling and recognition results are presented"
      ],
      "types": [
        "results",
        "result presentation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The preliminary outcomes of object modeling and recognition processes.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Preliminary modeling and recognition results are presented",
          "local_types": [
            "result presentation"
          ],
          "iri": "Entity-preliminary_modeling_and_recognition_result_are_presented-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "recognition results are presented",
          "local_types": [
            "results"
          ],
          "iri": "Entity-preliminary_modeling_and_recognition_result_are_presented-Mention-2"
        }
      ],
      "relevance": 0.5869140625
    },
    "Entity-novel_representation": {
      "node_id": "novel_representation",
      "disambiguation_index": 0,
      "label": "novel representation",
      "aliases": [
        "novel representation"
      ],
      "types": [
        "approach",
        "algorithm",
        "mathematical concept",
        "method",
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A new way to represent or describe something",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "novel representation",
          "local_types": [
            "approach",
            "algorithm",
            "mathematical concept",
            "method",
            "methodology"
          ],
          "iri": "Entity-novel_representation-Mention-1"
        }
      ],
      "relevance": 0.57958984375
    },
    "Entity-preliminary_modeling": {
      "node_id": "preliminary_modeling",
      "disambiguation_index": 0,
      "label": "Preliminary modeling",
      "aliases": [
        "Preliminary modeling"
      ],
      "types": [
        "modeling",
        "research method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The process of creating an initial or early-stage conceptual representation or framework for a system, concept, or phenomenon.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "Preliminary modeling",
          "local_types": [
            "modeling",
            "research method"
          ],
          "iri": "Entity-preliminary_modeling-Mention-1"
        }
      ],
      "relevance": 0.55859375
    },
    "Entity-spatial_relationship": {
      "node_id": "spatial_relationship",
      "disambiguation_index": 0,
      "label": "spatial relationships",
      "aliases": [
        "spatial relationships"
      ],
      "types": [
        "topology",
        "geometric relationship",
        "relationship",
        "mathematical concept",
        "pattern recognition",
        "geometry"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A type of relationship that describes the geometric or topological connections between entities in a given space.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "spatial relationships",
          "local_types": [
            "topology",
            "geometric relationship",
            "relationship",
            "mathematical concept",
            "pattern recognition",
            "geometry"
          ],
          "iri": "Entity-spatial_relationship-Mention-1"
        }
      ],
      "relevance": 0.54052734375
    },
    "Entity-proposed_approach_doe_not_require_a_separate_segmentation_stage": {
      "node_id": "proposed_approach_doe_not_require_a_separate_segmentation_stage",
      "disambiguation_index": 0,
      "label": "proposed approach does not require a separate segmentation stage",
      "aliases": [
        "proposed approach does not require a separate segmentation stage"
      ],
      "types": [
        "approach",
        "segmentation-free"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A method or technique that eliminates the need for segmenting data into distinct parts.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "proposed approach does not require a separate segmentation stage",
          "local_types": [
            "approach",
            "segmentation-free"
          ],
          "iri": "Entity-proposed_approach_doe_not_require_a_separate_segmentation_stage-Mention-1"
        }
      ],
      "relevance": 0.52099609375
    },
    "Entity-segmentation_stage": {
      "node_id": "segmentation_stage",
      "disambiguation_index": 0,
      "label": "segmentation stage",
      "aliases": [
        "segmentation stage",
        "a separate segmentation stage"
      ],
      "types": [
        "stage",
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A step in a process that involves dividing or separating something into distinct parts.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "segmentation stage",
          "local_types": [
            "process",
            "stage"
          ],
          "iri": "Entity-segmentation_stage-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "a separate segmentation stage",
          "local_types": [
            "stage"
          ],
          "iri": "Entity-segmentation_stage-Mention-2"
        }
      ],
      "relevance": 0.51025390625
    },
    "Entity-proposed_approach": {
      "node_id": "proposed_approach",
      "disambiguation_index": 0,
      "label": "proposed approach",
      "aliases": [
        "proposed approach"
      ],
      "types": [
        "methodology",
        "algorithm"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A methodology or algorithm for solving a problem or achieving an objective.",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-3",
          "local_name": "proposed approach",
          "local_types": [
            "methodology",
            "algorithm"
          ],
          "iri": "Entity-proposed_approach-Mention-1"
        }
      ],
      "relevance": 0.50634765625
    },
    "Entity-recognition_result": {
      "node_id": "recognition_result",
      "disambiguation_index": 0,
      "label": "recognition results",
      "aliases": [
        "recognition results"
      ],
      "types": [
        "study outcome"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The outcome of a study or experiment, typically involving classification or identification",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-4",
          "local_name": "recognition results",
          "local_types": [
            "study outcome"
          ],
          "iri": "Entity-recognition_result-Mention-1"
        }
      ],
      "relevance": 0.494384765625
    },
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "This paper",
      "aliases": [
        "This paper",
        "paper"
      ],
      "types": [
        "research paper",
        "academic publication",
        "research",
        "paper",
        "publication"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "A written work presenting research or findings on a particular topic",
      "mentions": [
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "This paper",
          "local_types": [
            "publication",
            "research",
            "paper"
          ],
          "iri": "Entity-this_paper-Mention-1"
        },
        {
          "reference": "Paper-99-Section-1-Paragraph-1-Sentence-1",
          "local_name": "paper",
          "local_types": [
            "research paper",
            "academic publication"
          ],
          "iri": "Entity-this_paper-Mention-2"
        }
      ],
      "relevance": 0.453369140625
    }
  },
  "summary": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships . Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint . The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes . Preliminary modeling and recognition results are presented .",
  "triples": [
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-novel_representation_for_three-dimensional_object"
    ],
    [
      "Entity-multi-view_constraint",
      "Predicate-associated_with",
      "Entity-group_of_patch"
    ],
    [
      "Entity-multi-view_constraint_associated_with_group_of_patch",
      "Predicate-are_combined_with",
      "Entity-normalized_representation_of_their_appearance"
    ],
    [
      "Entity-normalized_representation_of_their_appearance",
      "Predicate-guides",
      "Entity-matching_and_reconstruction"
    ],
    [
      "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image",
      "Predicate-allows",
      "Entity-recognition_in_a_single_photograph_taken_from_an_arbitrary_viewpoint"
    ],
    [
      "Entity-proposed_approach",
      "Predicate-does_not_require",
      "Entity-segmentation_stage"
    ],
    [
      "Entity-the_proposed_approach",
      "Predicate-is_applicable_to",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-proposed_approach",
      "Predicate-is_applicable_to",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-preliminary_modeling",
      "Predicate-are",
      "Entity-recognition_result"
    ],
    [
      "Entity-the_proposed_approach",
      "Predicate-represents",
      "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship"
    ],
    [
      "Entity-the_proposed_approach",
      "Predicate-combine",
      "Entity-affine-invariant_image_patch"
    ],
    [
      "Entity-in_term_of_affine-invariant_image_patch_and_their_spatial_relationship",
      "Predicate-represents",
      "Entity-affine-invariant_image_patch"
    ]
  ],
  "triples_typing": [
    [
      "Entity-matching_and_reconstruction",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-proposed_approach_doe_not_require_a_separate_segmentation_stage",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-multi-view_constraint",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-applicable_to_cluttered_scene",
      "skos:broader",
      "Entity-cluttered_scene"
    ],
    [
      "Entity-normalized_representation",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-novel_representation_for_three-dimensional_object",
      "skos:broader",
      "Entity-three-dimensional_object"
    ],
    [
      "Entity-acquisition_of_true_three-dimensional_affine_and_euclidean_model_from_multiple_image",
      "skos:broader",
      "Entity-multiple_image"
    ],
    [
      "Entity-normalized_representation_of_their_appearance",
      "skos:broader",
      "Entity-appearance"
    ],
    [
      "Entity-the_proposed_approach",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-novel_representation",
      "skos:broader",
      "Entity-proposed_approach"
    ],
    [
      "Entity-affine-invariant_image_patch_and_their_spatial_relationship",
      "skos:broader",
      "Entity-spatial_relationship"
    ],
    [
      "Entity-single_photograph_taken_from_an_arbitrary_viewpoint",
      "skos:broader",
      "Entity-multiple_image"
    ]
  ],
  "predicates": {
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates that the subject provides or offers something to someone or something else. It implies a sense of introduction, display, or revelation, connecting the subject with an idea, concept, or representation.",
      "disambiguation_index": 0
    },
    "Predicate-associated_with": {
      "label": "associated with",
      "description": "The predicate 'associated with' indicates a connection between two entities where one entity (the subject) has some relationship or correspondence to another entity (the object). This relationship can be characterized by similarity, membership, classification, or any other type of association. The subject and object are linked in that they share common characteristics, properties, or attributes.",
      "disambiguation_index": 0
    },
    "Predicate-are_combined_with": {
      "label": "are combined with",
      "description": "The predicate 'are combined with' indicates a relationship where two or more entities (the subject and object) are merged, integrated, or unified to form a new whole. This connection implies that the properties, characteristics, or features of each entity are brought together to create a cohesive representation.",
      "disambiguation_index": 0
    },
    "Predicate-guides": {
      "label": "guides",
      "description": "The predicate 'guides' indicates a relationship where the subject provides direction or instruction to achieve a specific outcome or goal, which is described by the object. In this context, the subject serves as an authority or expert that helps navigate through a process or situation.",
      "disambiguation_index": 0
    },
    "Predicate-allows": {
      "label": "allows",
      "description": "The predicate 'allows' indicates that the subject enables or permits the object to occur, happen, or be possible. It implies a causal relationship where the subject's existence or action creates an opportunity for the object to take place.",
      "disambiguation_index": 0
    },
    "Predicate-does_not_require": {
      "label": "does not require",
      "description": "The predicate 'does not require' indicates that a subject (a proposed approach or method) lacks a necessary condition or step to function properly. It implies that the object (in this case, segmentation stage) is not essential for the subject's operation.",
      "disambiguation_index": 0
    },
    "Predicate-is_applicable_to": {
      "label": "is applicable to",
      "description": "This predicate indicates a relationship where the subject (a concept, method, or solution) has relevance and effectiveness for the object (a specific context, scenario, or problem). The connection between the subject and object suggests that the former can be used to address or solve issues related to the latter.",
      "disambiguation_index": 0
    },
    "Predicate-are": {
      "label": "are",
      "description": "The predicate 'are' indicates a state of being or equivalence between two entities. It connects the subject and object by stating that they share a common characteristic, property, or classification.",
      "disambiguation_index": 0
    },
    "Predicate-represents": {
      "label": "represents",
      "description": "To represent means to convey or express a concept, idea, or phenomenon through a particular framework, model, or description. The predicate 'represents' indicates that the subject (a proposal, approach, theory, etc.) provides an abstracted or simplified view of something more complex, using the object as its underlying structure or foundation.",
      "disambiguation_index": 0
    },
    "Predicate-combine": {
      "label": "combine",
      "description": "To combine means to unite or merge two or more entities into a single entity, often resulting in a new whole that possesses properties of its constituent parts. This predicate suggests an integration process where distinct elements are brought together to form a cohesive unit.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' indicates that the subject concept is a specific instance or subclass of the object concept. It represents an is-a relationship, where the subject is a more detailed or specialized version of the object.",
      "disambiguation_index": 0
    }
  }
}