{
  "price": 0.21,
  "iri": "Paper-MEL_Metadata_Extractor__Loader",
  "title": "MEL: Metadata Extractor & Loader",
  "authors": [
    "Sergio J. Rodr\u00edguez M\u00e9ndez",
    "Pouya G. Omran",
    "Armin Haller",
    "KerryTaylor"
  ],
  "keywords": [
    "Metadata Extraction",
    "Information Extraction",
    "Data Preprocessing",
    "Knowledge Graph Construction",
    "Data Analysis Pipeline"
  ],
  "sections": [
    {
      "iri": "Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-1-Paragraph-1-Sentence-1",
              "text": "The metadata and content-based information extraction tasks from heterogeneous file sets are pre-processing steps of many Knowledge Graph Construction Pipelines (KGCP)."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-2",
              "text": "These tasks often take longer than necessary due to the lack of proper tools that integrate several complementary extraction methods and properties to get a rich output set."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-3",
              "text": "This paper presents MEL, a Python-based tool that implements a set of methods to extract metadata and content-based information from unstructured information encoded in different source document formats."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-4",
              "text": "The results are generated as JSON files, which can: (a) optionally be stored in a document store, and (b) easily be mapped to RDF using a variety of tools such as J2RM."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-5",
              "text": "MEL supports more than 20 different file types, making it a versatile tool that aids pre-processing tasks as part of a KGCP based on comprehensive configurable settings."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-2",
      "subtitle": "Introduction",
      "paragraphs": [
        {
          "iri": "Section-2-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-1-Sentence-1",
              "text": "This paper introduces MEL, a tool that implements a set of methods to extract metadata and content-based information from various file formats as JSON objects."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-2",
              "text": "For each supported file type, MEL extracts the textual content from the source document and performs specific pre-processing and data cleaning tasks."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-3",
              "text": "Also, it performs basic text analysis tasks (pattern matching and keyword extraction) and generates the results in a machine-readable format (JSON), preparing the ground for content-based analysis."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-4",
              "text": "MEL is integrated with \u201cThe NLP -NER Toolkit\u201d (TNNT), which automates the extraction task of categorised named entities from the MEL results by using diverse state-of-the-art NLP tools and NER models [5]."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-5",
              "text": "MEL implements primitives for metadata and content extraction from unstructured data sets of heterogeneous formats, and along with the TNNT results, it provides the groundwork for content-based analysis."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-6",
              "text": "MEL and TNNT were developed in conjunction with J2RM [4], to easily map the JSON results to RDF as part of an automated KGCP."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-3",
      "subtitle": "Core Features",
      "paragraphs": [
        {
          "iri": "Section-3-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-1-Sentence-1",
              "text": "MEL has comprehensive metadata extraction support of various file types and formats."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-2",
              "text": "In a nutshell: (1) it takes as input a document (file) set; (2) then, for each document, it extracts its related metadata and content-based information, while performing basic text analysis (such as applying a configurable set of regular expressions and keyword extraction task); and, (3) as output, it generates a JSON file with the extracted metadata and text content with a structure based on the supported formats' document object model."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-3",
              "text": "It can store the results in a document store."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-4",
              "text": "MEL's general output structure is presented in Table 1."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-5",
              "text": "MEL has a detailed configuration JSON file that defines how the processing will be performed through a set of parameters and flags that establish the initial settings related to the document store, input document sets, TNNT general configuration, file extension mappings, the \u201cAssociated-Metadata\u201d processing (Table 1), and regular expressions to apply in the text analysis task, among other settings."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-6",
              "text": "The supported file types are presented in Table 2."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-7",
              "text": "The third column shows the theoretical number of attributes that the tool is able to extract per document type, whilst the fourth column shows the average of the extracted attributes from four use case document sets."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-8",
              "text": "OLE 2 file types and .docm can only be processed on Windows operating systems."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-9",
              "text": "Specifically for OLE 2 file types, MEL uses the olemeta tool."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-4",
      "subtitle": "Architecture",
      "paragraphs": [
        {
          "iri": "Section-4-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-1-Sentence-1",
              "text": "MEL is fully integrated with TNNT as depicted in Figure 1."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-2",
              "text": "The set of Python-based methods implemented in MEL are generic and can be applied to extract the content and metadata of all supported file types."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-3",
              "text": "MEL uses various opensource packages and tools with complementary capabilities to form a \u201cSwiss army knife\u201d of metadata and content-based information extraction from heterogeneous document sets."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-4",
              "text": "As part of the \u201cGeneral-Metadata\u201d extraction task, MEL optionally uses the XML output from the NLNZ Metadata Extractor tool, a Java standalone tool that extracts a comprehensive attribute and property list from dozens of file formats."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-5",
              "text": "The MEL general processing model is presented in Figure 2."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-6",
              "text": "It is important to note that each file type has its own specific processing model as well as the text analysis task, which is the last step that is performed for any output."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-5",
      "subtitle": "Related Work",
      "paragraphs": [
        {
          "iri": "Section-5-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-1-Sentence-1",
              "text": "The most comprehensive and current state-of-the-art tool for content extraction and analysis is Apache Tika, which is a complete and complex Java-based general-purpose system."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-2",
              "text": "While MEL's core goals resemble the ones of Apache Tika, the main difference and benefit of MEL as compared to Apache Tika is that it is a lightweight Python-based package for the metadata extraction of common file formats aimed to be used in a KGCP."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-3",
              "text": "Although there is a wide range of Python-based tools and libraries for metadata extraction, to the best of our knowledge, there is no package available that fully integrates in one system a comprehensive set of methods for metadata and content extraction of common file formats that generate the results in JSON structures based on the document object model of each format type."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-4",
              "text": "Last, MEL can assist in the information extraction stage of several KGCPs, such as the ones described in [6], [2], and [3]."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-6",
      "subtitle": "Conclusions and Future Work",
      "paragraphs": [
        {
          "iri": "Section-6-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-1-Sentence-1",
              "text": "MEL provides a versatile mechanism to extract metadata and content-based information from unstructured data sets of heterogeneous file formats, agnostic of the data sets' domain (general purpose)."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-2",
              "text": "It has been tested over thousands of documents using different formats and datasets as part of the AGRIF project."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-3",
              "text": "Based on the structure of the MEL's JSON results, it is possible to easily add a vocabulary or light-weight ontology using JSON-LD annotations, in order to make the extracted metadata \u201cRDF ready\u201d."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-4",
              "text": "This will be explored in the near future leveraging on the integration with JSON-LD ontologies."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-5",
              "text": "More file formats will be added in a per use-case requirements basis, in order to support KGCP tasks."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-6",
              "text": "Additionally, a project to \u201ccontainerise\u201d the MEL+TNNT tools is planned in the near future."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-7",
              "text": "The major contributions of this tool are: (1) the ability to extract metadata sets and content-based information from different source document formats; (2) the comprehensive support of over 20 different file types/formats integrated into one easy-to-use Python-based system; (3) integration with TNNT which automates the extraction of categorised named entities from the results by using diverse state-of-the-art NLP tools and NER models; and (4) the JSON result files can be easily mapped to RDF using J2RM."
            }
          ]
        }
      ]
    }
  ],
  "times": [
    0.0003337860107421875,
    110.86925196647644,
    153.49751615524292,
    203.9728820323944,
    0.7187011241912842,
    0.0007009506225585938,
    0.0010068416595458984,
    161.04543781280518,
    272.2694516181946,
    24.59865689277649,
    407.20268416404724,
    0.17461609840393066,
    0.0013680458068847656,
    175.19330096244812,
    0.0031518936157226562,
    0.27332305908203125,
    0.005604982376098633,
    100.48008227348328,
    133.15698885917664,
    203.1566309928894,
    238.86971783638,
    33.11128902435303,
    471.9618299007416,
    35.922046184539795,
    0.012918949127197266,
    0.12509584426879883
  ],
  "nodes": {
    "Entity-mel": {
      "node_id": "mel",
      "disambiguation_index": 0,
      "label": "MEL",
      "aliases": [
        "the tool",
        "a Python-based tool",
        "this tool",
        "MEL"
      ],
      "types": [
        "organization",
        "model",
        "software",
        "project",
        "tool",
        "method",
        "metadata",
        "package",
        "metadata extraction tool",
        "system",
        "Python-based tool",
        "acronym",
        "entity",
        "metadata extraction"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "MEL is a Python-based tool designed for extracting metadata and content-based information from unstructured data in various document formats, facilitating pre-processing tasks in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software",
            "Python-based tool"
          ],
          "iri": "Entity-mel-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "system",
            "software"
          ],
          "iri": "Entity-mel-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "system"
          ],
          "iri": "Entity-mel-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "system",
            "software"
          ],
          "iri": "Entity-mel-Mention-6"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "MEL",
          "local_types": [
            "software",
            "tool",
            "system",
            "acronym",
            "entity"
          ],
          "iri": "Entity-mel-Mention-7"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "metadata extraction tool",
            "software",
            "metadata extraction"
          ],
          "iri": "Entity-mel-Mention-8"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "model",
            "system"
          ],
          "iri": "Entity-mel-Mention-9"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "MEL",
          "local_types": [
            "system",
            "software"
          ],
          "iri": "Entity-mel-Mention-10"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-11"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "software",
            "tool",
            "metadata extraction tool",
            "system",
            "model",
            "metadata extraction"
          ],
          "iri": "Entity-mel-Mention-12"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "MEL",
          "local_types": [
            "method",
            "system",
            "software",
            "tool"
          ],
          "iri": "Entity-mel-Mention-13"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "system",
            "software"
          ],
          "iri": "Entity-mel-Mention-14"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "organization",
            "tool",
            "metadata extraction tool",
            "project"
          ],
          "iri": "Entity-mel-Mention-15"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "metadata extraction tool",
            "software",
            "package"
          ],
          "iri": "Entity-mel-Mention-16"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "system"
          ],
          "iri": "Entity-mel-Mention-17"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "MEL",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-18"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "MEL",
          "local_types": [
            "metadata",
            "system",
            "metadata extraction tool"
          ],
          "iri": "Entity-mel-Mention-19"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "a Python-based tool",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-mel-Mention-20"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "the tool",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-mel-Mention-21"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "this tool",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-mel-Mention-22"
        }
      ],
      "relevance": 0.82958984375
    },
    "Entity-this_paper": {
      "node_id": "this_paper",
      "disambiguation_index": 0,
      "label": "This paper",
      "aliases": [
        "This paper"
      ],
      "types": [
        "paper",
        "research"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "This paper refers to the research work that introduces MEL, a Python-based tool designed for extracting metadata and content-based information from various unstructured document formats, facilitating pre-processing in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "This paper",
          "local_types": [
            "research"
          ],
          "iri": "Entity-this_paper-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "This paper",
          "local_types": [
            "paper"
          ],
          "iri": "Entity-this_paper-Mention-2"
        }
      ],
      "relevance": 0.81689453125
    },
    "Entity-method_to_extract_metadata_and_content-based_information": {
      "node_id": "method_to_extract_metadata_and_content-based_information",
      "disambiguation_index": 0,
      "label": "methods to extract metadata and content-based information",
      "aliases": [
        "methods to extract metadata and content-based information"
      ],
      "types": [
        "method",
        "information extraction"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The entity 'methods to extract metadata and content-based information' refers to the techniques implemented in the MEL tool, which is designed to process unstructured data from various document formats to extract relevant metadata and content information for use in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "methods to extract metadata and content-based information",
          "local_types": [
            "method",
            "information extraction"
          ],
          "iri": "Entity-method_to_extract_metadata_and_content-based_information-Mention-1"
        }
      ],
      "relevance": 0.771484375
    },
    "Entity-extracted_metadata_and_text_content": {
      "node_id": "extracted_metadata_and_text_content",
      "disambiguation_index": 0,
      "label": "extracted metadata and text content",
      "aliases": [
        "extracted metadata and text content"
      ],
      "types": [
        "metadata",
        "text content"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'extracted metadata and text content' refers to the information derived from various document types, including structured metadata and textual data, which is processed and outputted in a JSON format by the MEL tool as part of its functionality to facilitate knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "extracted metadata and text content",
          "local_types": [
            "metadata",
            "text content"
          ],
          "iri": "Entity-extracted_metadata_and_text_content-Mention-1"
        }
      ],
      "relevance": 0.7685546875
    },
    "Entity-mel_s_json_result": {
      "node_id": "mel_s_json_result",
      "disambiguation_index": 0,
      "label": "MEL's JSON results",
      "aliases": [
        "MEL's JSON results"
      ],
      "types": [
        "metadata",
        "results",
        "result"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "MEL's JSON results refer to the structured output files generated by the MEL tool, which contain extracted metadata and content-based information from various unstructured document formats, formatted in JSON to facilitate integration with RDF and support for knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "MEL's JSON results",
          "local_types": [
            "metadata",
            "results",
            "result"
          ],
          "iri": "Entity-mel_s_json_result-Mention-1"
        }
      ],
      "relevance": 0.7646484375
    },
    "Entity-meltnnt": {
      "node_id": "meltnnt",
      "disambiguation_index": 0,
      "label": "MEL+TNNT",
      "aliases": [
        "MEL+TNNT tools",
        "MEL+TNNT"
      ],
      "types": [
        "tool",
        "software",
        "tools"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "MEL+TNNT refers to a combined toolset that integrates MEL, a Python-based metadata extractor and loader, with TNNT, which automates the extraction of categorized named entities using advanced NLP tools and NER models.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "MEL+TNNT",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-meltnnt-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "MEL+TNNT tools",
          "local_types": [
            "tool",
            "software",
            "tools"
          ],
          "iri": "Entity-meltnnt-Mention-2"
        }
      ],
      "relevance": 0.76416015625
    },
    "Entity-package": {
      "node_id": "package",
      "disambiguation_index": 0,
      "label": "package",
      "aliases": [
        "package"
      ],
      "types": [
        "package",
        "software package",
        "software",
        "library"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'package' refers to MEL, a lightweight Python-based software package designed for the metadata extraction of common file formats, integrating various methods to produce results in JSON format for use in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "package",
          "local_types": [
            "package",
            "software package",
            "software",
            "library"
          ],
          "iri": "Entity-package-Mention-1"
        }
      ],
      "relevance": 0.7587890625
    },
    "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction": {
      "node_id": "comprehensive_set_of_method_for_metadata_and_content_extraction",
      "disambiguation_index": 0,
      "label": "comprehensive set of methods for metadata and content extraction",
      "aliases": [
        "comprehensive set of methods for metadata and content extraction"
      ],
      "types": [
        "methods",
        "metadata extraction",
        "content extraction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'comprehensive set of methods for metadata and content extraction' refers to a unified system within the MEL tool that integrates various techniques for extracting metadata and content from common file formats, producing structured JSON outputs based on the document object model of each format.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "comprehensive set of methods for metadata and content extraction",
          "local_types": [
            "methods",
            "metadata extraction",
            "content extraction"
          ],
          "iri": "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction-Mention-1"
        }
      ],
      "relevance": 0.75830078125
    },
    "Entity-output_set": {
      "node_id": "output_set",
      "disambiguation_index": 0,
      "label": "output set",
      "aliases": [
        "output set",
        "rich output set"
      ],
      "types": [
        "set",
        "results",
        "output",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'output set' refers to the rich results generated by the MEL tool, which includes extracted metadata and content-based information from various unstructured document formats, formatted as JSON files for further use in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "output set",
          "local_types": [
            "data",
            "results"
          ],
          "iri": "Entity-output_set-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "rich output set",
          "local_types": [
            "output",
            "set"
          ],
          "iri": "Entity-output_set-Mention-2"
        }
      ],
      "relevance": 0.740234375
    },
    "Entity-comprehensive_metadata_extraction_support": {
      "node_id": "comprehensive_metadata_extraction_support",
      "disambiguation_index": 0,
      "label": "comprehensive metadata extraction support",
      "aliases": [
        "comprehensive metadata extraction support"
      ],
      "types": [
        "feature"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Comprehensive metadata extraction support refers to MEL's capability to efficiently extract and process metadata and content-based information from a wide range of file types and formats, facilitating the pre-processing tasks necessary for Knowledge Graph Construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "comprehensive metadata extraction support",
          "local_types": [
            "feature"
          ],
          "iri": "Entity-comprehensive_metadata_extraction_support-Mention-1"
        }
      ],
      "relevance": 0.73828125
    },
    "Entity-related_metadata_and_content-based_information": {
      "node_id": "related_metadata_and_content-based_information",
      "disambiguation_index": 0,
      "label": "related metadata and content-based information",
      "aliases": [
        "related metadata and content-based information"
      ],
      "types": [
        "metadata",
        "content"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The phrase 'related metadata and content-based information' refers to the specific data extracted from documents by the MEL tool, which includes both descriptive metadata about the documents and the actual textual content, processed through various text analysis techniques to facilitate knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "related metadata and content-based information",
          "local_types": [
            "metadata",
            "content"
          ],
          "iri": "Entity-related_metadata_and_content-based_information-Mention-1"
        }
      ],
      "relevance": 0.73388671875
    },
    "Entity-mel_general_processing_model": {
      "node_id": "mel_general_processing_model",
      "disambiguation_index": 0,
      "label": "MEL general processing model",
      "aliases": [
        "MEL general processing model",
        "The MEL general processing model"
      ],
      "types": [
        "model",
        "concept",
        "processing",
        "theoretical framework"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The MEL general processing model refers to a theoretical framework that outlines the systematic approach and methods used by the MEL tool for extracting metadata and content from various file types in the context of knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "MEL general processing model",
          "local_types": [
            "model",
            "concept",
            "processing",
            "theoretical framework"
          ],
          "iri": "Entity-mel_general_processing_model-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "The MEL general processing model",
          "local_types": [
            "model"
          ],
          "iri": "Entity-mel_general_processing_model-Mention-2"
        }
      ],
      "relevance": 0.7314453125
    },
    "Entity-content": {
      "node_id": "content",
      "disambiguation_index": 0,
      "label": "content",
      "aliases": [
        "content"
      ],
      "types": [
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'content' refers to the information extracted from various supported file types, which includes both the textual and structural data present in unstructured documents.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "content",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-Mention-1"
        }
      ],
      "relevance": 0.7314453125
    },
    "Entity-a_set_of_method": {
      "node_id": "a_set_of_method",
      "disambiguation_index": 0,
      "label": "a set of methods",
      "aliases": [
        "a set of methods"
      ],
      "types": [
        "methods"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A set of methods refers to the various techniques and processes implemented by the MEL tool to extract metadata and content-based information from diverse file formats, enabling the generation of structured JSON outputs for further analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "a set of methods",
          "local_types": [
            "methods"
          ],
          "iri": "Entity-a_set_of_method-Mention-1"
        }
      ],
      "relevance": 0.728515625
    },
    "Entity-table_1": {
      "node_id": "table_1",
      "disambiguation_index": 0,
      "label": "Table 1",
      "aliases": [
        "Table 1"
      ],
      "types": [
        "data presentation",
        "table",
        "data representation",
        "reference"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Table 1 presents the general output structure of the MEL tool, which details how extracted metadata and content-based information are organized in the generated JSON files.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "Table 1",
          "local_types": [
            "data presentation",
            "table",
            "data representation",
            "reference"
          ],
          "iri": "Entity-table_1-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "Table 1",
          "local_types": [
            "table",
            "data representation"
          ],
          "iri": "Entity-table_1-Mention-2"
        }
      ],
      "relevance": 0.71826171875
    },
    "Entity-document__file__set": {
      "node_id": "document__file__set",
      "disambiguation_index": 0,
      "label": "document (file) set",
      "aliases": [
        "document (file) set",
        "a document (file) set"
      ],
      "types": [
        "file set",
        "document"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'document (file) set' refers to a collection of various file types and formats that are input into the MEL tool for the purpose of extracting metadata and content-based information.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "document (file) set",
          "local_types": [
            "document",
            "file set"
          ],
          "iri": "Entity-document__file__set-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "a document (file) set",
          "local_types": [
            "document",
            "file set"
          ],
          "iri": "Entity-document__file__set-Mention-2"
        }
      ],
      "relevance": 0.71533203125
    },
    "Entity-different_source_document_format": {
      "node_id": "different_source_document_format",
      "disambiguation_index": 0,
      "label": "different source document formats",
      "aliases": [
        "different source document formats"
      ],
      "types": [
        "document format"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Different source document formats refer to the various types of file formats from which the MEL tool can extract metadata and content-based information, supporting over 20 distinct file types to facilitate knowledge graph construction and data preprocessing tasks.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "different source document formats",
          "local_types": [
            "document format"
          ],
          "iri": "Entity-different_source_document_format-Mention-1"
        }
      ],
      "relevance": 0.7109375
    },
    "Entity-primitive_for_metadata_and_content_extraction": {
      "node_id": "primitive_for_metadata_and_content_extraction",
      "disambiguation_index": 0,
      "label": "primitives for metadata and content extraction",
      "aliases": [
        "primitives for metadata and content extraction"
      ],
      "types": [
        "methodology"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Primitives for metadata and content extraction refer to the foundational methods and techniques implemented in the MEL tool that facilitate the extraction of structured metadata and content from unstructured data sets across various file formats, enabling subsequent content-based analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "primitives for metadata and content extraction",
          "local_types": [
            "methodology"
          ],
          "iri": "Entity-primitive_for_metadata_and_content_extraction-Mention-1"
        }
      ],
      "relevance": 0.703125
    },
    "Entity-output_structure": {
      "node_id": "output_structure",
      "disambiguation_index": 0,
      "label": "output structure",
      "aliases": [
        "MEL's general output structure",
        "output structure"
      ],
      "types": [
        "information representation",
        "output",
        "data format",
        "output structure",
        "structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'output structure' refers to the organized format in which MEL generates and presents the extracted metadata and content-based information from documents, specifically formatted as JSON files based on the document object model of the supported file types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "output structure",
          "local_types": [
            "information representation",
            "structure",
            "output",
            "data format"
          ],
          "iri": "Entity-output_structure-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-4",
          "local_name": "MEL's general output structure",
          "local_types": [
            "output structure"
          ],
          "iri": "Entity-output_structure-Mention-2"
        }
      ],
      "relevance": 0.70166015625
    },
    "Entity-the_nlp_-ner_toolkit": {
      "node_id": "the_nlp_-ner_toolkit",
      "disambiguation_index": 0,
      "label": "The NLP -NER Toolkit",
      "aliases": [
        "The NLP -NER Toolkit",
        "TNNT"
      ],
      "types": [
        "software",
        "tool",
        "system",
        "toolkit",
        "acronym",
        "entity",
        "model"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "The NLP -NER Toolkit (TNNT) is a software tool that automates the extraction of categorized named entities from metadata and content extracted by the MEL tool, utilizing various advanced natural language processing (NLP) techniques and named entity recognition (NER) models.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "The NLP -NER Toolkit",
          "local_types": [
            "tool",
            "software",
            "toolkit"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "TNNT",
          "local_types": [
            "system",
            "tool"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "TNNT",
          "local_types": [
            "software",
            "tool",
            "system",
            "acronym",
            "entity"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "TNNT",
          "local_types": [
            "model",
            "tool",
            "system",
            "software"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-4"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "TNNT",
          "local_types": [
            "tool",
            "system",
            "software"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-5"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "TNNT",
          "local_types": [
            "tool",
            "software",
            "toolkit"
          ],
          "iri": "Entity-the_nlp_-ner_toolkit-Mention-6"
        }
      ],
      "relevance": 0.701171875
    },
    "Entity-format": {
      "node_id": "format",
      "disambiguation_index": 0,
      "label": "formats",
      "aliases": [
        "different formats",
        "formats",
        "various file formats",
        "different source document formats"
      ],
      "types": [
        "format",
        "document format",
        "data format",
        "file format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The term 'formats' refers to the various types of source document formats that the MEL tool can process for metadata and content-based information extraction, supporting over 20 different file types.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "formats",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-format-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "different source document formats",
          "local_types": [
            "document format",
            "format"
          ],
          "iri": "Entity-format-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "various file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-format-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "different formats",
          "local_types": [
            "format"
          ],
          "iri": "Entity-format-Mention-4"
        }
      ],
      "relevance": 0.69482421875
    },
    "Entity-each_file_type": {
      "node_id": "each_file_type",
      "disambiguation_index": 0,
      "label": "each file type",
      "aliases": [
        "each file type"
      ],
      "types": [
        "file type"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Each file type refers to the distinct formats of documents that MEL can process, each requiring a tailored processing model and text analysis approach for effective metadata and content extraction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "each file type",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-each_file_type-Mention-1"
        }
      ],
      "relevance": 0.69482421875
    },
    "Entity-input_document_set": {
      "node_id": "input_document_set",
      "disambiguation_index": 0,
      "label": "input document sets",
      "aliases": [
        "input document sets"
      ],
      "types": [
        "input data",
        "input",
        "document",
        "data collection"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Input document sets refer to collections of documents that are processed by the MEL tool to extract metadata and content-based information as part of a knowledge graph construction pipeline.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "input document sets",
          "local_types": [
            "input data",
            "input",
            "document",
            "data collection"
          ],
          "iri": "Entity-input_document_set-Mention-1"
        }
      ],
      "relevance": 0.6943359375
    },
    "Entity-associated-metadata": {
      "node_id": "associated-metadata",
      "disambiguation_index": 0,
      "label": "Associated-Metadata",
      "aliases": [
        "Associated-Metadata"
      ],
      "types": [
        "metadata",
        "data descriptor"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Associated-Metadata refers to a specific processing component within the MEL tool's configuration that defines how metadata related to input documents is extracted and structured in the output JSON files.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "Associated-Metadata",
          "local_types": [
            "metadata",
            "data descriptor"
          ],
          "iri": "Entity-associated-metadata-Mention-1"
        }
      ],
      "relevance": 0.6943359375
    },
    "Entity-processing_model": {
      "node_id": "processing_model",
      "disambiguation_index": 0,
      "label": "processing model",
      "aliases": [
        "processing model"
      ],
      "types": [
        "algorithm",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The processing model refers to the specific set of methods and procedures tailored for each file type within the MEL tool, which facilitates the extraction of metadata and content-based information as part of the overall data processing workflow.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "processing model",
          "local_types": [
            "algorithm",
            "system"
          ],
          "iri": "Entity-processing_model-Mention-1"
        }
      ],
      "relevance": 0.69287109375
    },
    "Entity-more_than_20_different_file_type": {
      "node_id": "more_than_20_different_file_type",
      "disambiguation_index": 0,
      "label": "more than 20 different file types",
      "aliases": [
        "more than 20 different file types",
        "over 20 different file types/formats"
      ],
      "types": [
        "file type",
        "format"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'more than 20 different file types' refers to the diverse range of document formats that the MEL tool can process for metadata and content-based information extraction in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "more than 20 different file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-more_than_20_different_file_type-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "over 20 different file types/formats",
          "local_types": [
            "file type",
            "format"
          ],
          "iri": "Entity-more_than_20_different_file_type-Mention-2"
        }
      ],
      "relevance": 0.69189453125
    },
    "Entity-specific_pre-processing_and_data_cleaning_task": {
      "node_id": "specific_pre-processing_and_data_cleaning_task",
      "disambiguation_index": 0,
      "label": "specific pre-processing and data cleaning tasks",
      "aliases": [
        "specific pre-processing and data cleaning tasks"
      ],
      "types": [
        "process",
        "data cleaning"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Specific pre-processing and data cleaning tasks refer to the operations performed by the MEL tool to prepare and refine the extracted textual content from various file formats, ensuring the data is clean and suitable for subsequent analysis and integration into knowledge graph construction pipelines.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "specific pre-processing and data cleaning tasks",
          "local_types": [
            "process",
            "data cleaning"
          ],
          "iri": "Entity-specific_pre-processing_and_data_cleaning_task-Mention-1"
        }
      ],
      "relevance": 0.6884765625
    },
    "Entity-20_different_file_type": {
      "node_id": "20_different_file_type",
      "disambiguation_index": 0,
      "label": "20 different file types",
      "aliases": [
        "20 different file types"
      ],
      "types": [
        "file type",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The mention '20 different file types' refers to the variety of document formats that the MEL tool can process for metadata and content extraction in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "20 different file types",
          "local_types": [
            "file type",
            "data format"
          ],
          "iri": "Entity-20_different_file_type-Mention-1"
        }
      ],
      "relevance": 0.6875
    },
    "Entity-document": {
      "node_id": "document",
      "disambiguation_index": 0,
      "label": "document",
      "aliases": [
        "documents",
        "document"
      ],
      "types": [
        "data",
        "data object",
        "data structure",
        "file",
        "document",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'document' refers to a file or set of files from which MEL extracts metadata and content-based information for processing in knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "document",
          "local_types": [
            "data structure",
            "file",
            "data object",
            "document"
          ],
          "iri": "Entity-document-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "documents",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-document-Mention-2"
        }
      ],
      "relevance": 0.6875
    },
    "Entity-any_output": {
      "node_id": "any_output",
      "disambiguation_index": 0,
      "label": "any output",
      "aliases": [
        "any output"
      ],
      "types": [
        "output"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'any output' refers to the final results generated after processing various file types and performing text analysis, which can be stored in JSON format and utilized in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "any output",
          "local_types": [
            "output"
          ],
          "iri": "Entity-any_output-Mention-1"
        }
      ],
      "relevance": 0.685546875
    },
    "Entity-automated_kgcp": {
      "node_id": "automated_kgcp",
      "disambiguation_index": 0,
      "label": "automated KGCP",
      "aliases": [
        "automated KGCP"
      ],
      "types": [
        "process",
        "system"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The automated KGCP refers to a Knowledge Graph Construction Pipeline that utilizes automated processes and tools, such as MEL and TNNT, to streamline the extraction and mapping of metadata and content from various file formats into a machine-readable format for knowledge graph development.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "automated KGCP",
          "local_types": [
            "process",
            "system"
          ],
          "iri": "Entity-automated_kgcp-Mention-1"
        }
      ],
      "relevance": 0.6845703125
    },
    "Entity-general-metadata": {
      "node_id": "general-metadata",
      "disambiguation_index": 0,
      "label": "General-Metadata",
      "aliases": [
        "General-Metadata"
      ],
      "types": [
        "task"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "General-Metadata refers to the extraction task within the MEL tool that utilizes XML output from the NLNZ Metadata Extractor to obtain a comprehensive list of attributes and properties from various file formats.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "General-Metadata",
          "local_types": [
            "task"
          ],
          "iri": "Entity-general-metadata-Mention-1"
        }
      ],
      "relevance": 0.68408203125
    },
    "Entity-metadata_and_content-based_information_extraction": {
      "node_id": "metadata_and_content-based_information_extraction",
      "disambiguation_index": 0,
      "label": "metadata and content-based information extraction",
      "aliases": [
        "metadata and content-based information extraction"
      ],
      "types": [
        "process",
        "information extraction"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Metadata and content-based information extraction refers to the process of extracting structured metadata and relevant content information from diverse unstructured document formats, facilitating data preprocessing for knowledge graph construction and enhancing the integration of various extraction methods.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "metadata and content-based information extraction",
          "local_types": [
            "process",
            "information extraction"
          ],
          "iri": "Entity-metadata_and_content-based_information_extraction-Mention-1"
        }
      ],
      "relevance": 0.68359375
    },
    "Entity-it": {
      "node_id": "it",
      "disambiguation_index": 0,
      "label": "It",
      "aliases": [
        "It"
      ],
      "types": [
        "entity"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'It' refers to the MEL tool, which is capable of storing the results of its metadata and content extraction processes in a document store.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "It",
          "local_types": [
            "entity"
          ],
          "iri": "Entity-it-Mention-1"
        }
      ],
      "relevance": 0.68310546875
    },
    "Entity-a_project_to__containerise__the_meltnnt_tool": {
      "node_id": "a_project_to__containerise__the_meltnnt_tool",
      "disambiguation_index": 0,
      "label": "a project to \u201ccontainerise\u201d the MEL+TNNT tools",
      "aliases": [
        "a project to \u201ccontainerise\u201d the MEL+TNNT tools"
      ],
      "types": [
        "project",
        "tools"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "A project aimed at packaging the MEL and TNNT tools into containerized environments to enhance their deployment and usability in metadata extraction and named entity recognition tasks.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "a project to \u201ccontainerise\u201d the MEL+TNNT tools",
          "local_types": [
            "project",
            "tools"
          ],
          "iri": "Entity-a_project_to__containerise__the_meltnnt_tool-Mention-1"
        }
      ],
      "relevance": 0.6826171875
    },
    "Entity-keyword_extraction_task": {
      "node_id": "keyword_extraction_task",
      "disambiguation_index": 0,
      "label": "keyword extraction task",
      "aliases": [
        "keyword extraction task"
      ],
      "types": [
        "task",
        "keyword extraction"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The keyword extraction task refers to a process within the MEL tool that involves analyzing documents to identify and extract significant words or phrases that represent the main topics or themes, contributing to the overall metadata and content-based information extraction from various file types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "keyword extraction task",
          "local_types": [
            "task",
            "keyword extraction"
          ],
          "iri": "Entity-keyword_extraction_task-Mention-1"
        }
      ],
      "relevance": 0.68115234375
    },
    "Entity-a_json_file": {
      "node_id": "a_json_file",
      "disambiguation_index": 0,
      "label": "a JSON file",
      "aliases": [
        "a JSON file"
      ],
      "types": [
        "file",
        "JSON"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A JSON file is a structured text file that stores extracted metadata and content-based information in a format compliant with the document object model, generated as output by the MEL tool during the metadata extraction process from various document types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "a JSON file",
          "local_types": [
            "file",
            "JSON"
          ],
          "iri": "Entity-a_json_file-Mention-1"
        }
      ],
      "relevance": 0.68115234375
    },
    "Entity-processing": {
      "node_id": "processing",
      "disambiguation_index": 0,
      "label": "processing",
      "aliases": [
        "processing"
      ],
      "types": [
        "process"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In this context, 'processing' refers to the execution of a defined set of operations and configurations applied to document sets for extracting metadata and content-based information using the MEL tool.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "processing",
          "local_types": [
            "process"
          ],
          "iri": "Entity-processing-Mention-1"
        }
      ],
      "relevance": 0.67919921875
    },
    "Entity-extracted_metadata": {
      "node_id": "extracted_metadata",
      "disambiguation_index": 0,
      "label": "extracted metadata",
      "aliases": [
        "extracted metadata"
      ],
      "types": [
        "metadata"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Extracted metadata refers to the structured information derived from unstructured data sets of various file formats, which can be formatted as JSON and made compatible with RDF through JSON-LD annotations, facilitating its use in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "extracted metadata",
          "local_types": [
            "metadata"
          ],
          "iri": "Entity-extracted_metadata-Mention-1"
        }
      ],
      "relevance": 0.6767578125
    },
    "Entity-figure_2": {
      "node_id": "figure_2",
      "disambiguation_index": 0,
      "label": "Figure 2",
      "aliases": [
        "Figure 2"
      ],
      "types": [
        "illustration",
        "figure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Figure 2 illustrates the general processing model of the MEL tool, which outlines the methodology for extracting metadata and content from various supported file types.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-5",
          "local_name": "Figure 2",
          "local_types": [
            "illustration",
            "figure"
          ],
          "iri": "Entity-figure_2-Mention-1"
        }
      ],
      "relevance": 0.67529296875
    },
    "Entity-tnnt_result": {
      "node_id": "tnnt_result",
      "disambiguation_index": 0,
      "label": "TNNT results",
      "aliases": [
        "TNNT results"
      ],
      "types": [
        "results",
        "output",
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "TNNT results refer to the output generated by 'The NLP -NER Toolkit', which automates the extraction of categorized named entities from the metadata and content extracted by the MEL tool.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "TNNT results",
          "local_types": [
            "results",
            "output",
            "data",
            "information"
          ],
          "iri": "Entity-tnnt_result-Mention-1"
        }
      ],
      "relevance": 0.67431640625
    },
    "Entity-parameter": {
      "node_id": "parameter",
      "disambiguation_index": 0,
      "label": "parameters",
      "aliases": [
        "parameters",
        "settings"
      ],
      "types": [
        "configuration",
        "settings",
        "configuration element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'parameters' refer to the configurable settings defined in a JSON file that dictate how metadata extraction and processing tasks are performed, including document store configurations, input document sets, and text analysis methods.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "parameters",
          "local_types": [
            "settings",
            "configuration element"
          ],
          "iri": "Entity-parameter-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "settings",
          "local_types": [
            "configuration",
            "settings"
          ],
          "iri": "Entity-parameter-Mention-2"
        }
      ],
      "relevance": 0.67431640625
    },
    "Entity-heterogeneous_format": {
      "node_id": "heterogeneous_format",
      "disambiguation_index": 0,
      "label": "heterogeneous formats",
      "aliases": [
        "heterogeneous formats",
        "heterogeneous file formats"
      ],
      "types": [
        "data type",
        "file format",
        "data format",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Heterogeneous formats refer to the various unstructured data types and file formats that MEL can process for metadata and content extraction, enabling the integration and analysis of diverse information sources.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "heterogeneous formats",
          "local_types": [
            "data type",
            "data format",
            "format"
          ],
          "iri": "Entity-heterogeneous_format-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "heterogeneous file formats",
          "local_types": [
            "data format",
            "file format"
          ],
          "iri": "Entity-heterogeneous_format-Mention-2"
        }
      ],
      "relevance": 0.67236328125
    },
    "Entity-supported_format__document_object_model": {
      "node_id": "supported_format__document_object_model",
      "disambiguation_index": 0,
      "label": "supported formats' document object model",
      "aliases": [
        "supported formats' document object model"
      ],
      "types": [
        "document object model",
        "format"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The 'supported formats' document object model' refers to the structured representation of metadata and content extracted from various document types by the MEL tool, which organizes this information in a JSON format tailored to the specific characteristics of each supported file format.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "supported formats' document object model",
          "local_types": [
            "document object model",
            "format"
          ],
          "iri": "Entity-supported_format__document_object_model-Mention-1"
        }
      ],
      "relevance": 0.669921875
    },
    "Entity-result_in_a_machine-readable_format": {
      "node_id": "result_in_a_machine-readable_format",
      "disambiguation_index": 0,
      "label": "results in a machine-readable format",
      "aliases": [
        "JSON results",
        "results in a machine-readable format"
      ],
      "types": [
        "results",
        "data format",
        "format"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'results in a machine-readable format' refers to the output generated by the MEL tool, specifically in the form of JSON files, which facilitates easy processing and analysis of extracted metadata and content from various file formats.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "results in a machine-readable format",
          "local_types": [
            "results",
            "format"
          ],
          "iri": "Entity-result_in_a_machine-readable_format-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "JSON results",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-result_in_a_machine-readable_format-Mention-2"
        }
      ],
      "relevance": 0.66748046875
    },
    "Entity-attribute": {
      "node_id": "attribute",
      "disambiguation_index": 0,
      "label": "attributes",
      "aliases": [
        "attributes"
      ],
      "types": [
        "metadata",
        "data",
        "features",
        "characteristics"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'attributes' refer to the specific pieces of metadata and content-based information that can be extracted from various document types during the metadata extraction process.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "attributes",
          "local_types": [
            "metadata",
            "data",
            "features",
            "characteristics"
          ],
          "iri": "Entity-attribute-Mention-1"
        }
      ],
      "relevance": 0.66650390625
    },
    "Entity-metadata_and_content-based_information": {
      "node_id": "metadata_and_content-based_information",
      "disambiguation_index": 0,
      "label": "metadata and content-based information",
      "aliases": [
        "metadata and content-based information"
      ],
      "types": [
        "metadata",
        "information"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Metadata and content-based information refers to the structured and unstructured data extracted from various document formats, which is essential for pre-processing in Knowledge Graph Construction Pipelines, enabling the organization and analysis of information for further use.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "metadata and content-based information",
          "local_types": [
            "information"
          ],
          "iri": "Entity-metadata_and_content-based_information-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "metadata and content-based information",
          "local_types": [
            "information"
          ],
          "iri": "Entity-metadata_and_content-based_information-Mention-2"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "metadata and content-based information",
          "local_types": [
            "metadata",
            "information"
          ],
          "iri": "Entity-metadata_and_content-based_information-Mention-3"
        }
      ],
      "relevance": 0.6650390625
    },
    "Entity-a_versatile_mechanism": {
      "node_id": "a_versatile_mechanism",
      "disambiguation_index": 0,
      "label": "a versatile mechanism",
      "aliases": [
        "a versatile mechanism"
      ],
      "types": [
        "mechanism"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'a versatile mechanism' refers to the functionality of the MEL tool, which enables the extraction of metadata and content-based information from a wide variety of unstructured data sets across different file formats, regardless of their specific domain.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "a versatile mechanism",
          "local_types": [
            "mechanism"
          ],
          "iri": "Entity-a_versatile_mechanism-Mention-1"
        }
      ],
      "relevance": 0.6650390625
    },
    "Entity-output": {
      "node_id": "output",
      "disambiguation_index": 0,
      "label": "output",
      "aliases": [
        "results",
        "output",
        "MEL results",
        "The results"
      ],
      "types": [
        "data",
        "results",
        "result",
        "data output"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "In this context, 'output' refers to the final results generated by the MEL tool after processing various file types and performing text analysis, which are produced in a structured format suitable for further use.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "output",
          "local_types": [
            "result",
            "data output"
          ],
          "iri": "Entity-output-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "The results",
          "local_types": [
            "results"
          ],
          "iri": "Entity-output-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "MEL results",
          "local_types": [
            "results"
          ],
          "iri": "Entity-output-Mention-3"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "results",
          "local_types": [
            "data"
          ],
          "iri": "Entity-output-Mention-4"
        }
      ],
      "relevance": 0.66455078125
    },
    "Entity-the_integration_with_json-ld_ontology": {
      "node_id": "the_integration_with_json-ld_ontology",
      "disambiguation_index": 0,
      "label": "the integration with JSON-LD ontologies",
      "aliases": [
        "the integration with JSON-LD ontologies"
      ],
      "types": [
        "integration",
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The integration with JSON-LD ontologies refers to the process of enhancing the metadata extracted by the MEL tool by incorporating JSON-LD annotations, which facilitate the transformation of the extracted data into a format compatible with Resource Description Framework (RDF) for improved interoperability and semantic understanding.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "the integration with JSON-LD ontologies",
          "local_types": [
            "integration",
            "ontology"
          ],
          "iri": "Entity-the_integration_with_json-ld_ontology-Mention-1"
        }
      ],
      "relevance": 0.66455078125
    },
    "Entity-thousand_of_document": {
      "node_id": "thousand_of_document",
      "disambiguation_index": 0,
      "label": "thousands of documents",
      "aliases": [
        "thousands of documents"
      ],
      "types": [
        "documents"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'thousands of documents' refers to a large collection of heterogeneous file formats that were utilized in the testing of the MEL tool for metadata and content-based information extraction as part of the AGRIF project.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "thousands of documents",
          "local_types": [
            "documents"
          ],
          "iri": "Entity-thousand_of_document-Mention-1"
        }
      ],
      "relevance": 0.66015625
    },
    "Entity-pre-processing_step": {
      "node_id": "pre-processing_step",
      "disambiguation_index": 0,
      "label": "pre-processing steps",
      "aliases": [
        "pre-processing steps"
      ],
      "types": [
        "process",
        "step"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Pre-processing steps refer to the initial tasks of extracting metadata and content-based information from diverse file sets, which are essential for the effective functioning of Knowledge Graph Construction Pipelines (KGCP).",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "pre-processing steps",
          "local_types": [
            "process",
            "step"
          ],
          "iri": "Entity-pre-processing_step-Mention-1"
        }
      ],
      "relevance": 0.6591796875
    },
    "Entity-specific_processing_model": {
      "node_id": "specific_processing_model",
      "disambiguation_index": 0,
      "label": "specific processing model",
      "aliases": [
        "specific processing model"
      ],
      "types": [
        "processing model"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'specific processing model' refers to the tailored methodologies employed by the MEL tool to handle and extract metadata and content from various file types, ensuring that each type is processed according to its unique characteristics and requirements.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "specific processing model",
          "local_types": [
            "processing model"
          ],
          "iri": "Entity-specific_processing_model-Mention-1"
        }
      ],
      "relevance": 0.65771484375
    },
    "Entity-various_file_type_and_format": {
      "node_id": "various_file_type_and_format",
      "disambiguation_index": 0,
      "label": "various file types and formats",
      "aliases": [
        "The supported file types",
        "all supported file types",
        "various file types and formats"
      ],
      "types": [
        "file type",
        "format"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'various file types and formats' refers to the diverse categories and structures of digital documents that MEL can process for metadata extraction, encompassing over 20 different formats to facilitate information retrieval and analysis.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "various file types and formats",
          "local_types": [
            "file type",
            "format"
          ],
          "iri": "Entity-various_file_type_and_format-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "The supported file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-various_file_type_and_format-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "all supported file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-various_file_type_and_format-Mention-3"
        }
      ],
      "relevance": 0.65673828125
    },
    "Entity-metadata_and_content-based_information_extraction_task": {
      "node_id": "metadata_and_content-based_information_extraction_task",
      "disambiguation_index": 0,
      "label": "metadata and content-based information extraction tasks",
      "aliases": [
        "metadata and content-based information extraction tasks"
      ],
      "types": [
        "information extraction",
        "task"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Metadata and content-based information extraction tasks refer to the pre-processing activities that involve extracting structured metadata and relevant content from diverse unstructured document formats, which are essential for the effective construction of Knowledge Graphs.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "metadata and content-based information extraction tasks",
          "local_types": [
            "information extraction",
            "task"
          ],
          "iri": "Entity-metadata_and_content-based_information_extraction_task-Mention-1"
        }
      ],
      "relevance": 0.6552734375
    },
    "Entity-document_type": {
      "node_id": "document_type",
      "disambiguation_index": 0,
      "label": "document type",
      "aliases": [
        "document type"
      ],
      "types": [
        "category",
        "type",
        "classification",
        "document"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'document type' refers to the specific category or format of a document that the MEL tool is capable of processing and extracting metadata from, as indicated by the theoretical number of attributes that can be extracted for each type.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "document type",
          "local_types": [
            "category",
            "type",
            "classification",
            "document"
          ],
          "iri": "Entity-document_type-Mention-1"
        }
      ],
      "relevance": 0.654296875
    },
    "Entity-metadata_and_content_extraction": {
      "node_id": "metadata_and_content_extraction",
      "disambiguation_index": 0,
      "label": "metadata and content extraction",
      "aliases": [
        "metadata and content extraction"
      ],
      "types": [
        "data processing",
        "information retrieval"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Metadata and content extraction refers to the process of retrieving and organizing structured information and relevant data from various file formats, often for the purpose of analysis or integration into other systems.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "metadata and content extraction",
          "local_types": [
            "data processing",
            "information retrieval"
          ],
          "iri": "Entity-metadata_and_content_extraction-Mention-1"
        }
      ],
      "relevance": 0.6494140625
    },
    "Entity-content_and_metadata": {
      "node_id": "content_and_metadata",
      "disambiguation_index": 0,
      "label": "content and metadata",
      "aliases": [
        "content and metadata"
      ],
      "types": [
        "data"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'content and metadata' refers to the information extracted from various file types, encompassing both the actual data contained within the files and the descriptive information about that data, which is essential for processing and utilizing unstructured information in knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "content and metadata",
          "local_types": [
            "data"
          ],
          "iri": "Entity-content_and_metadata-Mention-1"
        }
      ],
      "relevance": 0.64892578125
    },
    "Entity-tool": {
      "node_id": "tool",
      "disambiguation_index": 0,
      "label": "tools",
      "aliases": [
        "tools",
        "tool"
      ],
      "types": [
        "application",
        "instruments",
        "software",
        "utility"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'tools' refers to software applications that facilitate the integration of various extraction methods for metadata and content-based information from heterogeneous file sets, specifically within the context of Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "tools",
          "local_types": [
            "software",
            "instruments"
          ],
          "iri": "Entity-tool-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "tool",
          "local_types": [
            "software",
            "application"
          ],
          "iri": "Entity-tool-Mention-2"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "tools",
          "local_types": [
            "software",
            "utility"
          ],
          "iri": "Entity-tool-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "tool",
          "local_types": [
            "software",
            "application"
          ],
          "iri": "Entity-tool-Mention-4"
        }
      ],
      "relevance": 0.6484375
    },
    "Entity-attribute_and_property_list": {
      "node_id": "attribute_and_property_list",
      "disambiguation_index": 0,
      "label": "attribute and property list",
      "aliases": [
        "comprehensive attribute and property list",
        "attribute and property list"
      ],
      "types": [
        "data",
        "list",
        "data structure"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'attribute and property list' refers to a comprehensive set of metadata elements extracted from various file formats by the NLNZ Metadata Extractor tool, which is utilized by the MEL tool for general metadata extraction tasks.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "attribute and property list",
          "local_types": [
            "data structure"
          ],
          "iri": "Entity-attribute_and_property_list-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "comprehensive attribute and property list",
          "local_types": [
            "data",
            "list"
          ],
          "iri": "Entity-attribute_and_property_list-Mention-2"
        }
      ],
      "relevance": 0.6455078125
    },
    "Entity-table_2": {
      "node_id": "table_2",
      "disambiguation_index": 0,
      "label": "Table 2",
      "aliases": [
        "Table 2"
      ],
      "types": [
        "table",
        "data representation",
        "reference"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Table 2 presents the supported file types for the MEL tool, including the theoretical number of attributes that can be extracted per document type and the average number of extracted attributes from four use case document sets.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "Table 2",
          "local_types": [
            "table",
            "data representation",
            "reference"
          ],
          "iri": "Entity-table_2-Mention-1"
        }
      ],
      "relevance": 0.638671875
    },
    "Entity-four_use_case_document_set": {
      "node_id": "four_use_case_document_set",
      "disambiguation_index": 0,
      "label": "four use case document sets",
      "aliases": [
        "four use case document sets"
      ],
      "types": [
        "use case",
        "document set"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'four use case document sets' refers to a specific collection of document sets utilized in the evaluation of the MEL tool's capability to extract metadata and content-based information, highlighting the average number of attributes extracted from these sets.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "four use case document sets",
          "local_types": [
            "use case",
            "document set"
          ],
          "iri": "Entity-four_use_case_document_set-Mention-1"
        }
      ],
      "relevance": 0.638671875
    },
    "Entity-heterogeneous_file_set": {
      "node_id": "heterogeneous_file_set",
      "disambiguation_index": 0,
      "label": "heterogeneous file sets",
      "aliases": [
        "heterogeneous file sets"
      ],
      "types": [
        "file set",
        "file type",
        "data set",
        "file collection",
        "data collection"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Heterogeneous file sets refer to collections of files that vary in format, structure, and content, which are utilized in metadata and content-based information extraction processes for Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "heterogeneous file sets",
          "local_types": [
            "file set",
            "file type",
            "data set",
            "file collection",
            "data collection"
          ],
          "iri": "Entity-heterogeneous_file_set-Mention-1"
        }
      ],
      "relevance": 0.63525390625
    },
    "Entity-several_complementary_extraction_method": {
      "node_id": "several_complementary_extraction_method",
      "disambiguation_index": 0,
      "label": "several complementary extraction methods",
      "aliases": [
        "several complementary extraction methods"
      ],
      "types": [
        "extraction method"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Several complementary extraction methods refer to a variety of techniques used in metadata and content-based information extraction that work together to enhance the quality and richness of the output generated from heterogeneous file sets in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "several complementary extraction methods",
          "local_types": [
            "extraction method"
          ],
          "iri": "Entity-several_complementary_extraction_method-Mention-1"
        }
      ],
      "relevance": 0.634765625
    },
    "Entity-use_case_document_set": {
      "node_id": "use_case_document_set",
      "disambiguation_index": 0,
      "label": "use case document sets",
      "aliases": [
        "use case document sets"
      ],
      "types": [
        "case study",
        "document collection"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'use case document sets' refers to collections of documents utilized in practical scenarios to demonstrate the capabilities and performance of the MEL tool in extracting metadata and content-based information.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "use case document sets",
          "local_types": [
            "case study",
            "document collection"
          ],
          "iri": "Entity-use_case_document_set-Mention-1"
        }
      ],
      "relevance": 0.6337890625
    },
    "Entity-proper_tool": {
      "node_id": "proper_tool",
      "disambiguation_index": 0,
      "label": "proper tools",
      "aliases": [
        "proper tools"
      ],
      "types": [
        "tool"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Proper tools refer to integrated software solutions that combine various complementary methods for metadata and content-based information extraction, facilitating efficient processing in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "proper tools",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-proper_tool-Mention-1"
        }
      ],
      "relevance": 0.6298828125
    },
    "Entity-nlnz_metadata_extractor_tool": {
      "node_id": "nlnz_metadata_extractor_tool",
      "disambiguation_index": 0,
      "label": "NLNZ Metadata Extractor tool",
      "aliases": [
        "NLNZ Metadata Extractor tool"
      ],
      "types": [
        "tool",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The NLNZ Metadata Extractor tool is a Java standalone software that extracts a comprehensive list of attributes and properties from various file formats, providing XML output for use in metadata extraction tasks.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "NLNZ Metadata Extractor tool",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-nlnz_metadata_extractor_tool-Mention-1"
        }
      ],
      "relevance": 0.62890625
    },
    "Entity-heterogeneous_document_set": {
      "node_id": "heterogeneous_document_set",
      "disambiguation_index": 0,
      "label": "heterogeneous document sets",
      "aliases": [
        "heterogeneous document sets"
      ],
      "types": [
        "document",
        "document collection",
        "data",
        "data set"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Heterogeneous document sets refer to collections of documents that originate from various sources and formats, which require specialized methods for effective metadata and content extraction in data processing tasks.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "heterogeneous document sets",
          "local_types": [
            "document",
            "document collection",
            "data",
            "data set"
          ],
          "iri": "Entity-heterogeneous_document_set-Mention-1"
        }
      ],
      "relevance": 0.62841796875
    },
    "Entity-j2rm": {
      "node_id": "j2rm",
      "disambiguation_index": 0,
      "label": "J2RM",
      "aliases": [
        "J2RM"
      ],
      "types": [
        "software",
        "mapping tool",
        "project",
        "entity",
        "tool",
        "system",
        "acronym",
        "organization"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "J2RM is a software tool designed to facilitate the mapping of JSON results to RDF, enhancing the integration of metadata extraction processes within automated Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "J2RM",
          "local_types": [
            "software",
            "project",
            "entity",
            "tool",
            "system",
            "acronym",
            "organization"
          ],
          "iri": "Entity-j2rm-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "J2RM",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-j2rm-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "J2RM",
          "local_types": [
            "tool",
            "software",
            "mapping tool"
          ],
          "iri": "Entity-j2rm-Mention-3"
        }
      ],
      "relevance": 0.6279296875
    },
    "Entity-olemeta": {
      "node_id": "olemeta",
      "disambiguation_index": 0,
      "label": "olemeta",
      "aliases": [
        "olemeta tool",
        "olemeta"
      ],
      "types": [
        "tool",
        "metadata extraction tool",
        "software",
        "metadata extraction"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "olemeta is a tool used by the MEL software to extract metadata from OLE 2 file types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "olemeta",
          "local_types": [
            "tool",
            "software",
            "metadata extraction"
          ],
          "iri": "Entity-olemeta-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "olemeta tool",
          "local_types": [
            "metadata extraction tool",
            "software",
            "tool"
          ],
          "iri": "Entity-olemeta-Mention-2"
        }
      ],
      "relevance": 0.625
    },
    "Entity-comprehensive_configurable_setting": {
      "node_id": "comprehensive_configurable_setting",
      "disambiguation_index": 0,
      "label": "comprehensive configurable settings",
      "aliases": [
        "comprehensive configurable settings"
      ],
      "types": [
        "settings"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Comprehensive configurable settings refer to the flexible and extensive options available within the MEL tool that allow users to customize the metadata extraction and content-based information processing for various file types in Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "comprehensive configurable settings",
          "local_types": [
            "settings"
          ],
          "iri": "Entity-comprehensive_configurable_setting-Mention-1"
        }
      ],
      "relevance": 0.62451171875
    },
    "Entity-variety_of_tool": {
      "node_id": "variety_of_tool",
      "disambiguation_index": 0,
      "label": "variety of tools",
      "aliases": [
        "variety of tools"
      ],
      "types": [
        "tools"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'variety of tools' refers to different software applications and frameworks, such as J2RM, that facilitate the mapping of JSON output files to RDF format in the context of metadata extraction and knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "variety of tools",
          "local_types": [
            "tools"
          ],
          "iri": "Entity-variety_of_tool-Mention-1"
        }
      ],
      "relevance": 0.6220703125
    },
    "Entity-metadata_extraction": {
      "node_id": "metadata_extraction",
      "disambiguation_index": 0,
      "label": "metadata extraction",
      "aliases": [
        "metadata extraction"
      ],
      "types": [
        "information retrieval",
        "data processing",
        "process",
        "metadata",
        "data handling"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Metadata extraction is the process of retrieving and organizing metadata from various data sources to facilitate data management and information retrieval.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "metadata extraction",
          "local_types": [
            "process",
            "metadata",
            "data handling",
            "data processing"
          ],
          "iri": "Entity-metadata_extraction-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "metadata extraction",
          "local_types": [
            "process",
            "data processing"
          ],
          "iri": "Entity-metadata_extraction-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "metadata extraction",
          "local_types": [
            "process",
            "information retrieval",
            "metadata",
            "data processing"
          ],
          "iri": "Entity-metadata_extraction-Mention-3"
        }
      ],
      "relevance": 0.62060546875
    },
    "Entity-flag": {
      "node_id": "flag",
      "disambiguation_index": 0,
      "label": "flags",
      "aliases": [
        "flags"
      ],
      "types": [
        "settings",
        "configuration element"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the MEL tool, 'flags' refer to specific parameters within a configuration JSON file that dictate the initial settings for processing document sets and metadata extraction tasks.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "flags",
          "local_types": [
            "settings",
            "configuration element"
          ],
          "iri": "Entity-flag-Mention-1"
        }
      ],
      "relevance": 0.61865234375
    },
    "Entity-tnnt_general_configuration": {
      "node_id": "tnnt_general_configuration",
      "disambiguation_index": 0,
      "label": "TNNT general configuration",
      "aliases": [
        "TNNT general configuration"
      ],
      "types": [
        "system setting",
        "configuration"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The TNNT general configuration refers to a specific set of parameters and flags defined in a detailed JSON configuration file that dictates the initial settings for processing document sets within the MEL tool.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "TNNT general configuration",
          "local_types": [
            "system setting",
            "configuration"
          ],
          "iri": "Entity-tnnt_general_configuration-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-complementary_capability": {
      "node_id": "complementary_capability",
      "disambiguation_index": 0,
      "label": "complementary capabilities",
      "aliases": [
        "complementary capabilities"
      ],
      "types": [
        "capability"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "Complementary capabilities refer to the diverse and synergistic functionalities of various open-source packages and tools that, when integrated, enhance the effectiveness of metadata and content-based information extraction processes in the MEL tool.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "complementary capabilities",
          "local_types": [
            "capability"
          ],
          "iri": "Entity-complementary_capability-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-information_extraction_stage": {
      "node_id": "information_extraction_stage",
      "disambiguation_index": 0,
      "label": "information extraction stage",
      "aliases": [
        "information extraction stage"
      ],
      "types": [
        "process"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The information extraction stage refers to the process within Knowledge Graph Construction Pipelines (KGCPs) where metadata and content-based information is extracted from unstructured data sources to facilitate further data analysis and integration.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "information extraction stage",
          "local_types": [
            "process"
          ],
          "iri": "Entity-information_extraction_stage-Mention-1"
        }
      ],
      "relevance": 0.61669921875
    },
    "Entity-state-of-the-art_nlp_tool": {
      "node_id": "state-of-the-art_nlp_tool",
      "disambiguation_index": 0,
      "label": "state-of-the-art NLP tools",
      "aliases": [
        "state-of-the-art NLP tools"
      ],
      "types": [
        "NLP tool"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "State-of-the-art NLP tools refer to advanced natural language processing technologies and models that are utilized for tasks such as named entity recognition (NER) and information extraction, enhancing the capabilities of systems like MEL in processing and analyzing unstructured data.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "state-of-the-art NLP tools",
          "local_types": [
            "NLP tool"
          ],
          "iri": "Entity-state-of-the-art_nlp_tool-Mention-1"
        }
      ],
      "relevance": 0.6162109375
    },
    "Entity-nlnz_metadata_extractor": {
      "node_id": "nlnz_metadata_extractor",
      "disambiguation_index": 0,
      "label": "NLNZ Metadata Extractor",
      "aliases": [
        "NLNZ Metadata Extractor",
        "Java standalone tool"
      ],
      "types": [
        "tool",
        "programming language",
        "software",
        "Java application"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "The NLNZ Metadata Extractor is a Java standalone tool designed to extract a comprehensive list of attributes and properties from a wide range of file formats, facilitating metadata extraction tasks.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "NLNZ Metadata Extractor",
          "local_types": [
            "tool",
            "software",
            "Java application"
          ],
          "iri": "Entity-nlnz_metadata_extractor-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "Java standalone tool",
          "local_types": [
            "tool",
            "software",
            "programming language"
          ],
          "iri": "Entity-nlnz_metadata_extractor-Mention-2"
        }
      ],
      "relevance": 0.61572265625
    },
    "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis": {
      "node_id": "the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "disambiguation_index": 0,
      "label": "The most comprehensive and current state-of-the-art tool for content extraction and analysis",
      "aliases": [
        "The most comprehensive and current state-of-the-art tool for content extraction and analysis"
      ],
      "types": [
        "tool",
        "content extraction",
        "analysis"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The most comprehensive and current state-of-the-art tool for content extraction and analysis refers to Apache Tika, a Java-based system designed for extracting metadata and content from various file formats.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "The most comprehensive and current state-of-the-art tool for content extraction and analysis",
          "local_types": [
            "tool",
            "content extraction",
            "analysis"
          ],
          "iri": "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis-Mention-1"
        }
      ],
      "relevance": 0.615234375
    },
    "Entity-_3_": {
      "node_id": "_3_",
      "disambiguation_index": 0,
      "label": "[3]",
      "aliases": [
        "[3]"
      ],
      "types": [
        "reference"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term '[3]' refers to a specific Knowledge Graph Construction Pipeline (KGCP) that is discussed in the paper, highlighting its relevance to the information extraction capabilities of the MEL tool.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "[3]",
          "local_types": [
            "reference"
          ],
          "iri": "Entity-_3_-Mention-1"
        }
      ],
      "relevance": 0.6142578125
    },
    "Entity-_2_": {
      "node_id": "_2_",
      "disambiguation_index": 0,
      "label": "[2]",
      "aliases": [
        "[2]"
      ],
      "types": [
        "reference"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term '[2]' refers to a specific Knowledge Graph Construction Pipeline (KGCP) that is discussed in the paper, highlighting its relevance to the information extraction capabilities of the MEL tool.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "[2]",
          "local_types": [
            "reference"
          ],
          "iri": "Entity-_2_-Mention-1"
        }
      ],
      "relevance": 0.61181640625
    },
    "Entity-configurable_set_of_regular_expression": {
      "node_id": "configurable_set_of_regular_expression",
      "disambiguation_index": 0,
      "label": "configurable set of regular expressions",
      "aliases": [
        "configurable set of regular expressions",
        "a configurable set of regular expressions"
      ],
      "types": [
        "regular expressions",
        "configuration",
        "regular expression"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The 'configurable set of regular expressions' refers to a customizable collection of regex patterns used in the MEL tool to perform text analysis and extract relevant metadata and content-based information from various document types.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "configurable set of regular expressions",
          "local_types": [
            "regular expression",
            "configuration"
          ],
          "iri": "Entity-configurable_set_of_regular_expression-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "a configurable set of regular expressions",
          "local_types": [
            "regular expressions"
          ],
          "iri": "Entity-configurable_set_of_regular_expression-Mention-2"
        }
      ],
      "relevance": 0.6083984375
    },
    "Entity-task": {
      "node_id": "task",
      "disambiguation_index": 0,
      "label": "tasks",
      "aliases": [
        "KGCP tasks",
        "tasks",
        "These tasks"
      ],
      "types": [
        "activities",
        "task",
        "operations",
        "project"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'tasks' refers to the metadata and content-based information extraction activities that serve as pre-processing steps in Knowledge Graph Construction Pipelines (KGCP).",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "tasks",
          "local_types": [
            "activities",
            "operations"
          ],
          "iri": "Entity-task-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "KGCP tasks",
          "local_types": [
            "task",
            "project"
          ],
          "iri": "Entity-task-Mention-2"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "These tasks",
          "local_types": [
            "task"
          ],
          "iri": "Entity-task-Mention-3"
        }
      ],
      "relevance": 0.60791015625
    },
    "Entity-_6_": {
      "node_id": "_6_",
      "disambiguation_index": 0,
      "label": "[6]",
      "aliases": [
        "[6]"
      ],
      "types": [
        "reference"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term '[6]' refers to a specific Knowledge Graph Construction Pipeline (KGCP) that is discussed in the paper, highlighting its relevance to the information extraction capabilities of the MEL tool.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "[6]",
          "local_types": [
            "reference"
          ],
          "iri": "Entity-_6_-Mention-1"
        }
      ],
      "relevance": 0.607421875
    },
    "Entity-dozen_of_file_format": {
      "node_id": "dozen_of_file_format",
      "disambiguation_index": 0,
      "label": "dozens of file formats",
      "aliases": [
        "dozens of file formats"
      ],
      "types": [
        "file format"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'dozens of file formats' refers to a wide variety of document types that can be processed by the NLNZ Metadata Extractor tool to extract metadata and content-based information.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "dozens of file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-dozen_of_file_format-Mention-1"
        }
      ],
      "relevance": 0.6064453125
    },
    "Entity-content-based_information": {
      "node_id": "content-based_information",
      "disambiguation_index": 0,
      "label": "content-based information",
      "aliases": [
        "content-based information"
      ],
      "types": [
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Content-based information refers to the data extracted from unstructured information in various document formats, which is utilized in the context of metadata extraction and knowledge graph construction.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-4"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "content-based information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-content-based_information-Mention-5"
        }
      ],
      "relevance": 0.60595703125
    },
    "Entity-content_extraction": {
      "node_id": "content_extraction",
      "disambiguation_index": 0,
      "label": "content extraction",
      "aliases": [
        "content extraction"
      ],
      "types": [
        "process",
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Content extraction is the process of retrieving and organizing relevant information from unstructured data sources, enabling further analysis and utilization of the extracted data.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "content extraction",
          "local_types": [
            "process",
            "data processing"
          ],
          "iri": "Entity-content_extraction-Mention-1"
        }
      ],
      "relevance": 0.6044921875
    },
    "Entity-metadata_set": {
      "node_id": "metadata_set",
      "disambiguation_index": 0,
      "label": "metadata sets",
      "aliases": [
        "metadata sets"
      ],
      "types": [
        "metadata",
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Metadata sets are collections of data that provide information about other data, facilitating the organization, discovery, and management of various types of information across different formats.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "metadata sets",
          "local_types": [
            "metadata",
            "data",
            "information"
          ],
          "iri": "Entity-metadata_set-Mention-1"
        }
      ],
      "relevance": 0.6044921875
    },
    "Entity-content-based_information_extraction": {
      "node_id": "content-based_information_extraction",
      "disambiguation_index": 0,
      "label": "content-based information extraction",
      "aliases": [
        "content-based information extraction"
      ],
      "types": [
        "process",
        "information extraction",
        "methodology",
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Content-based information extraction is a methodology that involves extracting relevant information from data based on its content, often used in data processing and analysis tasks.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "content-based information extraction",
          "local_types": [
            "information extraction",
            "data processing"
          ],
          "iri": "Entity-content-based_information_extraction-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "content-based information extraction",
          "local_types": [
            "process",
            "methodology"
          ],
          "iri": "Entity-content-based_information_extraction-Mention-2"
        }
      ],
      "relevance": 0.60400390625
    },
    "Entity-per_use-case_requirement_basis": {
      "node_id": "per_use-case_requirement_basis",
      "disambiguation_index": 0,
      "label": "per use-case requirements basis",
      "aliases": [
        "per use-case requirements basis"
      ],
      "types": [
        "requirements"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'per use-case requirements basis' refers to the approach of adding file formats to the MEL tool according to the specific needs and requirements of different use cases in order to enhance its functionality for Knowledge Graph Construction Pipelines.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "per use-case requirements basis",
          "local_types": [
            "requirements"
          ],
          "iri": "Entity-per_use-case_requirement_basis-Mention-1"
        }
      ],
      "relevance": 0.60400390625
    },
    "Entity-content-based_analysis": {
      "node_id": "content-based_analysis",
      "disambiguation_index": 0,
      "label": "content-based analysis",
      "aliases": [
        "content-based analysis"
      ],
      "types": [
        "research method",
        "research approach",
        "analysis",
        "analysis method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Content-based analysis is a research method that focuses on examining and interpreting the content of various forms of data, such as text, images, or multimedia, to derive insights and patterns.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "content-based analysis",
          "local_types": [
            "research approach",
            "analysis",
            "analysis method"
          ],
          "iri": "Entity-content-based_analysis-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "content-based analysis",
          "local_types": [
            "research method",
            "analysis",
            "analysis method"
          ],
          "iri": "Entity-content-based_analysis-Mention-2"
        }
      ],
      "relevance": 0.59765625
    },
    "Entity-theoretical_number_of_attribute": {
      "node_id": "theoretical_number_of_attribute",
      "disambiguation_index": 0,
      "label": "theoretical number of attributes",
      "aliases": [
        "theoretical number of attributes"
      ],
      "types": [
        "attribute",
        "theoretical"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The theoretical number of attributes refers to the estimated count of distinct metadata and content-based information elements that the MEL tool can potentially extract from each type of document it processes.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "theoretical number of attributes",
          "local_types": [
            "attribute",
            "theoretical"
          ],
          "iri": "Entity-theoretical_number_of_attribute-Mention-1"
        }
      ],
      "relevance": 0.5966796875
    },
    "Entity-nlp_tool": {
      "node_id": "nlp_tool",
      "disambiguation_index": 0,
      "label": "NLP tools",
      "aliases": [
        "NLP tools"
      ],
      "types": [
        "tool",
        "technology",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "NLP tools are software applications or technologies designed to process and analyze natural language data, enabling tasks such as text analysis, language understanding, and information extraction.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "NLP tools",
          "local_types": [
            "tool",
            "technology",
            "software"
          ],
          "iri": "Entity-nlp_tool-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NLP tools",
          "local_types": [
            "tool",
            "technology",
            "software"
          ],
          "iri": "Entity-nlp_tool-Mention-2"
        }
      ],
      "relevance": 0.59619140625
    },
    "Entity-categorised_named_entity": {
      "node_id": "categorised_named_entity",
      "disambiguation_index": 0,
      "label": "categorised named entities",
      "aliases": [
        "categorised named entities"
      ],
      "types": [
        "entity"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "Categorised named entities refer to the specific entities identified and classified by the NLP -NER Toolkit (TNNT) from the results generated by the MEL tool, utilizing advanced natural language processing techniques.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "categorised named entities",
          "local_types": [
            "entity"
          ],
          "iri": "Entity-categorised_named_entity-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "categorised named entities",
          "local_types": [
            "entity"
          ],
          "iri": "Entity-categorised_named_entity-Mention-2"
        }
      ],
      "relevance": 0.595703125
    },
    "Entity-ole_2": {
      "node_id": "ole_2",
      "disambiguation_index": 0,
      "label": "OLE 2",
      "aliases": [
        "OLE 2"
      ],
      "types": [
        "file type",
        "format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "OLE 2 refers to a specific file type format that is compatible with the MEL tool for metadata extraction, which can only be processed on Windows operating systems.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "OLE 2",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-ole_2-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "OLE 2",
          "local_types": [
            "file type",
            "format"
          ],
          "iri": "Entity-ole_2-Mention-2"
        }
      ],
      "relevance": 0.59375
    },
    "Entity-property": {
      "node_id": "property",
      "disambiguation_index": 0,
      "label": "properties",
      "aliases": [
        "properties"
      ],
      "types": [
        "characteristics",
        "attributes"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "In the context of the paper, 'properties' refers to the various characteristics and attributes of extraction methods that are integrated to enhance the efficiency and richness of metadata and content-based information extraction from heterogeneous file sets.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "properties",
          "local_types": [
            "characteristics",
            "attributes"
          ],
          "iri": "Entity-property-Mention-1"
        }
      ],
      "relevance": 0.5927734375
    },
    "Entity-kgcp": {
      "node_id": "kgcp",
      "disambiguation_index": 0,
      "label": "KGCP",
      "aliases": [
        "KGCPs",
        "KGCP",
        "Knowledge Graph Construction Pipelines (KGCP)"
      ],
      "types": [
        "pipeline",
        "knowledge graph construction process",
        "data processing framework",
        "concept",
        "methodology",
        "project",
        "process",
        "Knowledge Graph",
        "framework",
        "system",
        "knowledge graph",
        "acronym",
        "task"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "KGCP refers to Knowledge Graph Construction Pipelines, which are frameworks that facilitate the integration and processing of data to create knowledge graphs from heterogeneous information sources.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "KGCP",
          "local_types": [
            "system",
            "framework"
          ],
          "iri": "Entity-kgcp-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "KGCP",
          "local_types": [
            "knowledge graph construction process",
            "project",
            "process",
            "framework",
            "system",
            "acronym"
          ],
          "iri": "Entity-kgcp-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "KGCP",
          "local_types": [
            "concept",
            "knowledge graph construction process",
            "project",
            "framework",
            "system",
            "acronym"
          ],
          "iri": "Entity-kgcp-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "KGCP",
          "local_types": [
            "task",
            "project"
          ],
          "iri": "Entity-kgcp-Mention-4"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Knowledge Graph Construction Pipelines (KGCP)",
          "local_types": [
            "pipeline",
            "Knowledge Graph",
            "data processing framework",
            "knowledge graph"
          ],
          "iri": "Entity-kgcp-Mention-5"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "KGCPs",
          "local_types": [
            "knowledge graph construction process",
            "concept",
            "methodology",
            "project"
          ],
          "iri": "Entity-kgcp-Mention-6"
        }
      ],
      "relevance": 0.5869140625
    },
    "Entity-ner_model": {
      "node_id": "ner_model",
      "disambiguation_index": 0,
      "label": "NER models",
      "aliases": [
        "NER models"
      ],
      "types": [
        "model",
        "tool",
        "technology",
        "machine learning model"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "NER models are machine learning models designed to identify and classify named entities in text into predefined categories such as names of people, organizations, locations, and other specific terms.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "NER models",
          "local_types": [
            "model",
            "technology",
            "machine learning model"
          ],
          "iri": "Entity-ner_model-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NER models",
          "local_types": [
            "model",
            "tool",
            "technology",
            "machine learning model"
          ],
          "iri": "Entity-ner_model-Mention-2"
        }
      ],
      "relevance": 0.5869140625
    },
    "Entity-project": {
      "node_id": "project",
      "disambiguation_index": 0,
      "label": "project",
      "aliases": [
        "project"
      ],
      "types": [
        "research program",
        "initiative"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'project' refers to an initiative aimed at containerizing the MEL and TNNT tools to enhance their deployment and usability.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-6",
          "local_name": "project",
          "local_types": [
            "research program",
            "initiative"
          ],
          "iri": "Entity-project-Mention-1"
        }
      ],
      "relevance": 0.5849609375
    },
    "Entity-the_last_step": {
      "node_id": "the_last_step",
      "disambiguation_index": 0,
      "label": "the last step",
      "aliases": [
        "the last step"
      ],
      "types": [
        "step"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The last step refers to the final text analysis task that is performed on the output generated from the specific processing model of each file type in the MEL tool.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "the last step",
          "local_types": [
            "step"
          ],
          "iri": "Entity-the_last_step-Mention-1"
        }
      ],
      "relevance": 0.5830078125
    },
    "Entity-the_text_analysis_task": {
      "node_id": "the_text_analysis_task",
      "disambiguation_index": 0,
      "label": "the text analysis task",
      "aliases": [
        "the text analysis task"
      ],
      "types": [
        "task",
        "text analysis"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The text analysis task refers to the final step in the processing model of various file types, where content and metadata are analyzed to produce the output results in the context of metadata and information extraction.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "the text analysis task",
          "local_types": [
            "task",
            "text analysis"
          ],
          "iri": "Entity-the_text_analysis_task-Mention-1"
        }
      ],
      "relevance": 0.58251953125
    },
    "Entity-knowledge_graph_construction_pipeline": {
      "node_id": "knowledge_graph_construction_pipeline",
      "disambiguation_index": 0,
      "label": "Knowledge Graph Construction Pipelines",
      "aliases": [
        "Knowledge Graph Construction Pipelines"
      ],
      "types": [
        "process",
        "concept",
        "knowledge graph",
        "pipeline"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Knowledge Graph Construction Pipelines are systematic processes designed to extract, integrate, and organize information from various data sources into a structured knowledge graph format.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "Knowledge Graph Construction Pipelines",
          "local_types": [
            "process",
            "concept",
            "knowledge graph",
            "pipeline"
          ],
          "iri": "Entity-knowledge_graph_construction_pipeline-Mention-1"
        }
      ],
      "relevance": 0.58154296875
    },
    "Entity-parameter_and_flag": {
      "node_id": "parameter_and_flag",
      "disambiguation_index": 0,
      "label": "parameters and flags",
      "aliases": [
        "parameters and flags"
      ],
      "types": [
        "parameters",
        "settings",
        "configuration",
        "flags"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'parameters and flags' refers to the configurable settings defined in a JSON file that dictate the processing behavior of the MEL tool, including aspects such as document store configuration, input document sets, and text analysis methods.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "parameters and flags",
          "local_types": [
            "parameters",
            "settings",
            "configuration",
            "flags"
          ],
          "iri": "Entity-parameter_and_flag-Mention-1"
        }
      ],
      "relevance": 0.5791015625
    },
    "Entity-diverse_state-of-the-art_nlp_tool_and_ner_model": {
      "node_id": "diverse_state-of-the-art_nlp_tool_and_ner_model",
      "disambiguation_index": 0,
      "label": "diverse state-of-the-art NLP tools and NER models",
      "aliases": [
        "diverse state-of-the-art NLP tools and NER models"
      ],
      "types": [
        "tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A collection of advanced software applications and algorithms designed for natural language processing (NLP) tasks, including named entity recognition (NER), that utilize the latest techniques and methodologies in the field.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "diverse state-of-the-art NLP tools and NER models",
          "local_types": [
            "tool"
          ],
          "iri": "Entity-diverse_state-of-the-art_nlp_tool_and_ner_model-Mention-1"
        }
      ],
      "relevance": 0.57861328125
    },
    "Entity-the_data_set__domain": {
      "node_id": "the_data_set__domain",
      "disambiguation_index": 0,
      "label": "the data sets' domain",
      "aliases": [
        "the data sets' domain"
      ],
      "types": [
        "domain"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The data sets' domain refers to the specific area or field of application from which the unstructured data sets originate, indicating that MEL is designed to work with various types of data regardless of their specific subject matter or context.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "the data sets' domain",
          "local_types": [
            "domain"
          ],
          "iri": "Entity-the_data_set__domain-Mention-1"
        }
      ],
      "relevance": 0.57861328125
    },
    "Entity-agrif": {
      "node_id": "agrif",
      "disambiguation_index": 0,
      "label": "AGRIF",
      "aliases": [
        "AGRIF project",
        "AGRIF"
      ],
      "types": [
        "initiative",
        "research project",
        "project"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "AGRIF refers to a project that involves testing the MEL tool over thousands of documents using various formats and datasets.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "AGRIF",
          "local_types": [
            "project"
          ],
          "iri": "Entity-agrif-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "AGRIF project",
          "local_types": [
            "initiative",
            "research project",
            "project"
          ],
          "iri": "Entity-agrif-Mention-2"
        }
      ],
      "relevance": 0.5771484375
    },
    "Entity-json_file": {
      "node_id": "json_file",
      "disambiguation_index": 0,
      "label": "JSON files",
      "aliases": [
        "JSON file",
        "JSON files"
      ],
      "types": [
        "data structure",
        "data format",
        "file format",
        "file",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON files are text-based files that store data in a structured format using JavaScript Object Notation (JSON), which is easy for humans to read and write, and easy for machines to parse and generate.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "JSON files",
          "local_types": [
            "file",
            "format",
            "data format",
            "file format"
          ],
          "iri": "Entity-json_file-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "JSON file",
          "local_types": [
            "file format",
            "file",
            "data structure",
            "format"
          ],
          "iri": "Entity-json_file-Mention-2"
        }
      ],
      "relevance": 0.57666015625
    },
    "Entity-rdf_ready": {
      "node_id": "rdf_ready",
      "disambiguation_index": 0,
      "label": "RDF ready",
      "aliases": [
        "RDF ready"
      ],
      "types": [
        "format"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "RDF ready refers to the state of extracted metadata that has been enhanced with JSON-LD annotations, making it compatible for easy mapping to RDF (Resource Description Framework) format.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "RDF ready",
          "local_types": [
            "format"
          ],
          "iri": "Entity-rdf_ready-Mention-1"
        }
      ],
      "relevance": 0.5751953125
    },
    "Entity-text_analysis": {
      "node_id": "text_analysis",
      "disambiguation_index": 0,
      "label": "text analysis",
      "aliases": [
        "text analysis"
      ],
      "types": [
        "process",
        "data analysis",
        "methodology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Text analysis is a process of examining and interpreting textual data to extract meaningful information, identify patterns, and derive insights.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "text analysis",
          "local_types": [
            "process",
            "data analysis",
            "methodology"
          ],
          "iri": "Entity-text_analysis-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "text analysis",
          "local_types": [
            "process",
            "methodology"
          ],
          "iri": "Entity-text_analysis-Mention-2"
        }
      ],
      "relevance": 0.57470703125
    },
    "Entity-json_result_file": {
      "node_id": "json_result_file",
      "disambiguation_index": 0,
      "label": "JSON result files",
      "aliases": [
        "JSON result files"
      ],
      "types": [
        "file type",
        "file",
        "data format",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON result files are structured text files that store data in a format that is easy for both humans and machines to read and write, using JavaScript Object Notation (JSON) to represent the data in key-value pairs.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "JSON result files",
          "local_types": [
            "file type",
            "file",
            "data format",
            "format"
          ],
          "iri": "Entity-json_result_file-Mention-1"
        }
      ],
      "relevance": 0.57373046875
    },
    "Entity-python-based_tool": {
      "node_id": "python-based_tool",
      "disambiguation_index": 0,
      "label": "Python-based tool",
      "aliases": [
        "Python-based tool"
      ],
      "types": [
        "tool",
        "software",
        "programming language"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A Python-based tool is a software application developed using the Python programming language, designed to perform specific tasks or functions, often related to data processing or analysis.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "Python-based tool",
          "local_types": [
            "tool",
            "software",
            "programming language"
          ],
          "iri": "Entity-python-based_tool-Mention-1"
        }
      ],
      "relevance": 0.572265625
    },
    "Entity-metadata": {
      "node_id": "metadata",
      "disambiguation_index": 0,
      "label": "metadata",
      "aliases": [
        "metadata"
      ],
      "types": [
        "data",
        "data type",
        "metadata",
        "data description",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Metadata refers to data that provides information about other data, helping to organize, manage, and understand the underlying content.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-1",
          "local_name": "metadata",
          "local_types": [
            "data type",
            "information"
          ],
          "iri": "Entity-metadata-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-4"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "metadata",
          "local_types": [
            "metadata",
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-5"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-6"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-7"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "metadata",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-metadata-Mention-8"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "metadata",
          "local_types": [
            "data description"
          ],
          "iri": "Entity-metadata-Mention-9"
        }
      ],
      "relevance": 0.57177734375
    },
    "Entity-average_of_the_extracted_attribute": {
      "node_id": "average_of_the_extracted_attribute",
      "disambiguation_index": 0,
      "label": "average of the extracted attributes",
      "aliases": [
        "average of the extracted attributes",
        "the average of the extracted attributes"
      ],
      "types": [
        "average",
        "attribute"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The 'average of the extracted attributes' refers to the mean value calculated from the number of attributes that the MEL tool is able to extract from four different use case document sets.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "average of the extracted attributes",
          "local_types": [
            "attribute",
            "average"
          ],
          "iri": "Entity-average_of_the_extracted_attribute-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-7",
          "local_name": "the average of the extracted attributes",
          "local_types": [
            "average",
            "attribute"
          ],
          "iri": "Entity-average_of_the_extracted_attribute-Mention-2"
        }
      ],
      "relevance": 0.57177734375
    },
    "Entity-state-of-the-art_nlp_tool_and_ner_model": {
      "node_id": "state-of-the-art_nlp_tool_and_ner_model",
      "disambiguation_index": 0,
      "label": "state-of-the-art NLP tools and NER models",
      "aliases": [
        "state-of-the-art NLP tools and NER models"
      ],
      "types": [
        "model",
        "tool",
        "NER model",
        "NLP tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "State-of-the-art NLP tools and NER models refer to advanced software and algorithms designed for natural language processing tasks, including the identification and classification of named entities within text.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "state-of-the-art NLP tools and NER models",
          "local_types": [
            "model",
            "tool",
            "NER model",
            "NLP tool"
          ],
          "iri": "Entity-state-of-the-art_nlp_tool_and_ner_model-Mention-1"
        }
      ],
      "relevance": 0.57177734375
    },
    "Entity-keyword_extraction": {
      "node_id": "keyword_extraction",
      "disambiguation_index": 0,
      "label": "keyword extraction",
      "aliases": [
        "keyword extraction"
      ],
      "types": [
        "technique",
        "text processing",
        "information retrieval",
        "text analysis technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Keyword extraction is a text processing technique used to identify and extract significant words or phrases from a body of text, facilitating information retrieval and analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "keyword extraction",
          "local_types": [
            "technique",
            "text processing",
            "text analysis technique"
          ],
          "iri": "Entity-keyword_extraction-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "keyword extraction",
          "local_types": [
            "text analysis technique",
            "information retrieval"
          ],
          "iri": "Entity-keyword_extraction-Mention-2"
        }
      ],
      "relevance": 0.57080078125
    },
    "Entity-text_analysis_task": {
      "node_id": "text_analysis_task",
      "disambiguation_index": 0,
      "label": "text analysis task",
      "aliases": [
        "text analysis task"
      ],
      "types": [
        "data processing",
        "process",
        "analysis",
        "analysis process",
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A text analysis task is a systematic process of examining and interpreting textual data to extract meaningful information, identify patterns, or derive insights.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "text analysis task",
          "local_types": [
            "analysis process",
            "analysis",
            "task"
          ],
          "iri": "Entity-text_analysis_task-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "text analysis task",
          "local_types": [
            "data processing",
            "process",
            "analysis",
            "analysis process",
            "task"
          ],
          "iri": "Entity-text_analysis_task-Mention-2"
        }
      ],
      "relevance": 0.5703125
    },
    "Entity-vocabulary_or_light-weight_ontology": {
      "node_id": "vocabulary_or_light-weight_ontology",
      "disambiguation_index": 0,
      "label": "vocabulary or light-weight ontology",
      "aliases": [
        "vocabulary or light-weight ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": false,
      "description": "The term 'vocabulary or light-weight ontology' refers to a structured set of terms and relationships that can be incorporated into the JSON results of the MEL tool using JSON-LD annotations to enhance the metadata's compatibility with RDF standards.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "vocabulary or light-weight ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-vocabulary_or_light-weight_ontology-Mention-1"
        }
      ],
      "relevance": 0.5703125
    },
    "Entity-python-based_tool_and_library": {
      "node_id": "python-based_tool_and_library",
      "disambiguation_index": 0,
      "label": "Python-based tools and libraries",
      "aliases": [
        "Python-based tools and libraries"
      ],
      "types": [
        "software",
        "library",
        "libraries",
        "tool",
        "tools"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Python-based tools and libraries refer to software components and frameworks developed in the Python programming language that provide functionalities for various tasks, including data manipulation, analysis, and extraction.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "Python-based tools and libraries",
          "local_types": [
            "software",
            "library",
            "libraries",
            "tool",
            "tools"
          ],
          "iri": "Entity-python-based_tool_and_library-Mention-1"
        }
      ],
      "relevance": 0.568359375
    },
    "Entity-xml_output": {
      "node_id": "xml_output",
      "disambiguation_index": 0,
      "label": "XML output",
      "aliases": [
        "XML output"
      ],
      "types": [
        "data",
        "data format",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "XML output refers to data formatted in Extensible Markup Language (XML), which is used to structure and store information in a way that is both human-readable and machine-readable.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "XML output",
          "local_types": [
            "data",
            "data format",
            "format"
          ],
          "iri": "Entity-xml_output-Mention-1"
        }
      ],
      "relevance": 0.56689453125
    },
    "Entity-rdf": {
      "node_id": "rdf",
      "disambiguation_index": 0,
      "label": "RDF",
      "aliases": [
        "RDF"
      ],
      "types": [
        "data model",
        "data structure",
        "data format",
        "semantic web",
        "technology",
        "semantic web standard",
        "semantic web technology",
        "standard",
        "format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "RDF, or Resource Description Framework, is a standard model for data interchange on the web that facilitates the representation of information about resources in a structured way, enabling interoperability and semantic understanding.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "RDF",
          "local_types": [
            "semantic web standard",
            "data structure",
            "data format",
            "format"
          ],
          "iri": "Entity-rdf-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "RDF",
          "local_types": [
            "data model",
            "data format",
            "semantic web standard",
            "standard",
            "format"
          ],
          "iri": "Entity-rdf-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "RDF",
          "local_types": [
            "semantic web standard",
            "semantic web technology",
            "data format",
            "format"
          ],
          "iri": "Entity-rdf-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "RDF",
          "local_types": [
            "data model",
            "data format",
            "semantic web",
            "technology",
            "semantic web standard",
            "format"
          ],
          "iri": "Entity-rdf-Mention-4"
        }
      ],
      "relevance": 0.5625
    },
    "Entity-ner": {
      "node_id": "ner",
      "disambiguation_index": 0,
      "label": "NER",
      "aliases": [
        "NER"
      ],
      "types": [
        "field",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "NER refers to Named Entity Recognition, a subtask of natural language processing that involves identifying and classifying key entities in text into predefined categories such as names, organizations, locations, and more.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NER",
          "local_types": [
            "field",
            "technology"
          ],
          "iri": "Entity-ner-Mention-1"
        }
      ],
      "relevance": 0.5615234375
    },
    "Entity-pattern_matching": {
      "node_id": "pattern_matching",
      "disambiguation_index": 0,
      "label": "pattern matching",
      "aliases": [
        "pattern matching"
      ],
      "types": [
        "technique",
        "text processing",
        "text analysis technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pattern matching is a technique used in text processing and analysis to identify and extract specific sequences or structures within text data based on predefined criteria.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "pattern matching",
          "local_types": [
            "technique",
            "text processing",
            "text analysis technique"
          ],
          "iri": "Entity-pattern_matching-Mention-1"
        }
      ],
      "relevance": 0.56103515625
    },
    "Entity-light-weight_ontology": {
      "node_id": "light-weight_ontology",
      "disambiguation_index": 0,
      "label": "light-weight ontology",
      "aliases": [
        "light-weight ontology"
      ],
      "types": [
        "ontology"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "A light-weight ontology refers to a simplified and flexible framework or vocabulary that can be easily integrated into JSON-LD annotations to enhance the metadata extracted by the MEL tool, making it compatible with RDF standards.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "light-weight ontology",
          "local_types": [
            "ontology"
          ],
          "iri": "Entity-light-weight_ontology-Mention-1"
        }
      ],
      "relevance": 0.56103515625
    },
    "Entity-document_store": {
      "node_id": "document_store",
      "disambiguation_index": 0,
      "label": "document store",
      "aliases": [
        "document store"
      ],
      "types": [
        "system component",
        "database",
        "repository",
        "system",
        "storage",
        "data storage",
        "storage system",
        "document"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A document store is a type of database designed to store, retrieve, and manage document-oriented information, typically in formats like JSON or XML.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "document store",
          "local_types": [
            "system",
            "storage system",
            "storage",
            "database"
          ],
          "iri": "Entity-document_store-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-3",
          "local_name": "document store",
          "local_types": [
            "database",
            "repository",
            "system",
            "storage",
            "data storage",
            "document"
          ],
          "iri": "Entity-document_store-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "document store",
          "local_types": [
            "data storage",
            "system component",
            "storage",
            "document"
          ],
          "iri": "Entity-document_store-Mention-3"
        }
      ],
      "relevance": 0.5576171875
    },
    "Entity-basic_text_analysis_task": {
      "node_id": "basic_text_analysis_task",
      "disambiguation_index": 0,
      "label": "basic text analysis tasks",
      "aliases": [
        "basic text analysis tasks"
      ],
      "types": [
        "text analysis",
        "task"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Basic text analysis tasks refer to fundamental operations such as pattern matching and keyword extraction performed on textual content to facilitate further content-based analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "basic text analysis tasks",
          "local_types": [
            "text analysis",
            "task"
          ],
          "iri": "Entity-basic_text_analysis_task-Mention-1"
        }
      ],
      "relevance": 0.556640625
    },
    "Entity-textual_content": {
      "node_id": "textual_content",
      "disambiguation_index": 0,
      "label": "textual content",
      "aliases": [
        "textual content"
      ],
      "types": [
        "content",
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Textual content refers to the written or printed material that conveys information or data within a document or file.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "textual content",
          "local_types": [
            "content",
            "data",
            "information"
          ],
          "iri": "Entity-textual_content-Mention-1"
        }
      ],
      "relevance": 0.5556640625
    },
    "Entity-basic_text_analysis": {
      "node_id": "basic_text_analysis",
      "disambiguation_index": 0,
      "label": "basic text analysis",
      "aliases": [
        "basic text analysis"
      ],
      "types": [
        "text analysis",
        "analysis"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Basic text analysis refers to the preliminary examination of text data that includes tasks such as applying regular expressions and extracting keywords to derive meaningful information from documents.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "basic text analysis",
          "local_types": [
            "text analysis",
            "analysis"
          ],
          "iri": "Entity-basic_text_analysis-Mention-1"
        }
      ],
      "relevance": 0.5556640625
    },
    "Entity-information_extraction": {
      "node_id": "information_extraction",
      "disambiguation_index": 0,
      "label": "information extraction",
      "aliases": [
        "information extraction"
      ],
      "types": [
        "process",
        "technique"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Information extraction is a process or technique used to automatically retrieve structured information from unstructured data sources.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-4",
          "local_name": "information extraction",
          "local_types": [
            "process",
            "technique"
          ],
          "iri": "Entity-information_extraction-Mention-1"
        }
      ],
      "relevance": 0.55419921875
    },
    "Entity-apache_tika": {
      "node_id": "apache_tika",
      "disambiguation_index": 0,
      "label": "Apache Tika",
      "aliases": [
        "Apache Tika"
      ],
      "types": [
        "software",
        "tool",
        "package",
        "system",
        "content extraction system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "Apache Tika is an open-source software toolkit designed for content detection, extraction, and analysis from various file formats.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "Apache Tika",
          "local_types": [
            "tool",
            "system",
            "software",
            "content extraction system"
          ],
          "iri": "Entity-apache_tika-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "Apache Tika",
          "local_types": [
            "tool",
            "software",
            "package"
          ],
          "iri": "Entity-apache_tika-Mention-2"
        }
      ],
      "relevance": 0.55322265625
    },
    "Entity-json-ld_ontology": {
      "node_id": "json-ld_ontology",
      "disambiguation_index": 0,
      "label": "JSON-LD ontologies",
      "aliases": [
        "JSON-LD ontologies"
      ],
      "types": [
        "data format",
        "ontology",
        "semantic web technology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON-LD ontologies are structured representations of knowledge that utilize JSON-LD, a lightweight Linked Data format, to define relationships and semantics in a machine-readable way, facilitating interoperability on the Semantic Web.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "JSON-LD ontologies",
          "local_types": [
            "data format",
            "ontology",
            "semantic web technology"
          ],
          "iri": "Entity-json-ld_ontology-Mention-1"
        }
      ],
      "relevance": 0.55322265625
    },
    "Entity-extraction_method": {
      "node_id": "extraction_method",
      "disambiguation_index": 0,
      "label": "extraction methods",
      "aliases": [
        "extraction methods"
      ],
      "types": [
        "techniques",
        "processes"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Extraction methods are techniques and processes used to obtain specific data or information from various sources.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-2",
          "local_name": "extraction methods",
          "local_types": [
            "techniques",
            "processes"
          ],
          "iri": "Entity-extraction_method-Mention-1"
        }
      ],
      "relevance": 0.55224609375
    },
    "Entity-unstructured_data_set_of_heterogeneous_format": {
      "node_id": "unstructured_data_set_of_heterogeneous_format",
      "disambiguation_index": 0,
      "label": "unstructured data sets of heterogeneous formats",
      "aliases": [
        "unstructured data sets of heterogeneous formats"
      ],
      "types": [
        "data set"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "Unstructured data sets of heterogeneous formats refer to collections of data that lack a predefined structure and come from various sources and file types, making them complex to process and analyze without specialized tools.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "unstructured data sets of heterogeneous formats",
          "local_types": [
            "data set"
          ],
          "iri": "Entity-unstructured_data_set_of_heterogeneous_format-Mention-1"
        }
      ],
      "relevance": 0.55126953125
    },
    "Entity-pattern_matching_and_keyword_extraction": {
      "node_id": "pattern_matching_and_keyword_extraction",
      "disambiguation_index": 0,
      "label": "pattern matching and keyword extraction",
      "aliases": [
        "pattern matching and keyword extraction"
      ],
      "types": [
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pattern matching and keyword extraction are techniques used in text analysis to identify specific patterns and extract significant words or phrases from a body of text.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "pattern matching and keyword extraction",
          "local_types": [
            "task"
          ],
          "iri": "Entity-pattern_matching_and_keyword_extraction-Mention-1"
        }
      ],
      "relevance": 0.55078125
    },
    "Entity-json-ld_annotation": {
      "node_id": "json-ld_annotation",
      "disambiguation_index": 0,
      "label": "JSON-LD annotations",
      "aliases": [
        "JSON-LD annotations"
      ],
      "types": [
        "annotation",
        "JSON-LD"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "JSON-LD annotations are a method for adding structured metadata to JSON data, enabling the integration of vocabularies or lightweight ontologies to enhance the interoperability of extracted metadata with RDF standards.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON-LD annotations",
          "local_types": [
            "annotation",
            "JSON-LD"
          ],
          "iri": "Entity-json-ld_annotation-Mention-1"
        }
      ],
      "relevance": 0.548828125
    },
    "Entity-json-ld": {
      "node_id": "json-ld",
      "disambiguation_index": 0,
      "label": "JSON-LD",
      "aliases": [
        "JSON-LD"
      ],
      "types": [
        "linked data",
        "data format",
        "technology",
        "annotation format",
        "ontology",
        "format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "JSON-LD is a lightweight Linked Data format that allows the representation of structured data using JSON, enabling interoperability and integration of data across different systems.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-4",
          "local_name": "JSON-LD",
          "local_types": [
            "technology",
            "ontology"
          ],
          "iri": "Entity-json-ld-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON-LD",
          "local_types": [
            "linked data",
            "data format",
            "technology",
            "annotation format",
            "format"
          ],
          "iri": "Entity-json-ld-Mention-2"
        }
      ],
      "relevance": 0.5458984375
    },
    "Entity-xml": {
      "node_id": "xml",
      "disambiguation_index": 0,
      "label": "XML",
      "aliases": [
        "XML"
      ],
      "types": [
        "markup language",
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "XML is a markup language used for encoding documents in a format that is both human-readable and machine-readable, often utilized for data representation and storage.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "XML",
          "local_types": [
            "markup language",
            "data format"
          ],
          "iri": "Entity-xml-Mention-1"
        }
      ],
      "relevance": 0.544921875
    },
    "Entity-json_object": {
      "node_id": "json_object",
      "disambiguation_index": 0,
      "label": "JSON objects",
      "aliases": [
        "JSON objects"
      ],
      "types": [
        "JSON",
        "data structure",
        "data format",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON objects are data structures that represent data in a lightweight, text-based format using key-value pairs, commonly used for data interchange between a server and a web application.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "JSON objects",
          "local_types": [
            "JSON",
            "data structure",
            "data format",
            "format"
          ],
          "iri": "Entity-json_object-Mention-1"
        }
      ],
      "relevance": 0.54248046875
    },
    "Entity-python-based_system": {
      "node_id": "python-based_system",
      "disambiguation_index": 0,
      "label": "Python-based system",
      "aliases": [
        "Python-based system"
      ],
      "types": [
        "programming environment",
        "system",
        "software",
        "programming language"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A Python-based system is a software solution developed using the Python programming language, designed to perform specific tasks or functions, often involving data processing, integration, or automation.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "Python-based system",
          "local_types": [
            "programming environment",
            "system",
            "software",
            "programming language"
          ],
          "iri": "Entity-python-based_system-Mention-1"
        }
      ],
      "relevance": 0.54052734375
    },
    "Entity-data_set": {
      "node_id": "data_set",
      "disambiguation_index": 0,
      "label": "data sets",
      "aliases": [
        "datasets",
        "data sets"
      ],
      "types": [
        "dataset",
        "data",
        "data collection"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Data sets refer to collections of related data that are organized for analysis, processing, or storage, and can encompass various formats and structures.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "data sets",
          "local_types": [
            "data"
          ],
          "iri": "Entity-data_set-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-2",
          "local_name": "datasets",
          "local_types": [
            "dataset",
            "data collection"
          ],
          "iri": "Entity-data_set-Mention-2"
        }
      ],
      "relevance": 0.53955078125
    },
    "Entity-result": {
      "node_id": "result",
      "disambiguation_index": 0,
      "label": "results",
      "aliases": [
        "results"
      ],
      "types": [
        "outcome",
        "output",
        "data"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Results refer to the outcomes or outputs generated from a process or analysis, often presented in a structured format such as JSON.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "results",
          "local_types": [
            "data",
            "outcome"
          ],
          "iri": "Entity-result-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "results",
          "local_types": [
            "output",
            "data"
          ],
          "iri": "Entity-result-Mention-2"
        }
      ],
      "relevance": 0.53857421875
    },
    "Entity-json": {
      "node_id": "json",
      "disambiguation_index": 0,
      "label": "JSON",
      "aliases": [
        "JSON"
      ],
      "types": [
        "data structure",
        "data format",
        "file format",
        "serialization format",
        "format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "JSON is a lightweight data interchange format that is easy for humans to read and write, and easy for machines to parse and generate, commonly used for representing structured data.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "JSON",
          "local_types": [
            "format",
            "data structure"
          ],
          "iri": "Entity-json-Mention-1"
        },
        {
          "reference": "Section-1-Paragraph-1-Sentence-4",
          "local_name": "JSON",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json-Mention-2"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "JSON",
          "local_types": [
            "data format",
            "file format"
          ],
          "iri": "Entity-json-Mention-3"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "JSON",
          "local_types": [
            "data format",
            "serialization format"
          ],
          "iri": "Entity-json-Mention-4"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-6",
          "local_name": "JSON",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json-Mention-5"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "JSON",
          "local_types": [
            "data format",
            "file format"
          ],
          "iri": "Entity-json-Mention-6"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "JSON",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json-Mention-7"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json-Mention-8"
        }
      ],
      "relevance": 0.53466796875
    },
    "Entity-python-based_package": {
      "node_id": "python-based_package",
      "disambiguation_index": 0,
      "label": "Python-based package",
      "aliases": [
        "Python-based package"
      ],
      "types": [
        "package",
        "tool"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A Python-based package is a software library or tool developed in the Python programming language that provides specific functionalities or services, often designed for ease of use and integration in various applications.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "Python-based package",
          "local_types": [
            "package",
            "tool"
          ],
          "iri": "Entity-python-based_package-Mention-1"
        }
      ],
      "relevance": 0.53466796875
    },
    "Entity-unstructured_data_set": {
      "node_id": "unstructured_data_set",
      "disambiguation_index": 0,
      "label": "unstructured data sets",
      "aliases": [
        "unstructured data sets"
      ],
      "types": [
        "data",
        "data format",
        "data type",
        "dataset",
        "data set"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Unstructured data sets refer to collections of data that do not have a predefined data model or structure, making them difficult to organize and analyze, and typically include formats such as text, images, audio, and video.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-5",
          "local_name": "unstructured data sets",
          "local_types": [
            "data type",
            "data",
            "data format",
            "data set"
          ],
          "iri": "Entity-unstructured_data_set-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "unstructured data sets",
          "local_types": [
            "dataset",
            "data",
            "data format",
            "data set"
          ],
          "iri": "Entity-unstructured_data_set-Mention-2"
        }
      ],
      "relevance": 0.5341796875
    },
    "Entity-pre-processing_and_data_cleaning_task": {
      "node_id": "pre-processing_and_data_cleaning_task",
      "disambiguation_index": 0,
      "label": "pre-processing and data cleaning tasks",
      "aliases": [
        "pre-processing and data cleaning tasks"
      ],
      "types": [
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pre-processing and data cleaning tasks refer to the systematic procedures applied to raw data to prepare it for analysis by removing inaccuracies, inconsistencies, and irrelevant information.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "pre-processing and data cleaning tasks",
          "local_types": [
            "task"
          ],
          "iri": "Entity-pre-processing_and_data_cleaning_task-Mention-1"
        }
      ],
      "relevance": 0.53369140625
    },
    "Entity-file_format": {
      "node_id": "file_format",
      "disambiguation_index": 0,
      "label": "file formats",
      "aliases": [
        "file formats",
        "file types/formats"
      ],
      "types": [
        "data",
        "data format",
        "information structure",
        "file type",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "File formats are standardized ways of encoding and organizing data in digital files, allowing for the storage, retrieval, and interpretation of information by software applications.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-1",
          "local_name": "file formats",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-file_format-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "file formats",
          "local_types": [
            "data",
            "data format",
            "format"
          ],
          "iri": "Entity-file_format-Mention-2"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "file formats",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-file_format-Mention-3"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-5",
          "local_name": "file formats",
          "local_types": [
            "format",
            "data format",
            "information structure"
          ],
          "iri": "Entity-file_format-Mention-4"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "file types/formats",
          "local_types": [
            "data format",
            "file type"
          ],
          "iri": "Entity-file_format-Mention-5"
        }
      ],
      "relevance": 0.5322265625
    },
    "Entity-python-based_method": {
      "node_id": "python-based_method",
      "disambiguation_index": 0,
      "label": "Python-based methods",
      "aliases": [
        "Python-based methods"
      ],
      "types": [
        "method",
        "programming language",
        "programming",
        "software technique",
        "programming method"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Python-based methods refer to techniques or approaches that utilize the Python programming language to perform tasks or solve problems, often in the context of software development or data processing.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "Python-based methods",
          "local_types": [
            "method",
            "programming language",
            "programming",
            "software technique",
            "programming method"
          ],
          "iri": "Entity-python-based_method-Mention-1"
        }
      ],
      "relevance": 0.53173828125
    },
    "Entity-java-based_general-purpose_system": {
      "node_id": "java-based_general-purpose_system",
      "disambiguation_index": 0,
      "label": "Java-based general-purpose system",
      "aliases": [
        "Java-based general-purpose system"
      ],
      "types": [
        "system",
        "Java"
      ],
      "node_type": "other",
      "LLM_familiarity": false,
      "description": "The term 'Java-based general-purpose system' refers to Apache Tika, a versatile tool designed for content extraction and analysis from various file formats, implemented in Java.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-1",
          "local_name": "Java-based general-purpose system",
          "local_types": [
            "system",
            "Java"
          ],
          "iri": "Entity-java-based_general-purpose_system-Mention-1"
        }
      ],
      "relevance": 0.53125
    },
    "Entity-machine-readable_format": {
      "node_id": "machine-readable_format",
      "disambiguation_index": 0,
      "label": "machine-readable format",
      "aliases": [
        "machine-readable format"
      ],
      "types": [
        "representation",
        "data format",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A machine-readable format is a structured data format that can be easily processed and understood by computers, enabling automated data manipulation and analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-3",
          "local_name": "machine-readable format",
          "local_types": [
            "representation",
            "data format",
            "format"
          ],
          "iri": "Entity-machine-readable_format-Mention-1"
        }
      ],
      "relevance": 0.52880859375
    },
    "Entity-source_document_format": {
      "node_id": "source_document_format",
      "disambiguation_index": 0,
      "label": "source document formats",
      "aliases": [
        "source document formats"
      ],
      "types": [
        "document type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Source document formats refer to the various types of file formats used to store and present documents, which can include text files, PDFs, Word documents, and other digital formats that contain structured or unstructured information.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "source document formats",
          "local_types": [
            "document type"
          ],
          "iri": "Entity-source_document_format-Mention-1"
        }
      ],
      "relevance": 0.52685546875
    },
    "Entity-document_object_model": {
      "node_id": "document_object_model",
      "disambiguation_index": 0,
      "label": "document object model",
      "aliases": [
        "document object model"
      ],
      "types": [
        "model",
        "document object model",
        "data structure",
        "format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "The document object model is a programming interface that represents and interacts with the structure of a document, typically in HTML or XML format, allowing for dynamic manipulation of its content and structure.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "document object model",
          "local_types": [
            "data structure",
            "format"
          ],
          "iri": "Entity-document_object_model-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "document object model",
          "local_types": [
            "model",
            "document object model",
            "data structure"
          ],
          "iri": "Entity-document_object_model-Mention-2"
        }
      ],
      "relevance": 0.52587890625
    },
    "Entity-window": {
      "node_id": "window",
      "disambiguation_index": 0,
      "label": "Windows",
      "aliases": [
        "Windows"
      ],
      "types": [
        "operating system"
      ],
      "node_type": "named entity",
      "LLM_familiarity": false,
      "description": "Windows refers to the family of operating systems developed by Microsoft, which is required for processing OLE 2 file types and .docm documents using the MEL tool.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "Windows",
          "local_types": [
            "operating system"
          ],
          "iri": "Entity-window-Mention-1"
        }
      ],
      "relevance": 0.52392578125
    },
    "Entity-file_type_and_format": {
      "node_id": "file_type_and_format",
      "disambiguation_index": 0,
      "label": "file types and formats",
      "aliases": [
        "file types and formats"
      ],
      "types": [
        "data structure",
        "file format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "File types and formats refer to the specific structures and encodings used to organize and store data within files, determining how the data can be accessed, interpreted, and utilized by software applications.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-1",
          "local_name": "file types and formats",
          "local_types": [
            "data structure",
            "file format"
          ],
          "iri": "Entity-file_type_and_format-Mention-1"
        }
      ],
      "relevance": 0.52197265625
    },
    "Entity-configuration_json_file": {
      "node_id": "configuration_json_file",
      "disambiguation_index": 0,
      "label": "configuration JSON file",
      "aliases": [
        "configuration JSON file"
      ],
      "types": [
        "configuration document",
        "file",
        "configuration"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A configuration JSON file is a structured text file formatted in JSON that contains settings and parameters used to configure software applications or systems.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "configuration JSON file",
          "local_types": [
            "configuration document",
            "file",
            "configuration"
          ],
          "iri": "Entity-configuration_json_file-Mention-1"
        }
      ],
      "relevance": 0.52001953125
    },
    "Entity-data_cleaning": {
      "node_id": "data_cleaning",
      "disambiguation_index": 0,
      "label": "data cleaning",
      "aliases": [
        "data cleaning"
      ],
      "types": [
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Data cleaning is the process of identifying and correcting inaccuracies or inconsistencies in data to improve its quality and usability for analysis.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "data cleaning",
          "local_types": [
            "data processing"
          ],
          "iri": "Entity-data_cleaning-Mention-1"
        }
      ],
      "relevance": 0.517578125
    },
    "Entity-regular_expression": {
      "node_id": "regular_expression",
      "disambiguation_index": 0,
      "label": "regular expressions",
      "aliases": [
        "regular expressions"
      ],
      "types": [
        "regex",
        "programming tool",
        "pattern matching",
        "expression",
        "text analysis tool",
        "text processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Regular expressions are sequences of characters that form a search pattern, primarily used for string matching and manipulation in text processing and analysis.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-2",
          "local_name": "regular expressions",
          "local_types": [
            "programming tool",
            "pattern matching",
            "text analysis tool",
            "text processing"
          ],
          "iri": "Entity-regular_expression-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "regular expressions",
          "local_types": [
            "pattern matching",
            "text analysis tool",
            "regex",
            "expression"
          ],
          "iri": "Entity-regular_expression-Mention-2"
        }
      ],
      "relevance": 0.51611328125
    },
    "Entity-swiss_army_knife": {
      "node_id": "swiss_army_knife",
      "disambiguation_index": 0,
      "label": "Swiss army knife",
      "aliases": [
        "Swiss army knife"
      ],
      "types": [
        "metaphor",
        "tool"
      ],
      "node_type": "other",
      "LLM_familiarity": true,
      "description": "The term 'Swiss army knife' refers to a versatile tool or metaphor that signifies a comprehensive solution integrating multiple complementary methods and capabilities for metadata and content-based information extraction from diverse document formats.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "Swiss army knife",
          "local_types": [
            "metaphor",
            "tool"
          ],
          "iri": "Entity-swiss_army_knife-Mention-1"
        }
      ],
      "relevance": 0.51513671875
    },
    "Entity-data_cleaning_task": {
      "node_id": "data_cleaning_task",
      "disambiguation_index": 0,
      "label": "data cleaning tasks",
      "aliases": [
        "data cleaning tasks"
      ],
      "types": [
        "data processing",
        "task"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Data cleaning tasks refer to the processes and activities involved in identifying and correcting or removing inaccuracies, inconsistencies, and errors in datasets to improve their quality and usability.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "data cleaning tasks",
          "local_types": [
            "data processing",
            "task"
          ],
          "iri": "Entity-data_cleaning_task-Mention-1"
        }
      ],
      "relevance": 0.51416015625
    },
    "Entity-common_file_format": {
      "node_id": "common_file_format",
      "disambiguation_index": 0,
      "label": "common file formats",
      "aliases": [
        "common file formats"
      ],
      "types": [
        "file format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Common file formats refer to standardized ways of encoding information in digital files, allowing for consistent storage, retrieval, and sharing of data across different software and systems.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "common file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-common_file_format-Mention-1"
        },
        {
          "reference": "Section-5-Paragraph-1-Sentence-2",
          "local_name": "common file formats",
          "local_types": [
            "file format"
          ],
          "iri": "Entity-common_file_format-Mention-2"
        }
      ],
      "relevance": 0.5126953125
    },
    "Entity-supported_file_type": {
      "node_id": "supported_file_type",
      "disambiguation_index": 0,
      "label": "supported file types",
      "aliases": [
        "supported file types"
      ],
      "types": [
        "file type"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Supported file types refer to the various formats of files that a system, application, or service can recognize, process, or utilize.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "supported file types",
          "local_types": [
            "file type"
          ],
          "iri": "Entity-supported_file_type-Mention-1"
        }
      ],
      "relevance": 0.51171875
    },
    "Entity-ole_2_file_type": {
      "node_id": "ole_2_file_type",
      "disambiguation_index": 0,
      "label": "OLE 2 file types",
      "aliases": [
        "OLE 2 file types"
      ],
      "types": [
        "data structure",
        "data format",
        "file format",
        "file type",
        "document format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "OLE 2 file types refer to a set of file formats and data structures used for storing and managing compound documents that can contain various types of data, such as text, images, and other media, typically associated with Microsoft applications.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "OLE 2 file types",
          "local_types": [
            "file type",
            "document format",
            "data format",
            "file format"
          ],
          "iri": "Entity-ole_2_file_type-Mention-1"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-9",
          "local_name": "OLE 2 file types",
          "local_types": [
            "file type",
            "data structure",
            "file format"
          ],
          "iri": "Entity-ole_2_file_type-Mention-2"
        }
      ],
      "relevance": 0.51025390625
    },
    "Entity-pre-processing": {
      "node_id": "pre-processing",
      "disambiguation_index": 0,
      "label": "pre-processing",
      "aliases": [
        "pre-processing"
      ],
      "types": [
        "data cleaning",
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pre-processing refers to the initial steps taken to prepare and clean data before it is analyzed or processed further.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "pre-processing",
          "local_types": [
            "data cleaning",
            "data processing"
          ],
          "iri": "Entity-pre-processing-Mention-1"
        }
      ],
      "relevance": 0.509765625
    },
    "Entity-pre-processing_task": {
      "node_id": "pre-processing_task",
      "disambiguation_index": 0,
      "label": "pre-processing tasks",
      "aliases": [
        "pre-processing tasks"
      ],
      "types": [
        "task",
        "data processing"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Pre-processing tasks refer to a set of operations or activities performed on data to prepare it for further analysis or processing, often involving cleaning, transforming, and organizing the data.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "pre-processing tasks",
          "local_types": [
            "task",
            "data processing"
          ],
          "iri": "Entity-pre-processing_task-Mention-1"
        }
      ],
      "relevance": 0.50732421875
    },
    "Entity-json_structure": {
      "node_id": "json_structure",
      "disambiguation_index": 0,
      "label": "JSON structures",
      "aliases": [
        "JSON structures"
      ],
      "types": [
        "data format",
        "JSON"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON structures refer to data representations that utilize the JavaScript Object Notation (JSON) format, which is a lightweight and human-readable way to store and exchange structured data.",
      "mentions": [
        {
          "reference": "Section-5-Paragraph-1-Sentence-3",
          "local_name": "JSON structures",
          "local_types": [
            "data format",
            "JSON"
          ],
          "iri": "Entity-json_structure-Mention-1"
        }
      ],
      "relevance": 0.5068359375
    },
    "Entity-json_result": {
      "node_id": "json_result",
      "disambiguation_index": 0,
      "label": "JSON results",
      "aliases": [
        "JSON results"
      ],
      "types": [
        "data format"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "JSON results refer to data formatted in JavaScript Object Notation (JSON), which is a lightweight data interchange format that is easy for humans to read and write, and easy for machines to parse and generate.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "JSON results",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-json_result-Mention-1"
        }
      ],
      "relevance": 0.5068359375
    },
    "Entity-file_type": {
      "node_id": "file_type",
      "disambiguation_index": 0,
      "label": "file types",
      "aliases": [
        "file types",
        "file type"
      ],
      "types": [
        "data format",
        "file format",
        "data type",
        "document type",
        "file category",
        "information type",
        "file"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "File types refer to the various formats or categories of files that define how data is stored and organized within a computer system.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "file types",
          "local_types": [
            "data type",
            "data format",
            "file format"
          ],
          "iri": "Entity-file_type-Mention-1"
        },
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "file type",
          "local_types": [
            "data format"
          ],
          "iri": "Entity-file_type-Mention-2"
        },
        {
          "reference": "Section-3-Paragraph-1-Sentence-6",
          "local_name": "file types",
          "local_types": [
            "data format",
            "document type"
          ],
          "iri": "Entity-file_type-Mention-3"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-2",
          "local_name": "file types",
          "local_types": [
            "data type",
            "file category",
            "file",
            "data format"
          ],
          "iri": "Entity-file_type-Mention-4"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-6",
          "local_name": "file type",
          "local_types": [
            "data format",
            "information type"
          ],
          "iri": "Entity-file_type-Mention-5"
        }
      ],
      "relevance": 0.50390625
    },
    "Entity-unstructured_information": {
      "node_id": "unstructured_information",
      "disambiguation_index": 0,
      "label": "unstructured information",
      "aliases": [
        "unstructured information"
      ],
      "types": [
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Unstructured information refers to data that does not have a predefined data model or is not organized in a predefined manner, making it difficult to analyze and process using traditional data processing techniques.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-3",
          "local_name": "unstructured information",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-unstructured_information-Mention-1"
        }
      ],
      "relevance": 0.49853515625
    },
    "Entity-file_extension_mapping": {
      "node_id": "file_extension_mapping",
      "disambiguation_index": 0,
      "label": "file extension mappings",
      "aliases": [
        "file extension mappings"
      ],
      "types": [
        "file extension",
        "configuration",
        "file handling",
        "file type",
        "mapping"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "File extension mappings refer to the associations between specific file extensions and their corresponding file types or formats, often used in configuration settings to determine how files should be processed or handled by software applications.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-5",
          "local_name": "file extension mappings",
          "local_types": [
            "file extension",
            "configuration",
            "file handling",
            "file type",
            "mapping"
          ],
          "iri": "Entity-file_extension_mapping-Mention-1"
        }
      ],
      "relevance": 0.4970703125
    },
    "Entity-source_document": {
      "node_id": "source_document",
      "disambiguation_index": 0,
      "label": "source document",
      "aliases": [
        "source document"
      ],
      "types": [
        "reference material",
        "document"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "A source document is a reference material that provides original information or data, typically in written form, used for analysis or research.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-2",
          "local_name": "source document",
          "local_types": [
            "reference material",
            "document"
          ],
          "iri": "Entity-source_document-Mention-1"
        }
      ],
      "relevance": 0.49609375
    },
    "Entity-.docm": {
      "node_id": ".docm",
      "disambiguation_index": 0,
      "label": ".docm",
      "aliases": [
        ".docm"
      ],
      "types": [
        "file type",
        "document format",
        "document",
        "file format"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": ".docm is a file format used for Microsoft Word documents that contain macros, allowing for enhanced functionality and automation within the document.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": ".docm",
          "local_types": [
            "file type",
            "document format",
            "document",
            "file format"
          ],
          "iri": "Entity-.docm-Mention-1"
        }
      ],
      "relevance": 0.495849609375
    },
    "Entity-named_entity": {
      "node_id": "named_entity",
      "disambiguation_index": 0,
      "label": "named entities",
      "aliases": [
        "named entities"
      ],
      "types": [
        "entity",
        "data type",
        "data",
        "information"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Named entities are specific terms or phrases that refer to distinct objects, individuals, organizations, or locations within a given context, often used in natural language processing to identify and categorize relevant information.",
      "mentions": [
        {
          "reference": "Section-2-Paragraph-1-Sentence-4",
          "local_name": "named entities",
          "local_types": [
            "entity",
            "data type",
            "information"
          ],
          "iri": "Entity-named_entity-Mention-1"
        },
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "named entities",
          "local_types": [
            "data",
            "information"
          ],
          "iri": "Entity-named_entity-Mention-2"
        }
      ],
      "relevance": 0.495849609375
    },
    "Entity-nlp": {
      "node_id": "nlp",
      "disambiguation_index": 0,
      "label": "NLP",
      "aliases": [
        "NLP"
      ],
      "types": [
        "field",
        "technology"
      ],
      "node_type": "named entity",
      "LLM_familiarity": true,
      "description": "NLP refers to Natural Language Processing, a field of artificial intelligence that focuses on the interaction between computers and human language, enabling machines to understand, interpret, and generate human language in a meaningful way.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-7",
          "local_name": "NLP",
          "local_types": [
            "field",
            "technology"
          ],
          "iri": "Entity-nlp-Mention-1"
        }
      ],
      "relevance": 0.478759765625
    },
    "Entity-opensource_package_and_tool": {
      "node_id": "opensource_package_and_tool",
      "disambiguation_index": 0,
      "label": "opensource packages and tools",
      "aliases": [
        "opensource packages and tools",
        "various opensource packages and tools"
      ],
      "types": [
        "tool",
        "software"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Opensource packages and tools refer to software components and utilities that are freely available for use, modification, and distribution, often developed collaboratively in a community-driven environment.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "opensource packages and tools",
          "local_types": [
            "tool",
            "software"
          ],
          "iri": "Entity-opensource_package_and_tool-Mention-1"
        },
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "various opensource packages and tools",
          "local_types": [
            "software",
            "tool"
          ],
          "iri": "Entity-opensource_package_and_tool-Mention-2"
        }
      ],
      "relevance": 0.464111328125
    },
    "Entity-java": {
      "node_id": "java",
      "disambiguation_index": 0,
      "label": "Java",
      "aliases": [
        "Java"
      ],
      "types": [
        "programming language"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-4",
          "local_name": "Java",
          "local_types": [
            "programming language"
          ],
          "iri": "Entity-java-Mention-1"
        }
      ],
      "relevance": 0.430419921875
    },
    "Entity-opensource_package": {
      "node_id": "opensource_package",
      "disambiguation_index": 0,
      "label": "opensource packages",
      "aliases": [
        "opensource packages"
      ],
      "types": [
        "software",
        "library"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Opensource packages are software components or libraries that are made available to the public with a license that allows users to freely use, modify, and distribute the software.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-3",
          "local_name": "opensource packages",
          "local_types": [
            "software",
            "library"
          ],
          "iri": "Entity-opensource_package-Mention-1"
        }
      ],
      "relevance": 0.418701171875
    },
    "Entity-window_operating_system": {
      "node_id": "window_operating_system",
      "disambiguation_index": 0,
      "label": "Windows operating systems",
      "aliases": [
        "Windows operating systems"
      ],
      "types": [
        "operating system",
        "software platform"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Windows operating systems are a family of operating systems developed by Microsoft, designed to run on personal computers and provide a graphical user interface for users.",
      "mentions": [
        {
          "reference": "Section-3-Paragraph-1-Sentence-8",
          "local_name": "Windows operating systems",
          "local_types": [
            "operating system",
            "software platform"
          ],
          "iri": "Entity-window_operating_system-Mention-1"
        }
      ],
      "relevance": 0.41162109375
    },
    "Entity-configurable_setting": {
      "node_id": "configurable_setting",
      "disambiguation_index": 0,
      "label": "configurable settings",
      "aliases": [
        "configurable settings"
      ],
      "types": [
        "settings",
        "configuration",
        "parameter"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Configurable settings refer to adjustable parameters or options within a system or application that allow users to customize its behavior or functionality according to their preferences.",
      "mentions": [
        {
          "reference": "Section-1-Paragraph-1-Sentence-5",
          "local_name": "configurable settings",
          "local_types": [
            "settings",
            "configuration",
            "parameter"
          ],
          "iri": "Entity-configurable_setting-Mention-1"
        }
      ],
      "relevance": 0.402099609375
    },
    "Entity-figure_1": {
      "node_id": "figure_1",
      "disambiguation_index": 0,
      "label": "Figure 1",
      "aliases": [
        "Figure 1"
      ],
      "types": [
        "illustration",
        "figure",
        "visual representation"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Figure 1 is a visual representation that illustrates a specific concept or data related to the content of the paper.",
      "mentions": [
        {
          "reference": "Section-4-Paragraph-1-Sentence-1",
          "local_name": "Figure 1",
          "local_types": [
            "illustration",
            "figure",
            "visual representation"
          ],
          "iri": "Entity-figure_1-Mention-1"
        }
      ],
      "relevance": 0.400634765625
    },
    "Entity-general_purpose": {
      "node_id": "general_purpose",
      "disambiguation_index": 0,
      "label": "general purpose",
      "aliases": [
        "general purpose"
      ],
      "types": [
        "application domain",
        "purpose"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "General purpose refers to a broad applicability or functionality that is not limited to a specific domain or use case.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-1",
          "local_name": "general purpose",
          "local_types": [
            "application domain",
            "purpose"
          ],
          "iri": "Entity-general_purpose-Mention-1"
        }
      ],
      "relevance": 0.399658203125
    },
    "Entity-vocabulary": {
      "node_id": "vocabulary",
      "disambiguation_index": 0,
      "label": "vocabulary",
      "aliases": [
        "vocabulary"
      ],
      "types": [
        "terminology",
        "vocabulary",
        "ontology"
      ],
      "node_type": "general term",
      "LLM_familiarity": true,
      "description": "Vocabulary refers to the set of words and phrases used within a particular language, field, or context, often encompassing terminology and concepts relevant to that area.",
      "mentions": [
        {
          "reference": "Section-6-Paragraph-1-Sentence-3",
          "local_name": "vocabulary",
          "local_types": [
            "terminology",
            "vocabulary",
            "ontology"
          ],
          "iri": "Entity-vocabulary-Mention-1"
        }
      ],
      "relevance": 0.3974609375
    }
  },
  "summary": "The metadata and content-based information extraction tasks from heterogeneous file sets are pre-processing steps of many Knowledge Graph Construction Pipelines (KGCP). These tasks often take longer than necessary due to the lack of proper tools that integrate several complementary extraction methods and properties to get a rich output set. This paper presents MEL, a Python-based tool that implements a set of methods to extract metadata and content-based information from unstructured information encoded in different source document formats. The results are generated as JSON files, which can: (a) optionally be stored in a document store, and (b) easily be mapped to RDF using a variety of tools such as J2RM. MEL supports more than 20 different file types, making it a versatile tool that aids pre-processing tasks as part of a KGCP based on comprehensive configurable settings.\n\nThis paper introduces MEL, a tool that implements a set of methods to extract metadata and content-based information from various file formats as JSON objects. For each supported file type, MEL extracts the textual content from the source document and performs specific pre-processing and data cleaning tasks. Also, it performs basic text analysis tasks (pattern matching and keyword extraction) and generates the results in a machine-readable format (JSON), preparing the ground for content-based analysis. MEL is integrated with \u201cThe NLP -NER Toolkit\u201d (TNNT), which automates the extraction task of categorised named entities from the MEL results by using diverse state-of-the-art NLP tools and NER models [5]. MEL implements primitives for metadata and content extraction from unstructured data sets of heterogeneous formats, and along with the TNNT results, it provides the groundwork for content-based analysis. MEL and TNNT were developed in conjunction with J2RM [4], to easily map the JSON results to RDF as part of an automated KGCP.\n\nMEL has comprehensive metadata extraction support of various file types and formats. In a nutshell: (1) it takes as input a document (file) set; (2) then, for each document, it extracts its related metadata and content-based information, while performing basic text analysis (such as applying a configurable set of regular expressions and keyword extraction task); and, (3) as output, it generates a JSON file with the extracted metadata and text content with a structure based on the supported formats' document object model. It can store the results in a document store. MEL's general output structure is presented in Table 1. MEL has a detailed configuration JSON file that defines how the processing will be performed through a set of parameters and flags that establish the initial settings related to the document store, input document sets, TNNT general configuration, file extension mappings, the \u201cAssociated-Metadata\u201d processing (Table 1), and regular expressions to apply in the text analysis task, among other settings. The supported file types are presented in Table 2. The third column shows the theoretical number of attributes that the tool is able to extract per document type, whilst the fourth column shows the average of the extracted attributes from four use case document sets. OLE 2 file types and .docm can only be processed on Windows operating systems. Specifically for OLE 2 file types, MEL uses the olemeta tool.\n\nMEL is fully integrated with TNNT as depicted in Figure 1. The set of Python-based methods implemented in MEL are generic and can be applied to extract the content and metadata of all supported file types. MEL uses various opensource packages and tools with complementary capabilities to form a \u201cSwiss army knife\u201d of metadata and content-based information extraction from heterogeneous document sets. As part of the \u201cGeneral-Metadata\u201d extraction task, MEL optionally uses the XML output from the NLNZ Metadata Extractor tool, a Java standalone tool that extracts a comprehensive attribute and property list from dozens of file formats. The MEL general processing model is presented in Figure 2. It is important to note that each file type has its own specific processing model as well as the text analysis task, which is the last step that is performed for any output.\n\nThe most comprehensive and current state-of-the-art tool for content extraction and analysis is Apache Tika, which is a complete and complex Java-based general-purpose system. While MEL's core goals resemble the ones of Apache Tika, the main difference and benefit of MEL as compared to Apache Tika is that it is a lightweight Python-based package for the metadata extraction of common file formats aimed to be used in a KGCP. Although there is a wide range of Python-based tools and libraries for metadata extraction, to the best of our knowledge, there is no package available that fully integrates in one system a comprehensive set of methods for metadata and content extraction of common file formats that generate the results in JSON structures based on the document object model of each format type. Last, MEL can assist in the information extraction stage of several KGCPs, such as the ones described in [6], [2], and [3].\n\nMEL provides a versatile mechanism to extract metadata and content-based information from unstructured data sets of heterogeneous file formats, agnostic of the data sets' domain (general purpose). It has been tested over thousands of documents using different formats and datasets as part of the AGRIF project. Based on the structure of the MEL's JSON results, it is possible to easily add a vocabulary or light-weight ontology using JSON-LD annotations, in order to make the extracted metadata \u201cRDF ready\u201d. This will be explored in the near future leveraging on the integration with JSON-LD ontologies. More file formats will be added in a per use-case requirements basis, in order to support KGCP tasks. Additionally, a project to \u201ccontainerise\u201d the MEL+TNNT tools is planned in the near future. The major contributions of this tool are: (1) the ability to extract metadata sets and content-based information from different source document formats; (2) the comprehensive support of over 20 different file types/formats integrated into one easy-to-use Python-based system; (3) integration with TNNT which automates the extraction of categorised named entities from the results by using diverse state-of-the-art NLP tools and NER models; and (4) the JSON result files can be easily mapped to RDF using J2RM.",
  "triples": [
    [
      "Entity-metadata_and_content-based_information_extraction_task",
      "Predicate-are_pre-processing_steps_of",
      "Entity-kgcp"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction_task",
      "Predicate-are_pre-processing_steps_of",
      "Entity-knowledge_graph_construction_pipeline"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction_task",
      "Predicate-are",
      "Entity-pre-processing_step"
    ],
    [
      "Entity-several_complementary_extraction_method",
      "Predicate-get",
      "Entity-output_set"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-mel"
    ],
    [
      "Entity-mel",
      "Predicate-is_a",
      "Entity-python-based_tool"
    ],
    [
      "Entity-mel",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-metadata"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-content-based_information"
    ],
    [
      "Entity-mel",
      "Predicate-extracts_from",
      "Entity-unstructured_information"
    ],
    [
      "Entity-unstructured_information",
      "Predicate-encoded_in",
      "Entity-format"
    ],
    [
      "Entity-mel",
      "Predicate-is",
      "Entity-mel"
    ],
    [
      "Entity-result",
      "Predicate-generated_as",
      "Entity-json_file"
    ],
    [
      "Entity-json_file",
      "Predicate-mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-json_file",
      "Predicate-stored_in",
      "Entity-document_store"
    ],
    [
      "Entity-json_file",
      "Predicate-mapped_to",
      "Entity-variety_of_tool"
    ],
    [
      "Entity-json_file",
      "Predicate-can_be_mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-mel",
      "Predicate-supports",
      "Entity-more_than_20_different_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-aids",
      "Entity-pre-processing_task"
    ],
    [
      "Entity-kgcp",
      "Predicate-is_based_on",
      "Entity-comprehensive_configurable_setting"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-mel"
    ],
    [
      "Entity-mel",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-metadata"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-content-based_information"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts_from",
      "Entity-format"
    ],
    [
      "Entity-format",
      "Predicate-are_represented_as",
      "Entity-json_object"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-textual_content"
    ],
    [
      "Entity-mel",
      "Predicate-performs",
      "Entity-specific_pre-processing_and_data_cleaning_task"
    ],
    [
      "Entity-basic_text_analysis_task",
      "Predicate-performs",
      "Entity-pattern_matching_and_keyword_extraction"
    ],
    [
      "Entity-basic_text_analysis_task",
      "Predicate-generates",
      "Entity-result_in_a_machine-readable_format"
    ],
    [
      "Entity-result",
      "Predicate-in",
      "Entity-machine-readable_format"
    ],
    [
      "Entity-result",
      "Predicate-prepares_the_ground_for",
      "Entity-content-based_analysis"
    ],
    [
      "Entity-mel",
      "Predicate-is_integrated_with",
      "Entity-the_nlp_-ner_toolkit"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-automates_the_extraction_task_of",
      "Entity-categorised_named_entity"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-uses",
      "Entity-diverse_state-of-the-art_nlp_tool_and_ner_model"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-extracts",
      "Entity-named_entity"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-extracts_from",
      "Entity-output"
    ],
    [
      "Entity-mel",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-extracts_from",
      "Entity-unstructured_data_set_of_heterogeneous_format"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-results_along_with",
      "Entity-mel"
    ],
    [
      "Entity-mel",
      "Predicate-developed_in_conjunction_with",
      "Entity-j2rm"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "Predicate-developed_in_conjunction_with",
      "Entity-j2rm"
    ],
    [
      "Entity-result_in_a_machine-readable_format",
      "Predicate-mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-automated_kgcp",
      "Predicate-part_of",
      "Entity-kgcp"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-result_in_a_machine-readable_format"
    ],
    [
      "Entity-mel",
      "Predicate-has",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-of",
      "Entity-various_file_type_and_format"
    ],
    [
      "Entity-document__file__set",
      "Predicate-takes_as_input",
      "Entity-document"
    ],
    [
      "Entity-document",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-document",
      "Predicate-extracts",
      "Entity-content-based_information"
    ],
    [
      "Entity-document",
      "Predicate-performs",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-basic_text_analysis",
      "Predicate-applies",
      "Entity-configurable_set_of_regular_expression"
    ],
    [
      "Entity-document",
      "Predicate-generates",
      "Entity-a_json_file"
    ],
    [
      "Entity-a_json_file",
      "Predicate-contains",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-a_json_file",
      "Predicate-has_a_structure_based_on",
      "Entity-supported_format__document_object_model"
    ],
    [
      "Entity-it",
      "Predicate-can_store",
      "Entity-output"
    ],
    [
      "Entity-output",
      "Predicate-in",
      "Entity-document_store"
    ],
    [
      "Entity-output_structure",
      "Predicate-is_presented_in",
      "Entity-table_1"
    ],
    [
      "Entity-various_file_type_and_format",
      "Predicate-is_presented_in",
      "Entity-table_2"
    ],
    [
      "Entity-supported_file_type",
      "Predicate-is_presented_in",
      "Entity-table_2"
    ],
    [
      "Entity-file_type",
      "Predicate-is_presented_in",
      "Entity-table_2"
    ],
    [
      "Entity-mel",
      "Predicate-is_able_to_extract",
      "Entity-attribute"
    ],
    [
      "Entity-theoretical_number_of_attribute",
      "Predicate-shows",
      "Entity-mel"
    ],
    [
      "Entity-average_of_the_extracted_attribute",
      "Predicate-is_from",
      "Entity-four_use_case_document_set"
    ],
    [
      "Entity-theoretical_number_of_attribute",
      "Predicate-is_for",
      "Entity-document_type"
    ],
    [
      "Entity-theoretical_number_of_attribute",
      "Predicate-is_able_to_extract",
      "Entity-document_type"
    ],
    [
      "Entity-average_of_the_extracted_attribute",
      "Predicate-shows",
      "Entity-average_of_the_extracted_attribute"
    ],
    [
      "Entity-ole_2_file_type",
      "Predicate-can_be_processed_on",
      "Entity-window_operating_system"
    ],
    [
      "Entity-.docm",
      "Predicate-can_be_processed_on",
      "Entity-window_operating_system"
    ],
    [
      "Entity-ole_2_file_type",
      "Predicate-can_only_be_processed_on",
      "Entity-window_operating_system"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-olemeta"
    ],
    [
      "Entity-olemeta",
      "Predicate-is_used_for",
      "Entity-ole_2_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-a_json_file"
    ],
    [
      "Entity-mel",
      "Predicate-performs",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-python-based_method",
      "Predicate-implemented_in",
      "Entity-mel"
    ],
    [
      "Entity-python-based_method",
      "Predicate-applied_to_extract",
      "Entity-content_and_metadata"
    ],
    [
      "Entity-content_and_metadata",
      "Predicate-of",
      "Entity-various_file_type_and_format"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-content_and_metadata"
    ],
    [
      "Entity-mel",
      "Predicate-applies_to",
      "Entity-various_file_type_and_format"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-metadata"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-opensource_package_and_tool"
    ],
    [
      "Entity-opensource_package_and_tool",
      "Predicate-have",
      "Entity-complementary_capability"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "Predicate-is_based_on",
      "Entity-heterogeneous_document_set"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-xml_output"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "Predicate-is_a",
      "Entity-nlnz_metadata_extractor"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "Predicate-extracts",
      "Entity-attribute_and_property_list"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "Predicate-extracts_from",
      "Entity-dozen_of_file_format"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-nlnz_metadata_extractor_tool"
    ],
    [
      "Entity-nlnz_metadata_extractor_tool",
      "Predicate-is_a",
      "Entity-nlnz_metadata_extractor"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-is_presented_in_(1)",
      "Entity-figure_2"
    ],
    [
      "Entity-text_analysis_task",
      "Predicate-is",
      "Entity-the_last_step"
    ],
    [
      "Entity-text_analysis_task",
      "Predicate-is_performed_for",
      "Entity-any_output"
    ],
    [
      "Entity-file_type",
      "Predicate-has",
      "Entity-specific_processing_model"
    ],
    [
      "Entity-text_analysis_task",
      "Predicate-is_the_last_step_of",
      "Entity-any_output"
    ],
    [
      "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "Predicate-is",
      "Entity-apache_tika"
    ],
    [
      "Entity-apache_tika",
      "Predicate-is_a",
      "Entity-java-based_general-purpose_system"
    ],
    [
      "Entity-mel",
      "Predicate-resembles",
      "Entity-apache_tika"
    ],
    [
      "Entity-mel",
      "Predicate-is_aimed_to_be_used_in",
      "Entity-kgcp"
    ],
    [
      "Entity-mel",
      "Predicate-is_for",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-metadata_extraction",
      "Predicate-of",
      "Entity-common_file_format"
    ],
    [
      "Entity-common_file_format",
      "Predicate-are_used_in",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-python-based_tool_and_library",
      "Predicate-are_used_for",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-package",
      "Predicate-integrates",
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction"
    ],
    [
      "Entity-common_file_format",
      "Predicate-generate",
      "Entity-json_structure"
    ],
    [
      "Entity-json_structure",
      "Predicate-are_based_on",
      "Entity-document_object_model"
    ],
    [
      "Entity-python-based_tool_and_library",
      "Predicate-are_available_for",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-metadata_and_content_extraction",
      "Predicate-is_a_comprehensive_set_of_methods_for",
      "Entity-common_file_format"
    ],
    [
      "Entity-metadata_extraction",
      "Predicate-is_available_in",
      "Entity-python-based_tool_and_library"
    ],
    [
      "Entity-mel",
      "Predicate-provides",
      "Entity-a_versatile_mechanism"
    ],
    [
      "Entity-a_versatile_mechanism",
      "Predicate-to_extract",
      "Entity-metadata_and_content-based_information"
    ],
    [
      "Entity-a_versatile_mechanism",
      "Predicate-to_extract",
      "Entity-unstructured_data_set"
    ],
    [
      "Entity-a_versatile_mechanism",
      "Predicate-to_extract",
      "Entity-content-based_information"
    ],
    [
      "Entity-unstructured_data_set",
      "Predicate-of",
      "Entity-heterogeneous_format"
    ],
    [
      "Entity-data_set",
      "Predicate-of",
      "Entity-general_purpose"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-content-based_information"
    ],
    [
      "Entity-agrif",
      "Predicate-tested_over",
      "Entity-thousand_of_document"
    ],
    [
      "Entity-agrif",
      "Predicate-tested_using",
      "Entity-format"
    ],
    [
      "Entity-agrif",
      "Predicate-tested_using",
      "Entity-data_set"
    ],
    [
      "Entity-mel",
      "Predicate-has",
      "Entity-json_result"
    ],
    [
      "Entity-json-ld_annotation",
      "Predicate-are_used_to_add",
      "Entity-vocabulary_or_light-weight_ontology"
    ],
    [
      "Entity-extracted_metadata",
      "Predicate-is_made",
      "Entity-rdf_ready"
    ],
    [
      "Entity-json_result",
      "Predicate-can_be_mapped_to",
      "Entity-rdf"
    ],
    [
      "Entity-the_integration_with_json-ld_ontology",
      "Predicate-leverages",
      "Entity-json-ld_ontology"
    ],
    [
      "Entity-file_format",
      "Predicate-will_be_added_in",
      "Entity-per_use-case_requirement_basis"
    ],
    [
      "Entity-file_format",
      "Predicate-supports",
      "Entity-task"
    ],
    [
      "Entity-project",
      "Predicate-is_planned_to",
      "Entity-a_project_to__containerise__the_meltnnt_tool"
    ],
    [
      "Entity-a_project_to__containerise__the_meltnnt_tool",
      "Predicate-involves",
      "Entity-meltnnt"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-metadata_set"
    ],
    [
      "Entity-mel",
      "Predicate-integrates_with",
      "Entity-the_nlp_-ner_toolkit"
    ],
    [
      "Entity-mel",
      "Predicate-uses",
      "Entity-state-of-the-art_nlp_tool_and_ner_model"
    ],
    [
      "Entity-mel",
      "Predicate-has_comprehensive_support_of",
      "Entity-more_than_20_different_file_type"
    ],
    [
      "Entity-mel",
      "Predicate-has_been_tested_over",
      "Entity-thousand_of_document"
    ],
    [
      "Entity-mel",
      "Predicate-supports",
      "Entity-task"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-meltnnt",
      "Predicate-integrates",
      "Entity-mel"
    ],
    [
      "Entity-mel",
      "Predicate-is_a",
      "Entity-package"
    ],
    [
      "Entity-mel",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-describes_the_systematic_approach_and_methods_used_by",
      "Entity-mel"
    ],
    [
      "Entity-table_1",
      "Predicate-presents_the_general_output_structure_of",
      "Entity-mel"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-package",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-implement",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-extracts",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-implement",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-mel_s_json_result",
      "Predicate-generated_as",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-meltnnt",
      "Predicate-integrates",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-package",
      "Predicate-produces",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "Predicate-includes",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-describes_the_systematic_approach_for_extracting",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-primitive_for_metadata_and_content_extraction",
      "Predicate-facilitate",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-mel_s_json_result",
      "Predicate-generate",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-meltnnt",
      "Predicate-integrates",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-package",
      "Predicate-produces",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-mel_s_json_result",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-mel_s_json_result",
      "Predicate-contains",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-mel_s_json_result",
      "Predicate-implement",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-meltnnt"
    ],
    [
      "Entity-meltnnt",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-package",
      "Predicate-is_a_component_of",
      "Entity-meltnnt"
    ],
    [
      "Entity-meltnnt",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-meltnnt",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-meltnnt",
      "Predicate-presents_the_general_output_structure_of",
      "Entity-table_1"
    ],
    [
      "Entity-meltnnt",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-package"
    ],
    [
      "Entity-package",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-table_1",
      "Predicate-presents_the_general_output_structure_of",
      "Entity-package"
    ],
    [
      "Entity-package",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-implements",
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-produces",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-produces",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-integrates",
      "Entity-meltnnt"
    ],
    [
      "Entity-package",
      "Predicate-implements",
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-implements",
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-extracts_metadata_and_content_from",
      "Entity-document__file__set"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-extracts_metadata_and_content_from",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-output_set"
    ],
    [
      "Entity-package",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-output_set",
      "Predicate-includes",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-output_set"
    ],
    [
      "Entity-output_set",
      "Predicate-generate",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-facilitates_the_extraction_of",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-generates",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-meltnnt",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-package",
      "Predicate-provides",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-provides",
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-facilitates_the_extraction_of",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-supports",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-facilitates_the_extraction_of",
      "Entity-content"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-is_presented_in_(1)",
      "Entity-table_1"
    ],
    [
      "Entity-document__file__set",
      "Predicate-supports",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-supports",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-comprehensive_metadata_extraction_support",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-describes_the_systematic_approach_and_methods_used_by",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-generates",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-integrates",
      "Entity-meltnnt"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-implements",
      "Entity-package"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-presents",
      "Entity-table_1"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-content"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-content",
      "Predicate-is_extracted_as",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-content",
      "Predicate-generate",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-meltnnt",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-package",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-content",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-content",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-is_used_by",
      "Entity-content"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-content"
    ],
    [
      "Entity-document__file__set",
      "Predicate-is_extracted_from",
      "Entity-content"
    ],
    [
      "Entity-different_source_document_format",
      "Predicate-is_extracted_from",
      "Entity-content"
    ],
    [
      "Entity-primitive_for_metadata_and_content_extraction",
      "Predicate-facilitates_the_extraction_of",
      "Entity-content"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-implements",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-generate",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-meltnnt",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-package",
      "Predicate-integrates",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "Predicate-implements",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-enables",
      "Entity-comprehensive_metadata_extraction_support"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-implements",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts",
      "Entity-content"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-a_set_of_method"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts_information_from",
      "Entity-document__file__set"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-extracts_information_from",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-a_set_of_method",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-presents",
      "Entity-table_1"
    ],
    [
      "Entity-mel",
      "Predicate-processes",
      "Entity-document__file__set"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-document__file__set"
    ],
    [
      "Entity-document__file__set",
      "Predicate-utilizes",
      "Entity-method_to_extract_metadata_and_content-based_information"
    ],
    [
      "Entity-document__file__set",
      "Predicate-extracts",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-document__file__set",
      "Predicate-generates",
      "Entity-mel_s_json_result"
    ],
    [
      "Entity-meltnnt",
      "Predicate-is_input_into",
      "Entity-document__file__set"
    ],
    [
      "Entity-package",
      "Predicate-processes",
      "Entity-document__file__set"
    ],
    [
      "Entity-document__file__set",
      "Predicate-generates",
      "Entity-output_set"
    ],
    [
      "Entity-document__file__set",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-document__file__set",
      "Predicate-is_input_to",
      "Entity-mel_general_processing_model"
    ],
    [
      "Entity-document__file__set",
      "Predicate-presents",
      "Entity-table_1"
    ],
    [
      "Entity-document__file__set",
      "Predicate-implements",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-mel",
      "Predicate-extracts_metadata_and_content_from",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "Predicate-implement",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-different_source_document_format",
      "Predicate-extracts",
      "Entity-extracted_metadata_and_text_content"
    ],
    [
      "Entity-mel_s_json_result",
      "Predicate-extracts_metadata_and_content_from",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-meltnnt",
      "Predicate-extracts_metadata_and_content_from",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-package",
      "Predicate-extracts_metadata_and_content_from",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-different_source_document_format",
      "Predicate-extracts",
      "Entity-output_set"
    ],
    [
      "Entity-different_source_document_format",
      "Predicate-extracts",
      "Entity-related_metadata_and_content-based_information"
    ],
    [
      "Entity-mel_general_processing_model",
      "Predicate-supports",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-table_1",
      "Predicate-presents",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-document__file__set",
      "Predicate-is_input_to",
      "Entity-different_source_document_format"
    ],
    [
      "Entity-different_source_document_format",
      "Predicate-facilitates_the_extraction_of",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-this_paper",
      "Predicate-introduces",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "Predicate-facilitates_the_extraction_of",
      "Entity-primitive_for_metadata_and_content_extraction"
    ],
    [
      "Entity-table_1",
      "Predicate-presents_the_general_output_structure_of",
      "Entity-primitive_for_metadata_and_content_extraction"
    ]
  ],
  "triples_typing": [
    [
      "Entity-property",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-machine-readable_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-file_type",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-file_extension_mapping",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-json_structure",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-nlnz_metadata_extractor_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-associated-metadata",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-dozen_of_file_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-tnnt_result",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-pattern_matching_and_keyword_extraction",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-keyword_extraction_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-textual_content",
      "skos:broader",
      "Entity-content"
    ],
    [
      "Entity-meltnnt",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-apache_tika",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-basic_text_analysis",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-mel_s_json_result",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-nlnz_metadata_extractor",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-output_structure",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-rdf",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-swiss_army_knife",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-heterogeneous_file_set",
      "skos:broader",
      "Entity-data_set"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-supported_format__document_object_model",
      "skos:broader",
      "Entity-document_object_model"
    ],
    [
      "Entity-mel_s_json_result",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-mel_general_processing_model",
      "skos:broader",
      "Entity-processing"
    ],
    [
      "Entity-json-ld_annotation",
      "skos:broader",
      "Entity-json-ld_ontology"
    ],
    [
      "Entity-json_result_file",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-a_json_file",
      "skos:broader",
      "Entity-json_result"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-extracted_metadata"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata_and_content-based_information_extraction"
    ],
    [
      "Entity-various_file_type_and_format",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-format",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-metadata_and_content_extraction"
    ],
    [
      "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-heterogeneous_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-xml_output",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-file_type",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-source_document",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-json",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json_structure",
      "skos:broader",
      "Entity-json_result"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-basic_text_analysis"
    ],
    [
      "Entity-unstructured_data_set_of_heterogeneous_format",
      "skos:broader",
      "Entity-data_set"
    ],
    [
      "Entity-specific_pre-processing_and_data_cleaning_task",
      "skos:broader",
      "Entity-data_cleaning_task"
    ],
    [
      "Entity-data_cleaning_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-more_than_20_different_file_type",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-json-ld_ontology",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-supported_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-regular_expression",
      "skos:broader",
      "Entity-pattern_matching"
    ],
    [
      "Entity-content-based_information_extraction",
      "skos:broader",
      "Entity-information_extraction"
    ],
    [
      "Entity-json_structure",
      "skos:broader",
      "Entity-json"
    ],
    [
      "Entity-metadata_extraction",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-output",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-python-based_tool"
    ],
    [
      "Entity-kgcp",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-ole_2_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "skos:broader",
      "Entity-metadata_and_content-based_information_extraction"
    ],
    [
      "Entity-apache_tika",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-pre-processing_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-output_set",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-ole_2",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-each_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-json"
    ],
    [
      "Entity-machine-readable_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-flag",
      "skos:broader",
      "Entity-parameter"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-regular_expression",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-state-of-the-art_nlp_tool",
      "skos:broader",
      "Entity-nlp_tool"
    ],
    [
      "Entity-tnnt_result",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-rdf_ready",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-package"
    ],
    [
      "Entity-mel_s_json_result",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-rdf",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-20_different_file_type",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-nlp_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-nlp_tool"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-more_than_20_different_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-the_text_analysis_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-unstructured_data_set",
      "skos:broader",
      "Entity-data_set"
    ],
    [
      "Entity-metadata_set",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-diverse_state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-json_result_file",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-apache_tika",
      "skos:broader",
      "Entity-package"
    ],
    [
      "Entity-more_than_20_different_file_type",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-extracted_metadata",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-heterogeneous_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-j2rm",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-ole_2",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-configurable_set_of_regular_expression",
      "skos:broader",
      "Entity-regular_expression"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "skos:broader",
      "Entity-content"
    ],
    [
      "Entity-specific_pre-processing_and_data_cleaning_task",
      "skos:broader",
      "Entity-data_cleaning"
    ],
    [
      "Entity-proper_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-kgcp",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-python-based_tool_and_library"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-heterogeneous_document_set",
      "skos:broader",
      "Entity-data_set"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-metadata_and_content-based_information_extraction"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-extracted_metadata"
    ],
    [
      "Entity-ole_2_file_type",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "skos:broader",
      "Entity-information_extraction"
    ],
    [
      "Entity-json_object",
      "skos:broader",
      "Entity-json_result"
    ],
    [
      "Entity-any_output",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-kgcp",
      "skos:broader",
      "Entity-knowledge_graph_construction_pipeline"
    ],
    [
      "Entity-j2rm",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-heterogeneous_document_set",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-content-based_information_extraction",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-ole_2",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-document__file__set",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-olemeta",
      "skos:broader",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-python-based_package",
      "skos:broader",
      "Entity-package"
    ],
    [
      "Entity-result_in_a_machine-readable_format",
      "skos:broader",
      "Entity-result"
    ],
    [
      "Entity-pre-processing",
      "skos:broader",
      "Entity-data_cleaning_task"
    ],
    [
      "Entity-pre-processing",
      "skos:broader",
      "Entity-data_cleaning"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "skos:broader",
      "Entity-extracted_metadata"
    ],
    [
      "Entity-extracted_metadata",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-the_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-file_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-state-of-the-art_nlp_tool"
    ],
    [
      "Entity-supported_file_type",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-heterogeneous_format",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-four_use_case_document_set",
      "skos:broader",
      "Entity-document__file__set"
    ],
    [
      "Entity-dozen_of_file_format",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-text_analysis_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-specific_processing_model",
      "skos:broader",
      "Entity-processing_model"
    ],
    [
      "Entity-pre-processing_and_data_cleaning_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-a_project_to__containerise__the_meltnnt_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-theoretical_number_of_attribute",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-java-based_general-purpose_system",
      "skos:broader",
      "Entity-java"
    ],
    [
      "Entity-20_different_file_type",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-ner"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "skos:broader",
      "Entity-metadata_extraction"
    ],
    [
      "Entity-keyword_extraction_task",
      "skos:broader",
      "Entity-keyword_extraction"
    ],
    [
      "Entity-json_result_file",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-ole_2_file_type",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-unstructured_data_set",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction_task",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-each_file_type",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-json-ld",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-input_document_set",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction_task",
      "skos:broader",
      "Entity-information_extraction"
    ],
    [
      "Entity-a_project_to__containerise__the_meltnnt_tool",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-the_most_comprehensive_and_current_state-of-the-art_tool_for_content_extraction_and_analysis",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-result_in_a_machine-readable_format",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json_result",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-configurable_setting",
      "skos:broader",
      "Entity-parameter"
    ],
    [
      "Entity-keyword_extraction_task",
      "skos:broader",
      "Entity-pattern_matching_and_keyword_extraction"
    ],
    [
      "Entity-several_complementary_extraction_method",
      "skos:broader",
      "Entity-extraction_method"
    ],
    [
      "Entity-json_result_file",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-task",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-heterogeneous_format",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-agrif",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-file_type",
      "skos:broader",
      "Entity-document_type"
    ],
    [
      "Entity-the_text_analysis_task",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-variety_of_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-xml_output",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-json",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-dozen_of_file_format",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-file_format",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-output_structure",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-json-ld_annotation",
      "skos:broader",
      "Entity-json-ld"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-project"
    ],
    [
      "Entity-heterogeneous_file_set",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-json",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-python-based_tool_and_library",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-document_store",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-mel",
      "skos:broader",
      "Entity-metadata_and_content_extraction"
    ],
    [
      "Entity-method_to_extract_metadata_and_content-based_information",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-file_format",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-ole_2_file_type",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-thousand_of_document",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-various_file_type_and_format",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-comprehensive_configurable_setting",
      "skos:broader",
      "Entity-parameter"
    ],
    [
      "Entity-heterogeneous_file_set",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-python-based_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-document_type",
      "skos:broader",
      "Entity-document"
    ],
    [
      "Entity-general-metadata",
      "skos:broader",
      "Entity-task"
    ],
    [
      "Entity-xml",
      "skos:broader",
      "Entity-file_format"
    ],
    [
      "Entity-source_document_format",
      "skos:broader",
      "Entity-document_type"
    ],
    [
      "Entity-attribute",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-ner_model",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-parameter_and_flag",
      "skos:broader",
      "Entity-parameter"
    ],
    [
      "Entity-supported_format__document_object_model",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-average_of_the_extracted_attribute",
      "skos:broader",
      "Entity-attribute"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-json",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-python-based_package",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-.docm",
      "skos:broader",
      "Entity-common_file_format"
    ],
    [
      "Entity-opensource_package_and_tool",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-keyword_extraction",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-metadata_extraction",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-state-of-the-art_nlp_tool_and_ner_model",
      "skos:broader",
      "Entity-ner_model"
    ],
    [
      "Entity-common_file_format",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-pattern_matching",
      "skos:broader",
      "Entity-text_analysis"
    ],
    [
      "Entity-various_file_type_and_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction_task",
      "skos:broader",
      "Entity-content_extraction"
    ],
    [
      "Entity-20_different_file_type",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-json_file",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-basic_text_analysis",
      "skos:broader",
      "Entity-text_analysis_task"
    ],
    [
      "Entity-comprehensive_set_of_method_for_metadata_and_content_extraction",
      "skos:broader",
      "Entity-metadata_and_content_extraction"
    ],
    [
      "Entity-basic_text_analysis",
      "skos:broader",
      "Entity-the_text_analysis_task"
    ],
    [
      "Entity-associated-metadata",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-a_json_file",
      "skos:broader",
      "Entity-json"
    ],
    [
      "Entity-document_object_model",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-json-ld",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "skos:broader",
      "Entity-content-based_information_extraction"
    ],
    [
      "Entity-basic_text_analysis_task",
      "skos:broader",
      "Entity-the_text_analysis_task"
    ],
    [
      "Entity-attribute",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-metadata_and_content-based_information_extraction",
      "skos:broader",
      "Entity-information_extraction"
    ],
    [
      "Entity-result_in_a_machine-readable_format",
      "skos:broader",
      "Entity-format"
    ],
    [
      "Entity-file_extension_mapping",
      "skos:broader",
      "Entity-file_type"
    ],
    [
      "Entity-result_in_a_machine-readable_format",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-related_metadata_and_content-based_information",
      "skos:broader",
      "Entity-metadata"
    ],
    [
      "Entity-parameter_and_flag",
      "skos:broader",
      "Entity-flag"
    ],
    [
      "Entity-window",
      "skos:broader",
      "Entity-window_operating_system"
    ],
    [
      "Entity-format",
      "skos:broader",
      "Entity-file_type_and_format"
    ],
    [
      "Entity-output_set",
      "skos:broader",
      "Entity-output"
    ],
    [
      "Entity-the_nlp_-ner_toolkit",
      "skos:broader",
      "Entity-tool"
    ],
    [
      "Entity-mel_s_json_result",
      "skos:broader",
      "Entity-metadata_set"
    ],
    [
      "Entity-extracted_metadata_and_text_content",
      "skos:broader",
      "Entity-textual_content"
    ]
  ],
  "predicates": {
    "Predicate-are_pre-processing_steps_of": {
      "label": "are pre-processing steps of",
      "description": "The predicate 'are pre-processing steps of' indicates that the subject consists of specific tasks or activities that serve as preliminary actions or procedures necessary for the successful execution or functioning of the object. It implies a relationship where the subject contributes foundational support or preparation that enhances or enables the capabilities of the object.",
      "disambiguation_index": 0
    },
    "Predicate-are": {
      "label": "are",
      "description": "The predicate 'are' serves as a linking verb that establishes a relationship of identity or classification between the subject and the object. It indicates that the subject is being defined or categorized by the object, suggesting that the subject possesses the characteristics or qualities described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-get": {
      "label": "get",
      "description": "The predicate 'get' indicates a relationship where the subject is responsible for obtaining, retrieving, or acquiring the object. It signifies a process or action through which the subject successfully accesses or produces the object, often implying a transformation or extraction of information, resources, or results.",
      "disambiguation_index": 0
    },
    "Predicate-presents": {
      "label": "presents",
      "description": "The predicate 'presents' indicates an action where the subject introduces, displays, or offers information, findings, or concepts to an audience or recipient, represented by the object. It implies a formal or structured communication of content, often in a context where the subject aims to inform, educate, or share insights with the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_a": {
      "label": "is a",
      "description": "The predicate 'is a' establishes a classification or categorization relationship between the subject and the object. It indicates that the subject belongs to or is an instance of the category defined by the object. This predicate is commonly used to define the type or nature of the subject, linking it to a broader class or concept.",
      "disambiguation_index": 0
    },
    "Predicate-implements": {
      "label": "implements",
      "description": "The predicate 'implements' denotes the action of putting a plan, idea, or method into effect by a subject. It signifies that the subject is actively executing or applying specific strategies, techniques, or processes represented by the object. This connection indicates a practical application of theoretical concepts or designs, where the subject takes responsibility for the realization of the object in a functional context.",
      "disambiguation_index": 0
    },
    "Predicate-extracts": {
      "label": "extracts",
      "description": "The predicate 'extracts' indicates an action where the subject is performing a process or operation to obtain or derive specific information, data, or elements represented by the object. This connection implies that the subject has the capability or method to isolate and retrieve the object from a larger set of data or context.",
      "disambiguation_index": 0
    },
    "Predicate-extracts_from": {
      "label": "extracts from",
      "description": "The predicate 'extracts from' indicates a relationship where the subject is actively obtaining or deriving specific information, data, or insights from the object. This implies a process of analysis or processing where the subject identifies and retrieves relevant elements from the broader context represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-encoded_in": {
      "label": "encoded in",
      "description": "The predicate 'encoded in' signifies a relationship where the subject is transformed or represented in a specific manner or structure defined by the object. It implies that the subject's original form or content has been systematically converted or organized according to the characteristics or rules of the object, thereby facilitating its storage, transmission, or interpretation.",
      "disambiguation_index": 0
    },
    "Predicate-is": {
      "label": "is",
      "description": "The predicate 'is' serves as a linking verb that establishes an identity or equivalence between the subject and the object. It indicates that the subject and object refer to the same entity or concept, thereby affirming their sameness or defining characteristics.",
      "disambiguation_index": 0
    },
    "Predicate-generated_as": {
      "label": "generated as",
      "description": "The predicate 'generated as' indicates the process or method by which the subject is produced or created in a specific format or representation, which is denoted by the object. It establishes a relationship where the subject is transformed or outputted into the form specified by the object.",
      "disambiguation_index": 0
    },
    "Predicate-mapped_to": {
      "label": "mapped to",
      "description": "The predicate 'mapped to' indicates a relationship where the subject is associated with or transformed into the object, often implying a conversion or representation of data from one format or structure to another. This connection suggests that the subject can be understood, interpreted, or utilized in the context of the object, highlighting a correspondence or equivalence between the two.",
      "disambiguation_index": 0
    },
    "Predicate-stored_in": {
      "label": "stored in",
      "description": "The predicate 'stored in' indicates a relationship where the subject is kept or maintained within the confines of the object. It signifies that the subject is located or preserved in the object, which serves as a container or repository for the subject's data or information.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_mapped_to": {
      "label": "can be mapped to",
      "description": "The predicate 'can be mapped to' indicates a relationship where the subject is capable of being transformed, represented, or correlated with the object, suggesting a potential for conversion or alignment between the two entities in a meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-supports": {
      "label": "supports",
      "description": "The predicate 'supports' indicates that the subject provides assistance, compatibility, or endorsement for the object, which typically represents a feature, capability, or resource. This relationship implies that the subject enables or facilitates the use or functionality of the object in some manner.",
      "disambiguation_index": 0
    },
    "Predicate-aids": {
      "label": "aids",
      "description": "The predicate 'aids' indicates a supportive or facilitative relationship between the subject and the object, where the subject provides assistance, help, or enhancement to the object in achieving a goal or completing a process.",
      "disambiguation_index": 0
    },
    "Predicate-is_based_on": {
      "label": "is based on",
      "description": "The predicate 'is based on' establishes a foundational relationship between the subject and the object, indicating that the subject derives its principles, structure, or functionality from the object. It suggests that the object serves as a source, framework, or reference point that informs or underpins the subject's characteristics or operations.",
      "disambiguation_index": 0
    },
    "Predicate-introduces": {
      "label": "introduces",
      "description": "The predicate 'introduces' signifies an action where the subject presents or brings forth the object to the audience or context, often implying a first-time presentation or a new perspective on the object. It establishes a relationship where the subject serves as a source of information or insight regarding the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_represented_as": {
      "label": "are represented as",
      "description": "The predicate 'are represented as' indicates a relationship where the subject is depicted, illustrated, or characterized in a specific manner or form that is defined by the object. It suggests that the subject can be understood or conceptualized through the lens of the object, providing a means of interpretation or representation.",
      "disambiguation_index": 0
    },
    "Predicate-performs": {
      "label": "performs",
      "description": "The predicate 'performs' indicates an action or activity carried out by the subject, which involves executing or undertaking a specific task or set of tasks represented by the object. It establishes a relationship where the subject is the agent that actively engages in the process described by the object, highlighting the subject's role in the completion of the task.",
      "disambiguation_index": 0
    },
    "Predicate-generates": {
      "label": "generates",
      "description": "The predicate 'generates' indicates a causal or productive relationship where the subject actively produces or creates the object as a result of its processes or actions. It implies that the subject's activities lead to the formation or emergence of the object, which can be in various forms such as data, outcomes, or products.",
      "disambiguation_index": 0
    },
    "Predicate-in": {
      "label": "in",
      "description": "The predicate 'in' indicates a relationship where the subject is contained within or characterized by the object, often denoting a state, condition, or format that the subject assumes or is expressed through.",
      "disambiguation_index": 0
    },
    "Predicate-prepares_the_ground_for": {
      "label": "prepares the ground for",
      "description": "The predicate 'prepares the ground for' indicates that the subject creates the necessary conditions, context, or foundation that enables or facilitates the realization or implementation of the object. It suggests a preparatory action that leads to the eventual occurrence or development of the object, implying a supportive or enabling relationship between the subject and the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_integrated_with": {
      "label": "is integrated with",
      "description": "The predicate 'is integrated with' indicates a relationship where the subject is combined or connected with the object in a cohesive manner, suggesting that they work together or function as a unified system. This integration implies that the subject and object share data, functionalities, or processes, enhancing their overall capabilities and effectiveness.",
      "disambiguation_index": 0
    },
    "Predicate-automates_the_extraction_task_of": {
      "label": "automates the extraction task of",
      "description": "The predicate 'automates the extraction task of' indicates that the subject is capable of performing a process that systematically retrieves and organizes specific information from a larger dataset or text. This process is characterized by its efficiency and reduction of manual effort, allowing for the identification and classification of particular elements, such as named entities, within the object. Essentially, it highlights the role of the subject in enhancing productivity and accuracy in information extraction tasks.",
      "disambiguation_index": 0
    },
    "Predicate-uses": {
      "label": "uses",
      "description": "The predicate 'uses' indicates that the subject actively employs or utilizes the object in order to achieve a specific purpose or function. It establishes a relationship where the subject relies on the object as a resource, tool, or method to perform tasks or fulfill objectives.",
      "disambiguation_index": 0
    },
    "Predicate-results_along_with": {
      "label": "results along with",
      "description": "The predicate 'results along with' indicates a relationship where the subject produces or generates outcomes that are associated with or accompanied by the object. It suggests that the results obtained from the subject are not isolated but are linked to the object in a meaningful way, often implying a collaborative or complementary nature between the two.",
      "disambiguation_index": 0
    },
    "Predicate-developed_in_conjunction_with": {
      "label": "developed in conjunction with",
      "description": "The predicate 'developed in conjunction with' indicates a collaborative relationship between the subject and the object, where both parties actively participate in the development process. This suggests that the subject and object work together, sharing resources, knowledge, or expertise to create or enhance a product, project, or initiative.",
      "disambiguation_index": 0
    },
    "Predicate-part_of": {
      "label": "part of",
      "description": "The predicate 'part of' indicates a relationship where the subject is a component, segment, or constituent of the object. This implies that the subject is included within the broader context or structure represented by the object, suggesting a hierarchical or associative connection between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-has": {
      "label": "has",
      "description": "The predicate 'has' indicates a relationship of possession or ownership between the subject and the object. It signifies that the subject possesses, contains, or is equipped with the qualities, features, or attributes represented by the object. In this context, the subject is characterized by the presence of the object, which can be a tangible or intangible entity.",
      "disambiguation_index": 0
    },
    "Predicate-of": {
      "label": "of",
      "description": "The predicate 'of' is used to indicate a relationship of belonging or association between the subject and the object. It connects the subject to the object by specifying that the subject pertains to, is related to, or is characterized by the object. In general, 'of' serves to clarify the context or scope of the subject by linking it to the object, which often represents a category, type, or characteristic relevant to the subject.",
      "disambiguation_index": 0
    },
    "Predicate-takes_as_input": {
      "label": "takes as input",
      "description": "The predicate 'takes as input' establishes a relationship where the subject is designed to receive or process the object. It indicates that the subject requires the object as a necessary component for its operation, function, or analysis, thereby highlighting a dependency or interaction between the two entities.",
      "disambiguation_index": 0
    },
    "Predicate-applies": {
      "label": "applies",
      "description": "The predicate 'applies' indicates a relationship where the subject utilizes or implements the object in a relevant context. It suggests that the subject is actively engaging with the object to achieve a specific purpose or outcome, often involving the execution or enforcement of rules, methods, or processes represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-contains": {
      "label": "contains",
      "description": "The predicate 'contains' indicates that the subject has within it or includes the object as part of its composition or content. It establishes a relationship where the subject is a container or holder of the object, which can be data, information, or physical items.",
      "disambiguation_index": 0
    },
    "Predicate-has_a_structure_based_on": {
      "label": "has a structure based on",
      "description": "The predicate 'has a structure based on' indicates that the subject is organized or arranged according to the principles, rules, or framework defined by the object. It establishes a foundational relationship where the subject's configuration or format is derived from or influenced by the object, suggesting that the object provides the underlying guidelines or model that shapes the subject's structure.",
      "disambiguation_index": 0
    },
    "Predicate-can_store": {
      "label": "can store",
      "description": "The predicate 'can store' indicates the ability of the subject to retain or keep the object in a particular form or state for future use or reference. It implies a capacity for preservation, whether it be data, information, physical items, or other entities, suggesting that the subject has the necessary resources or mechanisms to hold onto the object over time.",
      "disambiguation_index": 0
    },
    "Predicate-is_presented_in": {
      "label": "is presented in",
      "description": "The predicate 'is presented in' indicates that the subject is displayed, shown, or detailed within the context of the object. It establishes a relationship where the subject's information, characteristics, or data are conveyed through the medium or format specified by the object, suggesting that the object serves as a reference point or location for the subject's presentation.",
      "disambiguation_index": 0
    },
    "Predicate-is_able_to_extract": {
      "label": "is able to extract",
      "description": "The predicate 'is able to extract' indicates the capability or potential of the subject to retrieve or obtain specific information, data, or characteristics represented by the object. It implies that the subject possesses the necessary skills, tools, or processes to successfully identify and separate the object from a larger context or dataset.",
      "disambiguation_index": 0
    },
    "Predicate-shows": {
      "label": "shows",
      "description": "The predicate 'shows' indicates a relationship where the subject presents, demonstrates, or reveals information, characteristics, or qualities about the object. It implies that the subject provides evidence or insight that allows for the understanding or recognition of the object in question.",
      "disambiguation_index": 0
    },
    "Predicate-is_from": {
      "label": "is from",
      "description": "The predicate 'is from' establishes a relationship of origin or source between the subject and the object. It indicates that the subject is derived from, associated with, or originates in the context of the object, thereby linking the two entities in a way that highlights the source or basis of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-is_for": {
      "label": "is for",
      "description": "The predicate 'is for' establishes a relationship of purpose or association between the subject and the object, indicating that the subject serves a specific function, role, or relevance to the object. It implies that the subject is intended to support, relate to, or be applicable in the context of the object.",
      "disambiguation_index": 0
    },
    "Predicate-can_be_processed_on": {
      "label": "can be processed on",
      "description": "The predicate 'can be processed on' indicates the capability or compatibility of the subject with the object, suggesting that the subject is able to undergo a specific type of processing or operation when utilized within the context of the object. This relationship highlights the environments, systems, or platforms that support the processing of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-can_only_be_processed_on": {
      "label": "can only be processed on",
      "description": "The predicate 'can only be processed on' indicates a restriction or limitation regarding the processing capabilities of the subject. It establishes that the subject is compatible with, or can function within, the context of the object, which represents a specific environment, platform, or system. This implies that the subject cannot be effectively utilized or handled outside of the specified object, highlighting a dependency on that particular context for its operation.",
      "disambiguation_index": 0
    },
    "Predicate-is_used_for": {
      "label": "is used for",
      "description": "The predicate 'is used for' establishes a functional relationship between the subject and the object, indicating that the subject serves a specific purpose or function related to the object. It implies that the subject is applicable, relevant, or instrumental in the context of the object, often highlighting the utility or role of the subject in relation to the object.",
      "disambiguation_index": 0
    },
    "Predicate-implemented_in": {
      "label": "implemented in",
      "description": "The predicate 'implemented in' establishes a relationship where the subject represents a method, technique, or system that is realized or executed within the framework, environment, or language specified by the object. It indicates that the subject is operationally integrated or constructed using the resources or capabilities provided by the object.",
      "disambiguation_index": 0
    },
    "Predicate-applied_to_extract": {
      "label": "applied to extract",
      "description": "The predicate 'applied to extract' indicates a functional relationship where the subject is utilized or implemented to obtain or retrieve specific information or elements represented by the object. This suggests that the subject serves as a tool or technique that facilitates the process of extraction, targeting the particular aspects or data types denoted by the object.",
      "disambiguation_index": 0
    },
    "Predicate-applies_to": {
      "label": "applies to",
      "description": "The predicate 'applies to' establishes a relationship between the subject and the object, indicating that the subject is relevant or suitable for the object. It suggests that the subject has a functional or contextual connection with the object, which may encompass a range of categories, types, or instances that the subject can interact with or be associated with.",
      "disambiguation_index": 0
    },
    "Predicate-have": {
      "label": "have",
      "description": "The predicate 'have' indicates a relationship of possession or ownership between the subject and the object. It signifies that the subject possesses certain attributes, qualities, or resources represented by the object. In this context, it connects the subject to the object by asserting that the subject contains or is associated with the characteristics described by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_presented_in_(1)": {
      "label": "is presented in",
      "description": "The predicate 'is presented in' establishes a relationship where the subject is the entity being depicted, described, or explained, while the object refers to the medium, location, or context in which this presentation occurs. This connection indicates that the subject can be found or is illustrated within the specified object, providing a reference point for understanding or visualizing the subject.",
      "disambiguation_index": 1
    },
    "Predicate-is_performed_for": {
      "label": "is performed for",
      "description": "The predicate 'is performed for' establishes a relationship where the subject is an action or task that is carried out with the intention of achieving or producing the object. It indicates the purpose or goal behind the execution of the subject, suggesting that the subject is undertaken to fulfill a need, requirement, or to generate a specific result represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_the_last_step_of": {
      "label": "is the last step of",
      "description": "The predicate 'is the last step of' indicates a relationship where the subject represents a process or activity that culminates in the object, which is the final result or outcome of that process. It signifies that the object is the concluding phase or product that arises from the completion of the subject.",
      "disambiguation_index": 0
    },
    "Predicate-resembles": {
      "label": "resembles",
      "description": "The predicate 'resembles' indicates a similarity or likeness between the subject and the object. It suggests that the subject shares certain characteristics, features, or qualities with the object, allowing for a comparison that highlights their commonalities. This connection can pertain to various aspects such as appearance, functionality, behavior, or conceptual attributes.",
      "disambiguation_index": 0
    },
    "Predicate-is_aimed_to_be_used_in": {
      "label": "is aimed to be used in",
      "description": "The predicate 'is aimed to be used in' indicates a purpose or intended application of the subject in relation to the object. It suggests that the subject is designed, developed, or intended for utilization within the context or framework represented by the object. This connection implies a functional relationship where the subject serves a specific role or fulfills a particular need within the domain of the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_used_in": {
      "label": "are used in",
      "description": "The predicate 'are used in' indicates a functional relationship where the subject serves a role or purpose within the context of the object. It implies that the subject is applied, utilized, or employed in the processes, activities, or domains represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_used_for": {
      "label": "are used for",
      "description": "The predicate 'are used for' indicates the purpose or function of the subject in relation to the object. It connects the subject, which typically represents a tool, method, or resource, to the object, which signifies a specific task, activity, or goal that the subject facilitates or accomplishes.",
      "disambiguation_index": 0
    },
    "Predicate-integrates": {
      "label": "integrates",
      "description": "The predicate 'integrates' denotes a relationship in which the subject combines or unifies with the object to form a cohesive whole. It implies that the subject incorporates the object into its structure or functionality, enhancing its capabilities or effectiveness by utilizing the components or features represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-generate": {
      "label": "generate",
      "description": "The predicate 'generate' indicates the action of producing or creating something from a given source or set of inputs. In the context of the subject and object, it signifies that the subject is responsible for the creation or formulation of the object, resulting in a new entity or output that is derived from the subject's characteristics or functionalities.",
      "disambiguation_index": 0
    },
    "Predicate-are_based_on": {
      "label": "are based on",
      "description": "The predicate 'are based on' indicates a foundational relationship where the subject derives its principles, structure, or functionality from the object. It suggests that the subject is built upon, influenced by, or fundamentally connected to the object, which serves as a source or reference point for the subject's characteristics or behavior.",
      "disambiguation_index": 0
    },
    "Predicate-are_available_for": {
      "label": "are available for",
      "description": "The predicate 'are available for' indicates that the subject provides access, support, or utility for the object, suggesting that the subject can be utilized or employed in relation to the object in a practical or functional manner.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_comprehensive_set_of_methods_for": {
      "label": "is a comprehensive set of methods for",
      "description": "The predicate 'is a comprehensive set of methods for' establishes a relationship where the subject represents a collection of techniques or approaches that are designed to effectively address, analyze, or work with the object, which typically denotes a specific category, domain, or type of content. This indicates that the subject encompasses a wide range of strategies that are applicable to the object, suggesting a thorough and systematic framework for understanding or processing it.",
      "disambiguation_index": 0
    },
    "Predicate-is_available_in": {
      "label": "is available in",
      "description": "The predicate 'is available in' indicates that the subject can be found, utilized, or implemented within the context of the object. It establishes a relationship where the subject is compatible with, or can be accessed through, the resources, tools, or environments specified by the object.",
      "disambiguation_index": 0
    },
    "Predicate-provides": {
      "label": "provides",
      "description": "The predicate 'provides' indicates a relationship in which the subject offers, supplies, or makes available the object to another entity or for a specific purpose. It implies an act of giving or furnishing something that is useful, beneficial, or necessary, thereby establishing a connection where the subject is the source or provider and the object is the resource or mechanism being made accessible.",
      "disambiguation_index": 0
    },
    "Predicate-to_extract": {
      "label": "to extract",
      "description": "The predicate 'to extract' denotes the action of retrieving or obtaining specific information or elements from a source, where the subject is the entity performing the action and the object represents the information or elements being retrieved. This action implies a process of separation or selection, allowing the subject to access and utilize the specified data or content.",
      "disambiguation_index": 0
    },
    "Predicate-tested_over": {
      "label": "tested over",
      "description": "The predicate 'tested over' indicates that the subject has undergone a process of evaluation or examination in relation to the object. It implies that the subject has been assessed, analyzed, or validated using the specified object as a basis for testing, which often involves a quantitative or qualitative measure.",
      "disambiguation_index": 0
    },
    "Predicate-tested_using": {
      "label": "tested using",
      "description": "The predicate 'tested using' indicates a relationship where the subject has undergone a process of evaluation or examination through the application of the object. It implies that the subject is assessed for its effectiveness, performance, or reliability by utilizing the methods, tools, or criteria represented by the object.",
      "disambiguation_index": 0
    },
    "Predicate-are_used_to_add": {
      "label": "are used to add",
      "description": "The predicate 'are used to add' indicates a functional relationship where the subject serves a purpose or function that facilitates the inclusion or incorporation of the object. It implies that the subject provides a mechanism, method, or capability that enables the enhancement or expansion of the object, often in a context where additional information, structure, or meaning is being introduced.",
      "disambiguation_index": 0
    },
    "Predicate-is_made": {
      "label": "is made",
      "description": "The predicate 'is made' indicates a process or action through which the subject undergoes transformation or creation to achieve the state or form represented by the object. It signifies that the subject is the source or origin of the resulting object, which is a product or outcome of this process.",
      "disambiguation_index": 0
    },
    "Predicate-leverages": {
      "label": "leverages",
      "description": "The predicate 'leverages' indicates that the subject utilizes or takes advantage of the object in order to enhance its functionality, effectiveness, or performance. It implies a relationship where the subject benefits from the properties, features, or capabilities of the object, suggesting a strategic or beneficial use of the object to achieve specific goals or outcomes.",
      "disambiguation_index": 0
    },
    "Predicate-will_be_added_in": {
      "label": "will be added in",
      "description": "The predicate 'will be added in' indicates a future action or event where the subject is expected to incorporate or include the object within a specified context or framework. It suggests that the addition is contingent upon certain conditions or requirements, which are often outlined in the object, thereby establishing a relationship of dependency between the subject and the object.",
      "disambiguation_index": 0
    },
    "Predicate-is_planned_to": {
      "label": "is planned to",
      "description": "The predicate 'is planned to' indicates a future intention or arrangement regarding the subject, suggesting that the subject is associated with a specific objective or action that is intended to be carried out. It connects the subject to the object by expressing a planned course of action or goal that the subject aims to achieve.",
      "disambiguation_index": 0
    },
    "Predicate-involves": {
      "label": "involves",
      "description": "The predicate 'involves' indicates a relationship where the subject is engaged in or requires the object as a necessary component, activity, or aspect of its execution or existence. It suggests that the object is integral to the subject's purpose or function.",
      "disambiguation_index": 0
    },
    "Predicate-integrates_with": {
      "label": "integrates with",
      "description": "The predicate 'integrates with' denotes a relationship where the subject establishes a functional or operational connection with the object, allowing for collaboration, interaction, or the combination of features and capabilities. This integration often implies that the subject can utilize or enhance its functionalities through the object, resulting in a cohesive system or process.",
      "disambiguation_index": 0
    },
    "Predicate-has_comprehensive_support_of": {
      "label": "has comprehensive support of",
      "description": "The predicate 'has comprehensive support of' indicates that the subject possesses a wide-ranging and thorough capability or functionality concerning the object. It implies that the subject can effectively handle, accommodate, or provide assistance for the various aspects or elements represented by the object, suggesting a high level of versatility and inclusivity.",
      "disambiguation_index": 0
    },
    "Predicate-has_been_tested_over": {
      "label": "has been tested over",
      "description": "The predicate 'has been tested over' indicates that the subject has undergone a process of evaluation or experimentation involving the object, which typically represents a quantity or set of items. This phrase suggests that the subject's effectiveness, reliability, or performance has been assessed in relation to the specified object, implying a level of scrutiny or validation based on the given context.",
      "disambiguation_index": 0
    },
    "Predicate-describes_the_systematic_approach_and_methods_used_by": {
      "label": "describes the systematic approach and methods used by",
      "description": "This predicate establishes a relationship where the subject provides an explanation or overview of the organized strategies and techniques that are employed by the object. It indicates that the subject offers insights into the methodologies and frameworks that the object utilizes in its operations or processes.",
      "disambiguation_index": 0
    },
    "Predicate-presents_the_general_output_structure_of": {
      "label": "presents the general output structure of",
      "description": "The predicate 'presents the general output structure of' indicates that the subject provides a comprehensive overview or framework regarding the organization, format, or arrangement of the information or data represented by the object. It establishes a relationship where the subject serves as a reference point or source that elucidates how the object is structured or formatted in a general sense.",
      "disambiguation_index": 0
    },
    "Predicate-implement": {
      "label": "implement",
      "description": "The predicate 'implement' signifies the action of putting a plan, idea, or method into effect by utilizing specific tools, techniques, or components. In the context of a subject and object, it indicates that the subject is actively applying or executing the strategies or frameworks represented by the object to achieve a particular goal or function.",
      "disambiguation_index": 0
    },
    "Predicate-produces": {
      "label": "produces",
      "description": "The predicate 'produces' indicates a relationship where the subject generates, creates, or yields the object as a result of its processes or functions. It signifies that the subject is responsible for the existence or emergence of the object, which can be a tangible or intangible outcome.",
      "disambiguation_index": 0
    },
    "Predicate-includes": {
      "label": "includes",
      "description": "The predicate 'includes' establishes a relationship where the subject encompasses or contains the object as a part of its entirety. It indicates that the object is a component or subset of the subject, suggesting that the subject is broader or more comprehensive while the object represents specific elements or instances that fall within that broader category.",
      "disambiguation_index": 0
    },
    "Predicate-describes_the_systematic_approach_for_extracting": {
      "label": "describes the systematic approach for extracting",
      "description": "This predicate indicates that the subject provides a detailed explanation or framework regarding the methods and procedures involved in the extraction process, specifically targeting the retrieval of certain types of information or data, which is represented by the object. It establishes a relationship where the subject serves as a guide or reference for understanding how to effectively obtain the specified content.",
      "disambiguation_index": 0
    },
    "Predicate-facilitate": {
      "label": "facilitate",
      "description": "The predicate 'facilitate' indicates a supportive or enabling relationship between the subject and the object, where the subject provides the means, resources, or conditions that make the process or outcome represented by the object easier or more achievable.",
      "disambiguation_index": 0
    },
    "Predicate-is_a_component_of": {
      "label": "is a component of",
      "description": "The predicate 'is a component of' establishes a relationship where the subject is identified as a part or element that contributes to the whole represented by the object. This indicates that the subject plays a role in the structure, function, or composition of the object, suggesting a hierarchical or integrative connection between the two.",
      "disambiguation_index": 0
    },
    "Predicate-extracts_metadata_and_content_from": {
      "label": "extracts metadata and content from",
      "description": "The predicate 'extracts metadata and content from' indicates a process or action where the subject, typically a system, method, or tool, retrieves and identifies relevant information and data attributes from the object, which is usually a collection of documents or files. This process involves analyzing the object to obtain structured or unstructured data, enabling further use or analysis of the extracted information.",
      "disambiguation_index": 0
    },
    "Predicate-facilitates_the_extraction_of": {
      "label": "facilitates the extraction of",
      "description": "The predicate 'facilitates the extraction of' indicates that the subject provides assistance, support, or mechanisms that enable or simplify the process of obtaining or retrieving the object, which typically consists of data or information. This relationship highlights the role of the subject in making the extraction process more efficient or effective.",
      "disambiguation_index": 0
    },
    "Predicate-is_extracted_as": {
      "label": "is extracted as",
      "description": "The predicate 'is extracted as' indicates a relationship where the subject undergoes a process of extraction, resulting in the object, which represents the specific form or components that have been derived from the subject. This implies that the subject contains information or elements that can be separated or identified, and the object specifies what those extracted elements are.",
      "disambiguation_index": 0
    },
    "Predicate-is_used_by": {
      "label": "is used by",
      "description": "The predicate 'is used by' establishes a relationship where the subject serves as a tool, method, or framework that is employed or utilized by the object. It indicates that the object relies on or benefits from the capabilities or functionalities provided by the subject in order to achieve a specific purpose or outcome.",
      "disambiguation_index": 0
    },
    "Predicate-is_extracted_from": {
      "label": "is extracted from",
      "description": "The predicate 'is extracted from' indicates a relationship where the subject represents a source or container from which specific information, data, or elements (the object) are derived or obtained. This implies a process of retrieval or separation, highlighting that the object is a component or subset that originates from the subject.",
      "disambiguation_index": 0
    },
    "Predicate-enables": {
      "label": "enables",
      "description": "The predicate 'enables' indicates a facilitative relationship where the subject provides the means, capability, or opportunity for the object to occur or be realized. It suggests that the subject plays a crucial role in making the object possible, thereby enhancing or supporting its implementation or effectiveness.",
      "disambiguation_index": 0
    },
    "Predicate-extracts_information_from": {
      "label": "extracts information from",
      "description": "The predicate 'extracts information from' indicates a process in which a subject, typically a system, method, or tool, retrieves or derives relevant data, insights, or knowledge from an object, which is usually a collection of documents, files, or datasets. This relationship highlights the capability of the subject to analyze, interpret, or summarize the content of the object to produce useful information.",
      "disambiguation_index": 0
    },
    "Predicate-processes": {
      "label": "processes",
      "description": "The predicate 'processes' indicates an action or function performed by the subject on the object, where the subject engages in a systematic series of operations or transformations to manipulate, analyze, or manage the object. In this context, the subject is actively involved in handling the object, which is typically a collection of items or data, to achieve a specific outcome or result.",
      "disambiguation_index": 0
    },
    "Predicate-utilizes": {
      "label": "utilizes",
      "description": "The predicate 'utilizes' indicates that the subject employs or makes use of the object in order to achieve a specific purpose or function. It establishes a relationship where the subject actively engages with the object, leveraging its capabilities or features to fulfill a particular need or task.",
      "disambiguation_index": 0
    },
    "Predicate-is_input_into": {
      "label": "is input into",
      "description": "The predicate 'is input into' indicates a relationship where the subject is being entered, recorded, or incorporated into the object, which typically represents a system, collection, or structured format. This implies a transfer of information or data from the subject to the object, suggesting that the subject contributes to or becomes part of the object in a meaningful way.",
      "disambiguation_index": 0
    },
    "Predicate-is_input_to": {
      "label": "is input to",
      "description": "The predicate 'is input to' establishes a relationship where the subject serves as a source of data or information that is utilized by the object. In this context, the subject, which can be a document, file, or any form of data set, is provided as an input for processing, analysis, or further action by the object, which typically represents a system, model, or process designed to handle or interpret the input.",
      "disambiguation_index": 0
    },
    "skos:broader": {
      "label": "has a broader term",
      "description": "The predicate 'has a broader term' establishes a hierarchical relationship between the subject and the object, indicating that the subject is a more specific instance or category that falls under the wider classification represented by the object. This relationship implies that the object encompasses a broader scope or set of characteristics that includes the subject, thereby situating the subject within a larger conceptual framework.",
      "disambiguation_index": 0
    }
  }
}