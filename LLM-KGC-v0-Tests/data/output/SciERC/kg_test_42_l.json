{
  "iri": "Paper-42",
  "title": "H01-1042",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-42-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-42-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-1",
              "text": "The purpose of this research is to test the efficacy of applying automated evaluation techniques , originally devised for the evaluation of human language learners , to the output of machine translation -LRB- MT -RRB- systems ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-2",
              "text": "We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-3",
              "text": "This , the first experiment in a series of experiments , looks at the intelligibility of MT output ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-4",
              "text": "A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-5",
              "text": "Even more illuminating was the factors on which the assessors made their decisions ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-6",
              "text": "We tested this to see if similar criteria could be elicited from duplicating the experiment using machine translation output ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-7",
              "text": "Subjects were given a set of up to six extracts of translated newswire text ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-8",
              "text": "Some of the extracts were expert human translations , others were machine translation outputs ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-9",
              "text": "The subjects were given three minutes per extract to determine whether they believed the sample output to be an expert human translation or a machine translation ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-10",
              "text": "Additionally , they were asked to mark the word at which they made this decision ."
            },
            {
              "iri": "Paper-42-Section-1-Paragraph-1-Sentence-11",
              "text": "The results of this experiment , along with a preliminary analysis of the factors involved in the decision making process will be presented here ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "The purpose of this research is to test the efficacy of applying automated evaluation techniques , originally devised for the evaluation of human language learners , to the output of machine translation -LRB- MT -RRB- systems . We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems . This , the first experiment in a series of experiments , looks at the intelligibility of MT output . A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words . Even more illuminating was the factors on which the assessors made their decisions . We tested this to see if similar criteria could be elicited from duplicating the experiment using machine translation output . Subjects were given a set of up to six extracts of translated newswire text . Some of the extracts were expert human translations , others were machine translation outputs . The subjects were given three minutes per extract to determine whether they believed the sample output to be an expert human translation or a machine translation . Additionally , they were asked to mark the word at which they made this decision . The results of this experiment , along with a preliminary analysis of the factors involved in the decision making process will be presented here .",
  "kg2text": [
    "A language assessment study, also known as this experiment, showed that assessors can differentiate native from non-native language essays in less than 100 words. The purpose of this research was to test the efficacy of applying automated evaluation techniques originally designed for human language learners to machine translation systems. This experiment looks at how similar criteria could be elicited by duplicating the experiment using machine translation output, which has a broader term as A language learning experiment. In addition, it also explores whether these evaluation techniques will provide information about machine translation systems and their ability to translate text from one natural language to another, human language learning process, or even the translation process itself.",
    "This research aims to test the efficacy of applying automated evaluation techniques originally designed for human language learners to machine translation systems. The purpose of this study involves evaluating the intelligibility of MT output, which looks at the comprehensibility or clarity of machine translation outputs. To achieve this goal, a language learning experiment was conducted where subjects were given extracts of translated newswire text and asked to evaluate them within three minutes per extract. Some of these extracts were expert human translations, while others were machine translation outputs. The results of this experiment, along with a preliminary analysis of the factors involved in the decision-making process will be presented here."
  ],
  "times": [
    15.656127691268921
  ]
}