{
  "iri": "Paper-93",
  "title": "C08-2010",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-93-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-93-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-93-Section-1-Paragraph-1-Sentence-1",
              "text": "Language resource quality is crucial in NLP ."
            },
            {
              "iri": "Paper-93-Section-1-Paragraph-1-Sentence-2",
              "text": "Many of the resources used are derived from data created by human beings out of an NLP context , especially regarding MT and reference translations ."
            },
            {
              "iri": "Paper-93-Section-1-Paragraph-1-Sentence-3",
              "text": "Indeed , automatic evaluations need high-quality data that allow the comparison of both automatic and human translations ."
            },
            {
              "iri": "Paper-93-Section-1-Paragraph-1-Sentence-4",
              "text": "The validation of these resources is widely recommended before being used ."
            },
            {
              "iri": "Paper-93-Section-1-Paragraph-1-Sentence-5",
              "text": "This paper describes the impact of using different-quality references on evaluation ."
            },
            {
              "iri": "Paper-93-Section-1-Paragraph-1-Sentence-6",
              "text": "Surprisingly enough , similar scores are obtained in many cases regardless of the quality ."
            },
            {
              "iri": "Paper-93-Section-1-Paragraph-1-Sentence-7",
              "text": "Thus , the limitations of the automatic metrics used within MT are also discussed in this regard ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "Language resource quality is crucial in NLP . Many of the resources used are derived from data created by human beings out of an NLP context , especially regarding MT and reference translations . Indeed , automatic evaluations need high-quality data that allow the comparison of both automatic and human translations . The validation of these resources is widely recommended before being used . This paper describes the impact of using different-quality references on evaluation . Surprisingly enough , similar scores are obtained in many cases regardless of the quality . Thus , the limitations of the automatic metrics used within MT are also discussed in this regard .",
  "kg2text": [
    "The quality of language resources used for Natural Language Processing (NLP) evaluations has an impact on using different-quality references. Many of these resources allow comparison with the quality, and are also derived from data created by human beings out of NLP context. Automatic metrics used within MT have a broader term that includes reference translations. The importance or standard of excellence of language resources is crucial in NLP. Similarly, machine-generated text or its corresponding original versions (MT) has a broader term that includes Language resource quality and references. Moreover, the use of varying quality reference translations in evaluating machine translation systems can result in similar scores. This paper describes the impact of using different-quality references on evaluation.",
    "This paper describes the impact of using different-quality references on evaluation, which has implications for both papers and evaluations. The outcome or result of this assessment can be measured by scores that evaluate performance. Automatic evaluations require high-quality data resources to function effectively."
  ],
  "times": [
    10.004055500030518
  ]
}