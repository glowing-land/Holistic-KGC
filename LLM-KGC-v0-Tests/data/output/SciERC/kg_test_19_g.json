{
  "iri": "Paper-19",
  "title": "INTERSPEECH_2008_20_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-19-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-19-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-19-Section-1-Paragraph-1-Sentence-1",
              "text": "In the study of expressive speech communication , it is commonly accepted that the emotion perceived by the listener is a good approximation of the intended emotion conveyed by the speaker ."
            },
            {
              "iri": "Paper-19-Section-1-Paragraph-1-Sentence-2",
              "text": "This paper analyzes the validity of this assumption by comparing the mismatches between the assessments made by na \u00a8 \u0131ve listeners and by the speakers that generated the data ."
            },
            {
              "iri": "Paper-19-Section-1-Paragraph-1-Sentence-3",
              "text": "The analysis is based on the hypothesis that people are better decoders of their own emotions ."
            },
            {
              "iri": "Paper-19-Section-1-Paragraph-1-Sentence-4",
              "text": "Therefore , self-assessments will be closer to the intended emotions ."
            },
            {
              "iri": "Paper-19-Section-1-Paragraph-1-Sentence-5",
              "text": "Using the IEMOCAP database , discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments evaluated by the actors and na \u00a8 \u0131ve listeners are compared ."
            },
            {
              "iri": "Paper-19-Section-1-Paragraph-1-Sentence-6",
              "text": "The results indicate that there is a mismatch between the expression and perception of emotion ."
            },
            {
              "iri": "Paper-19-Section-1-Paragraph-1-Sentence-7",
              "text": "The speakers in the database assigned their own emotions to more specific emotional categories , which led to more extreme values in the activation-valence space ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "In the study of expressive speech communication , it is commonly accepted that the emotion perceived by the listener is a good approximation of the intended emotion conveyed by the speaker . This paper analyzes the validity of this assumption by comparing the mismatches between the assessments made by na \u00a8 \u0131ve listeners and by the speakers that generated the data . The analysis is based on the hypothesis that people are better decoders of their own emotions . Therefore , self-assessments will be closer to the intended emotions . Using the IEMOCAP database , discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments evaluated by the actors and na \u00a8 \u0131ve listeners are compared . The results indicate that there is a mismatch between the expression and perception of emotion . The speakers in the database assigned their own emotions to more specific emotional categories , which led to more extreme values in the activation-valence space .",
  "kg2text": [
    "This paper analyzes the speakers in the database, focusing on the mismatches identified between their emotional assessments and the self-assessments they provided. It also examines the assumption that the emotion perceived by a listener accurately reflects the intended emotion conveyed by a speaker. Mismatches, which are discrepancies between the expression and perception of emotion, are made by speakers and have a broader term encompassing assessments. The IEMOCAP database plays a crucial role in comparing emotional assessments, including both discrete (categorical) and continuous (attribute-based) evaluations, which are conducted by both actors and naive listeners. Furthermore, the emotion perceived by the listener is often a good approximation of the intended emotion conveyed by the speaker, highlighting the complexities of emotional communication.",
    "The expression and perception of emotion encompasses various aspects of how emotions are conveyed and understood, with expression being a broader term. Within this context, the intended emotion conveyed by the speaker is linked to the speaker themselves, who are recognized as decoders of their own emotions. People, as decoders, engage in assessments that are part of a larger analysis, which is based on the hypothesis that individuals are better at interpreting their own emotional states than external observers. This analysis also highlights the emotion perceived by the listener, which is another broader term related to the listener's role in emotional communication. Furthermore, emotional categories lead to more extreme values in the activation-valence space, indicating the intensity of emotions. The hypothesis that people are better decoders of their own emotions involves individuals who decode their own emotions, while the emotion perceived by the listener and more specific emotional categories are both broader terms under the umbrella of emotion. Discrete and continuous emotional assessments are also categorized under emotion, and self-assessments are expected to be closer to the intended emotions that speakers aim to convey. Overall, the intended emotions, which are broader terms of emotion, reflect the complex interplay between speakers and listeners in the realm of emotional expression.",
    "In the realm of emotional analysis, more extreme values in the activation-valence space are categorized under the broader concept of the activation-valence space, which serves as a framework for understanding emotions based on their activation and valence. Similarly, the expression and perception of emotion, the intended emotion conveyed by the speaker, and their own emotions all fall under the broader term of emotion, highlighting the complexity of emotional experiences. Additionally, the hypothesis that people are better decoders of their own emotions is also classified within the domain of emotion, suggesting that individuals may have a unique insight into their emotional states. The speakers in the database, which includes the IEMOCAP dataset, represent a structured collection of data that aids in the study of emotional expression in speech. Recent results from this database indicate a mismatch between the expression and perception of emotion, underscoring the challenges in accurately interpreting emotional signals. Overall, these relationships illustrate the intricate connections between various aspects of emotion and the frameworks used to study them."
  ],
  "times": [
    8.911055088043213
  ]
}