{
  "iri": "Paper-24",
  "title": "CVPR_2006_10_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-24-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-24-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-1",
              "text": "In this paper we discuss object detection when only a small number of training examples are given ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-2",
              "text": "Specifically , we show how to incorporate a simple prior on the distribution of natural images into support vector machines ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-3",
              "text": "SVMs are known to be robust to overfitting ; however , a few training examples usually do not represent well the structure of the class ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-4",
              "text": "Thus the resulting detectors are not robust and highly depend on the choice of the training examples ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-5",
              "text": "We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB- ."
            },
            {
              "iri": "Paper-24-Section-1-Paragraph-1-Sentence-6",
              "text": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "In this paper we discuss object detection when only a small number of training examples are given . Specifically , we show how to incorporate a simple prior on the distribution of natural images into support vector machines . SVMs are known to be robust to overfitting ; however , a few training examples usually do not represent well the structure of the class . Thus the resulting detectors are not robust and highly depend on the choice of the training examples . We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB- . Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples .",
  "kg2text": [
    "When only a small number of training examples are given, object detection can be challenging. To improve robustness to this limitation, we discuss incorporating a simple prior on the distribution of natural images into support vector machines (SVMs). This approach obtained the resulting detector, which is more robust than traditional SVM-based detectors that rely solely on a few training examples. In fact, these detectors usually do not represent well the structure of the class and are prone to overfitting when trained with only 10 positive and 10 negative examples. By contrast, our prior-based approach improves object detection by leveraging the background knowledge about natural images."
  ],
  "times": [
    5.905445098876953
  ]
}