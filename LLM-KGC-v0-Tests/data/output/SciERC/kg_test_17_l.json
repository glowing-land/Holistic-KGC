{
  "iri": "Paper-17",
  "title": "ICML_2016_11_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-17-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-17-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-17-Section-1-Paragraph-1-Sentence-1",
              "text": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual ."
            },
            {
              "iri": "Paper-17-Section-1-Paragraph-1-Sentence-2",
              "text": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA ."
            },
            {
              "iri": "Paper-17-Section-1-Paragraph-1-Sentence-3",
              "text": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery ."
            },
            {
              "iri": "Paper-17-Section-1-Paragraph-1-Sentence-4",
              "text": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions ."
            },
            {
              "iri": "Paper-17-Section-1-Paragraph-1-Sentence-5",
              "text": "In particular , our guarantee suggests that a substantial amount of low rank matrices , which can not be recovered by standard robust PCA , become re-coverable by our proposed method ."
            },
            {
              "iri": "Paper-17-Section-1-Paragraph-1-Sentence-6",
              "text": "The result theoretically justifies the effectiveness of features in robust PCA ."
            },
            {
              "iri": "Paper-17-Section-1-Paragraph-1-Sentence-7",
              "text": "In addition , we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual . While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA . Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery . We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions . In particular , our guarantee suggests that a substantial amount of low rank matrices , which can not be recovered by standard robust PCA , become re-coverable by our proposed method . The result theoretically justifies the effectiveness of features in robust PCA . In addition , we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information .",
  "kg2text": [
    "We propose to study the problem of robust principal component analysis (PCA) with side information. Our proposed method incorporates this side information into a convex problem, which can exactly recover low-rank matrices under certain conditions. This approach improves upon current methods that only consider the low rank plus sparse structure and cannot recover many machine learning applications. The result theoretically justifies the effectiveness of features in robust PCA, suggesting that our guarantee suggests that a substantial amount of low-rank matrices become re-coverable by our proposed method.",
    "Current approaches are developed by only considering low rank plus sparse structure. Noisy image classification, a broader term of machine learning applications, has its own set of challenges. In some cases, side information about row and/or column entities may also be given to aid in dimensionality reduction techniques like our proposed method, which can recover low rank matrices that standard robust PCA cannot. Our guarantee suggests that many such matrices become re-coverable by this approach, making it a valuable contribution to the field of paper."
  ],
  "times": [
    12.803441762924194
  ]
}