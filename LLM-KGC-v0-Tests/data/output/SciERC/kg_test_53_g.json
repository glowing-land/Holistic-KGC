{
  "iri": "Paper-53",
  "title": "ICML_1995_38_abs",
  "authors": [],
  "keywords": [],
  "sections": [
    {
      "iri": "Paper-53-Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Paper-53-Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-1",
              "text": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-2",
              "text": "In this paper , we present methods by which an agent learns action models from its own experience and from its observation of a domain expert ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-3",
              "text": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-4",
              "text": "Training instances are generated from experience and observation , and a variant of GOLEM is used to learn action models from these instances ."
            },
            {
              "iri": "Paper-53-Section-1-Paragraph-1-Sentence-5",
              "text": "The integrated learning system has been experimentally validated in simulated construction and ooce domains ."
            }
          ]
        }
      ]
    }
  ],
  "summary": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems . In this paper , we present methods by which an agent learns action models from its own experience and from its observation of a domain expert . These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms . Training instances are generated from experience and observation , and a variant of GOLEM is used to learn action models from these instances . The integrated learning system has been experimentally validated in simulated construction and ooce domains .",
  "kg2text": [
    "This paper presents methods for learning action models, which are essential for autonomous agents to enhance their planning capabilities. The methods enable agents to learn action models from both their own experiences and the observations of domain experts. Specifically, GOLEM and a variant of GOLEM are utilized to learn these action models, which are broader representations of actions. The action model formalism provides a structured approach for this learning process. Agents learn action models through experience and observation, with the latter encompassing the analysis of a domain expert's actions. Furthermore, the methods introduced in this paper differ from previous work by incorporating effective noise-handling mechanisms, which improve the reliability of the learning process. The integrated learning system has been experimentally validated in simulated construction and operational domains, demonstrating its effectiveness in real-world scenarios. Overall, the relationship between experience, observation, and the learning of action models is crucial for the development of reactive agents.",
    "The action model formalism is better suited to meet the needs of a re-active agent, which is a broader term encompassing agents that learn from their environment. In the area of learning for autonomous agents, noise-handling mechanisms are successfully implemented to enhance the reliability of action model learning. Training instances, which are generated from experience and observation, are crucial for learning action models. These training instances are utilized to develop action models that enable agents to plan effectively. Furthermore, simulated construction and ooce domains serve as controlled environments for testing these learning systems, with ooce domains being a broader category. The methods described in this paper, which also falls under the broader term of paper, include techniques for enabling agents to learn from their own experiences and the observation of a domain expert, who is a knowledgeable individual in a specific field. Overall, the integration of noise-handling mechanisms and structured methodologies plays a significant role in advancing the capabilities of autonomous agents."
  ],
  "times": [
    4.710044622421265
  ]
}