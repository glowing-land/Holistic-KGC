{
  "iri": "Paper-A_Pipeline_For_Analysing_Grant_Applications",
  "title": "A Pipeline For Analysing Grant Applications",
  "authors": [
    "Shuaiqun Pan",
    "Sergio J. Rodr\u00edguez M\u00e9ndez",
    "Kerry Taylor"
  ],
  "keywords": [
    "Grant applications",
    "Random Forest classifier",
    "TF-IDF algorithm"
  ],
  "sections": [
    {
      "iri": "Section-1",
      "subtitle": "Abstract",
      "paragraphs": [
        {
          "iri": "Section-1-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-1-Paragraph-1-Sentence-1",
              "text": "Data mining techniques can transform massive amounts of unstructured data into quantitative data that quickly reveal insights, trends, and patterns behind the original data."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-2",
              "text": "In this paper, a data mining model is applied to analyse the 2019 grant applications submitted to an Australian Government research funding agency to investigate whether grant schemes successfully identifies innovative project proposals, as intended."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-3",
              "text": "The grant applications are peer-reviewed research proposals that include specific 'innovation and creativity' (IC) scores assigned by reviewers."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-4",
              "text": "In addition to predicting the IC score for each research proposal, we are particularly interested in understanding the vocabulary of innovative proposals."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-5",
              "text": "In order to solve this problem, various data mining models and feature encoding algorithms are studied and explored."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-6",
              "text": "As a result, we propose a model with the best performance, a Random Forest (RF) classifier over documents encoded with features denoting the presence or absence of unigrams."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-7",
              "text": "In specific, the unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, which only implements the IDF part of TF-IDF."
            },
            {
              "iri": "Section-1-Paragraph-1-Sentence-8",
              "text": "Besides the proposed model, this paper also presents a rigorous experimental pipeline for analysing grant applications, and the experimental results prove its feasibility."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-2",
      "subtitle": "Introduction",
      "paragraphs": [
        {
          "iri": "Section-2-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-1-Sentence-1",
              "text": "In the 21st century, the importance of developing cutting-edge scientific research is self-evident for every country."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-2",
              "text": "Therefore, each country's government research funding agencies are willing to provide much scientific research funding to support essential and cutting-edge scientific research each year."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-3",
              "text": "Determining whether a scientific research project is worthy of funding is a significant and rigorous step for funding agencies."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-4",
              "text": "To obtain financial support, scientists and researchers always write research proposals to present their research plans and explain the significance of the project to the funding agencies."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-5",
              "text": "Usually, the government research funding agencies receive thousands of research proposals each year, which are reviewed only by expert panels."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-6",
              "text": "However, with the increase in the number of research proposals and the development of data mining techniques, funding agencies are increasingly using data mining models to assist in the manual review of research proposals."
            },
            {
              "iri": "Section-2-Paragraph-1-Sentence-7",
              "text": "At the same time, it must be made clear that relying solely on data mining models to replace manual checks is not reliable."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-2-Sentence-1",
              "text": "Applying data mining models to a research proposal has several benefits."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-2",
              "text": "First, data mining models can briefly introduce the essential features of the research proposals to help human evaluators better screen the excellent research proposals, such as the influential features of the data mining models across all the research proposals."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-3",
              "text": "Second, an effective data mining model can help human evaluators understand the research proposals\u2019 strengths and weaknesses during the manual review process."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-4",
              "text": "Next, a high-quality data mining model can be applied to develop procedures and guidelines for human assessors to evaluate future research proposals to improve the quality of assessments."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-5",
              "text": "Fourth, for government or funding agencies, different funding projects should be established to improve the quality of various types of research."
            },
            {
              "iri": "Section-2-Paragraph-2-Sentence-6",
              "text": "Data mining models can better understand how to ensure that human evaluators respond to these necessary qualities."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-3-Sentence-1",
              "text": "Based on the benefits and motivations mentioned above, we hope to apply a data mining model with an appropriate feature extraction technique to predict high IC-score research proposals based on the IC scores assigned by the expert reviewers."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-2",
              "text": "Meanwhile, the other primary goal of the project is to develop a predictive vocabulary for contemporaneous proposals and to understand how the model inferred research proposals with high IC scores from the data features."
            },
            {
              "iri": "Section-2-Paragraph-3-Sentence-3",
              "text": "In addition, we focus on proposing an efficient feature extraction technique rather than the choice of classifiers, so we choose the very common Decision Tree (DT) and RF classifiers for experimental comparison."
            }
          ]
        },
        {
          "iri": "Section-2-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-2-Paragraph-4-Sentence-1",
              "text": "The contributions of this paper are listed as follows:"
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-2",
              "text": "A strict experimental pipeline for analysing grant applications is given, and the experimental results prove its feasibility."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-3",
              "text": "A model is proposed with a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-4",
              "text": "The unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, which only implements the IDF part of TF-IDF."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-5",
              "text": "The proposed model for predicting high IC-score research proposals can achieve an accuracy of 84.17% across all types of grant applications."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-6",
              "text": "This paper is divided into six sections."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-7",
              "text": "In the first section, the project's motivation and problem statement are briefly introduced."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-8",
              "text": "In section 2, the background and related work of this project are introduced."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-9",
              "text": "The methodology section mainly describes the pipeline we apply for this research project."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-10",
              "text": "Section 4 brings the overall design of the project."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-11",
              "text": "Then, the experimental settings and implementations with the hardware platforms are introduced in this section."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-12",
              "text": "The fifth section gives the experimental results of this project and carries on the further analysis."
            },
            {
              "iri": "Section-2-Paragraph-4-Sentence-13",
              "text": "Conclusions and future work are described in section 6."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-3",
      "subtitle": "Related Work",
      "paragraphs": [
        {
          "iri": "Section-3-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-1-Sentence-1",
              "text": "2.1 Computer science in evaluating grant applications."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-2",
              "text": "Oztaysi et al. [2] proposed a multi-criteria approach to evaluate research proposals based on interval-valued intuitionistic fuzzy sets."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-3",
              "text": "In this method, a fuzzy preference relation matrix was used to determine the relative importance of criteria."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-4",
              "text": "The Preference Selection Index (PSI) was another interesting method to evaluate research grant applications [3]."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-5",
              "text": "One advantage of applying the PSI method was that the researcher did not need to determine the weight criteria."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-6",
              "text": "Another similar and recently related work was the research paper classification system built based on the TF-IDF and LDA schemes [4]."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-7",
              "text": "This system used a Latent Dirichlet allocation (LDA) scheme to extract representative keywords from the abstract of each paper [5]."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-8",
              "text": "The K-means clustering algorithm [6] was applied to group papers with similar topics based on the TF-IDF vector encoding of each paper."
            },
            {
              "iri": "Section-3-Paragraph-1-Sentence-9",
              "text": "The results showed that the LDA with 30 keywords using TF-IDF obtained the best F-score compared with the LDA with fewer keywords."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-2-Sentence-1",
              "text": "2.2 Term vectors and statistical measures in text representation."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-2",
              "text": "TF-IDF is commonly used in data mining and information retrieval."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-3",
              "text": "TF indicates the frequency of a word in a document or a collection of documents."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-4",
              "text": "When calculating TF, all the words from documents are treated as equally important."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-5",
              "text": "However, in practice, people only pay attention to a certain of words."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-6",
              "text": "For example, \u201cthis\", \u201care\", and \u201cit\" usually do not represent important in most cases."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-7",
              "text": "Then, the IDF is implemented to adjust the term weights in documents which can increase the weights of those rare but important words and weigh down those frequent words but less important."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-8",
              "text": "In 2016, Guo and Yang [7] analysed the shortcomings of the TF-IDF algorithm."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-9",
              "text": "Then, an intra-class dispersion algorithm based on TF-IDF was proposed."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-10",
              "text": "Chen et al. [8] proposed a new term weighting technique called Term Frequency & Inverse Gravity Moment (TF-IGM), which was mainly used to measure the class discrimination of a term."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-11",
              "text": "The experimental results showed that the TF-IGM performed better than the traditional TF-IDF in three standard corpora."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-12",
              "text": "Das and Chakraborty [9] proposed a text sentiment classification technique based on the TF-IDF algorithm and Next Word Negation (NWN)."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-13",
              "text": "In addition, this study also compared the binary bag of words, TF-IDF, and TF-IDF with NWN algorithms."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-14",
              "text": "Fan and Qin [10] proposed another improved TF-IDF algorithm, TF-IDCRF, which focused on the relationship between classes in the classification model."
            },
            {
              "iri": "Section-3-Paragraph-2-Sentence-15",
              "text": "In 2019, an improved TF-IDF algorithm based on classification discrimination strength was proposed for text classification [11]."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-3-Sentence-1",
              "text": "2.3 Data mining models in text classification."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-2",
              "text": "In the field of data mining, the DT classifier is widely welcome for its advantage of showing how models make decisions according to the data features [12]."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-3",
              "text": "RF classifier is another popular data mining model."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-4",
              "text": "The term forest can be interpreted to mean that each classifier in the ensemble is a DT classifier, while all combinations of classifiers are a forest [13]."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-5",
              "text": "In the RF classifier, each decision tree also selects the optimal attribute based on the Attribute Selection Measures (ASM)."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-6",
              "text": "At the same time, each decision tree depends independently on a random sample."
            },
            {
              "iri": "Section-3-Paragraph-3-Sentence-7",
              "text": "The RF classifier votes on each tree in specific classification problems and selects the most popular category as the final result."
            }
          ]
        },
        {
          "iri": "Section-3-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-3-Paragraph-4-Sentence-1",
              "text": "In 2016, a news classification method was proposed based on the TF-IDF algorithm and Support Vector Machine (SVM) [14]."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-2",
              "text": "Based on a different number of n-grams and various data sets, five data mining classifiers were built and compared [15]."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-3",
              "text": "The results can guide researchers to select an appropriate data mining model according to the size of the data set."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-4",
              "text": "Four different data mining models were implemented with five different ensemble methods, and the experimental results showed that the RF classifier with the Bagging ensemble method achieved the best performance [16]."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-5",
              "text": "Wongso et al. [17] applied TF-IDF and SVD algorithms [18] to the feature selection step and compare the two algorithms."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-6",
              "text": "At the same time, the Multivariate Bernoulli Naive Bayes [19], and SVM were compared in this study."
            },
            {
              "iri": "Section-3-Paragraph-4-Sentence-7",
              "text": "Finally, with the combination of TF-IDF and Multivariate Bernoulli Naive Bayes, news articles in the Indonesian Language corpus were classified, and the best result was obtained [17]."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-4",
      "subtitle": "Methodology",
      "paragraphs": [
        {
          "iri": "Section-4-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-1-Sentence-1",
              "text": "This section details the workflow of our proposed pipeline and the data mining model."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-2",
              "text": "Fig. 1 shows the pipeline of analysing grant applications."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-3",
              "text": "3.1 Data set."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-4",
              "text": "The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-5",
              "text": "3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7)."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-6",
              "text": "In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-7",
              "text": "Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d"
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-8",
              "text": "Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-9",
              "text": "A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-10",
              "text": "By default, all JSON files are stored in CouchDB database [21] based on the proposal index."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-11",
              "text": "Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-12",
              "text": "At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-13",
              "text": "Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-14",
              "text": "In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project."
            },
            {
              "iri": "Section-4-Paragraph-1-Sentence-15",
              "text": "Table 1 also shows the median IC score, 5.0, the most frequent IC score."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-2-Sentence-1",
              "text": "3.2 Text pre-processing for grant applications."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-2",
              "text": "HaCohen-Kerner et al. [22] proved that text pre-processing techniques could make the model achieve better performance than without the text pre-processing step."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-3",
              "text": "After all the text is extracted, all characters, whether uppercase or lowercase, are converted to lowercase."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-4",
              "text": "Then, the numbers are also removed because the numbers in the research proposals are not relevant for future analysis."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-5",
              "text": "Thirdly, removing punctuations and tokenizing by whitespace are also adopted, which make the text into small pieces called tokens."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-6",
              "text": "In addition, the deletion of stop words is one of the most crucial text pre-processing techniques."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-7",
              "text": "Fani et al. [23] have shown that deleting stop words can improve the performance of data mining tasks."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-8",
              "text": "Therefore, we create a list of custom stop words according to the IDF formula and delete the IDF value of the term from the text lower than 1.0."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-9",
              "text": "The reason for choosing 1.0 is that after implementation some preliminary experiments, we confirm that the feature words considered as important by DT and RF classifiers will less than 1000 words."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-10",
              "text": "Meanwhile, the words whose IDF value are less than 1.0 only account for 0.2% of the total words, and they are all common words such as \u201cnext\u201d, \u201cshift\u201d and \u201cother\u201d."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-11",
              "text": "We believe that these words appear too frequently and have no influence on the experimental results."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-12",
              "text": "Finally, text stemming is the last technique we apply in the text pre-processing step."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-13",
              "text": "Text stemming is a technique for reducing each word to its root format [24]."
            },
            {
              "iri": "Section-4-Paragraph-2-Sentence-14",
              "text": "It helps to reduce the vocabulary and surface syntax to get closer to the meaning of each term, and the Porter Stemming algorithm [25] is implemented in this step."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-3-Sentence-1",
              "text": "This section details the workflow of our proposed pipeline and the data mining model."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-2",
              "text": "Fig. 1 shows the pipeline of analysing grant applications."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-3",
              "text": "3.1 Data set."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-4",
              "text": "The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-5",
              "text": "3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7)."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-6",
              "text": "In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-7",
              "text": "Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d"
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-8",
              "text": "Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-9",
              "text": "A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-10",
              "text": "By default, all JSON files are stored in CouchDB database [21] based on the proposal index."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-11",
              "text": "Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-12",
              "text": "At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-13",
              "text": "Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-14",
              "text": "In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project."
            },
            {
              "iri": "Section-4-Paragraph-3-Sentence-15",
              "text": "Table 1 also shows the median IC score, 5.0, the most frequent IC score."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-4-Sentence-1",
              "text": "3.4 Design and apply the feature extraction technique."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-2",
              "text": "We propose a modified TF-IDF algorithm, which only implements the IDF part of TF-IDF as the feature extraction technique."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-3",
              "text": "In specific, if the term exists at least once in the documents, specify the IDF value for this term directly."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-4",
              "text": "In addition, if a term does not exist in the documents, then the term is assigned a value of 0."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-5",
              "text": "The design of this modified feature extraction algorithm follows the idea that rare terms can define innovativeness."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-6",
              "text": "The experiment also considers the n-grams [26]."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-7",
              "text": "Unigram is the most common choice for text classification tasks, but bigram and trigram may better represent scientific terms, where bigram is two consecutive words in a sentence, and trigram is three consecutive words in a sentence."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-8",
              "text": "At the same time, when collecting proposals, we also consider deleting the words that only exist once or twice, because very rare terms tend not to be predictive."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-9",
              "text": "In addition, the bigram mentioned in this paper denotes a combination of the unigrams and bigrams."
            },
            {
              "iri": "Section-4-Paragraph-4-Sentence-10",
              "text": "The trigram denotes a combination of the unigrams, bigrams, and trigrams."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-5-Sentence-1",
              "text": "3.5 Apply data mining models with grant applications."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-2",
              "text": "This paper uses DT and RF classifiers for text classification because we would like to find out the most influential terms and understood how the data mining model predicts high and low IC-score research proposals."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-3",
              "text": "The DT and RF classifiers are convenient to present this valuable information."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-4",
              "text": "Based on the experimental result of the high and low IC-score research proposals selection, all experiments are conducted with the low IC-score research proposals (IC score 0~15%) and the high IC-score research proposals (IC score 85%~100%)."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-5",
              "text": "In the comparison study of feature extraction techniques, 400 research proposals for each low and high IC score are randomly selected for model training, and the training data is 85%, and the test data is 15%."
            },
            {
              "iri": "Section-4-Paragraph-5-Sentence-6",
              "text": "In order to analyse the proposed model in the end, the 100 most influential terms from the collections of research proposals are extracted by the function from scikit-learn library [27], which bring us an intuitive understanding of how much each term contributes to reducing the weighted impurities."
            }
          ]
        },
        {
          "iri": "Section-4-Paragraph-6",
          "sentences": [
            {
              "iri": "Section-4-Paragraph-6-Sentence-1",
              "text": "3.6 Analyse moderate IC-score grant applications."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-2",
              "text": "We also conduct several experiments to analyse moderate IC-score research proposals based on the proposed model."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-3",
              "text": "The purpose of this series of experiments is to determine whether there is a relation between proposals with moderate IC scores and that of high and low IC scores."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-4",
              "text": "Since the proposed model is trained based on the low IC-score proposals of 0~15% and high IC-score proposals of 85~100%, the range of research proposals with moderate IC score is 15%~85%."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-5",
              "text": "Based on the median IC score, the selection range of testing moderate IC score by testing several cut-off options, such as 20, 25, 30, 35, 40, 45, and 50."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-6",
              "text": "Table 4 shows a list of experiments used to analyse the research proposals of moderate IC score."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-7",
              "text": "Considering the symmetric distribution of the IC scores, new research proposals with low and high IC scores are selected in each experiment, and performance analysis is conducted based on the proposed training model."
            },
            {
              "iri": "Section-4-Paragraph-6-Sentence-8",
              "text": "In addition to the experiments in Table 4, another experiment is designed to check the median IC-score research proposals (IC score = 5.0) to predict the proportion of high or low IC-score research proposals rather than calculate the test accuracy."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-5",
      "subtitle": "Experimental Settings",
      "paragraphs": [
        {
          "iri": "Section-5-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-1-Sentence-1",
              "text": "This section describes all experimental settings for this paper."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-2",
              "text": "Initially, MEL [20] is implemented through a set of Python-based methods to extract metadata for all supported file types."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-3",
              "text": "To extract metadata from the PDF version of a file, the Tesseract-OCR method [28] and pdftotext tool [29] are applied."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-4",
              "text": "In the statistical analysis of grant applications, the Python language and Numpy library [30] are used to calculate the median, mode, and other statistical measurements of IC score."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-5",
              "text": "In the experiments of selecting high, low, and moderate IC-score research proposals and implementing the data mining models, the scikit-learn library [27] is applied to implement the DT and RF classifiers."
            },
            {
              "iri": "Section-5-Paragraph-1-Sentence-6",
              "text": "The python library gensim [31] is used to implement the TF-IDF algorithm and the newly proposed modified TF-IDF algorithm."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-2-Sentence-1",
              "text": "Hyper-parameter tuning is a significant step in applying data mining models, and the Bayesian Optimization tool [32] is applied."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-2",
              "text": "The first step to implement Bayesian Optimization is to define the data mining model, such as the RF classifier and its parameters and corresponding bounds."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-3",
              "text": "In addition, we also need to implement the scoring method and the cross-validation setup."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-4",
              "text": "Secondly, the maximize method is used to run the technique with n_iter and init_points parameters."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-5",
              "text": "The n_iter is defined for the number of steps to run the optimization function."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-6",
              "text": "The more steps, the easier it is to find the best accuracy value."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-7",
              "text": "The init_points is defined for random exploration on the parameter space, which helps to explore the diversity of the space."
            },
            {
              "iri": "Section-5-Paragraph-2-Sentence-8",
              "text": "Finally, the parameter values for each accuracy are listed, highlighting the best combination of the parameter and the target value."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-3-Sentence-1",
              "text": "To find the hyper-parameters of the RF classifier, the range of each parameter is set as follows: max_depth = (5, 60), min_samples_split = (10, 100), max_features = (0.1, 0.999), max_samples_leaf = (10, 50) and n_estimation = (100, 400)."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-2",
              "text": "For the DT classifier, the range settings for finding hyper-parameters are as follows: max_depth = (3, 10), min_samples_split = (3, 10), max_features = (0.1, 0.999),and max_samples_leaf = (3, 10)."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-3",
              "text": "The max_depth parameter indicates the maximum depth of the tree, and the max_features denotes the number of features to consider when finding the best split [27]."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-4",
              "text": "The parameters min_samples_leaf, min_samples_split, and n_estimators are defined as the minimum number of samples needed on a leaf node, the minimum number of samples needed to split an internal node, and the number of trees in the forest, respectively."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-5",
              "text": "All experiments related to RF classifier and DT classifier adopt the same setting of the hyper-parameter range."
            },
            {
              "iri": "Section-5-Paragraph-3-Sentence-6",
              "text": "Meanwhile, the 10-fold cross-validation method is also applied in finding the hyper-parameters."
            }
          ]
        },
        {
          "iri": "Section-5-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-5-Paragraph-4-Sentence-1",
              "text": "To evaluate the performance of the newly proposed modified TF-IDF algorithm and the TF-IDF algorithm with different data mining classifiers, the classification accuracy (Acc), F1 score are selected as the evaluation metrics."
            },
            {
              "iri": "Section-5-Paragraph-4-Sentence-2",
              "text": "The hardware platform is MacBook Pro with Intel Core i7 2.9 GHz Quard-Core processor."
            },
            {
              "iri": "Section-5-Paragraph-4-Sentence-3",
              "text": "The memory configuration is 16GB 2133 MHz LPDDR3."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-6",
      "subtitle": "Experimental Result",
      "paragraphs": [
        {
          "iri": "Section-6-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-1-Sentence-1",
              "text": "Table 5 shows the performance of the TF-IDF algorithm with DT and RF classifiers."
            },
            {
              "iri": "Section-6-Paragraph-1-Sentence-2",
              "text": "It can be found that the RF classifier can consistently achieve better performance than the DT classifier under the different settings of the n-grams and deletion of rare terms."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-2-Sentence-1",
              "text": "Table 6 shows the performance of the newly proposed modified TF-IDF algorithm with DT and RF classifiers."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-2",
              "text": "Based on the comparison of Table 5 and Table 6, the best performance is achieved with 84.17% accuracy by the RF classifier with the newly proposed modified TF-IDF algorithm except the No.14 model combination in Table 6."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-3",
              "text": "The hyper-parameters are max_depth = 22, max_features = 0.9931, min_samples_leaf = 11, min_samples_split = 67 and n_estimation = 102."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-4",
              "text": "To include all the terms from the corpus, we choose the RF classifier based on unigram and the modified TF-IDF algorithm as the final proposed model."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-5",
              "text": "Another reason why we do not choose the bigram and trigram combinations as the proposed model is the bigram and trigram terms are in fact not regarded as essential features by DT and RF classifiers."
            },
            {
              "iri": "Section-6-Paragraph-2-Sentence-6",
              "text": "Features extracted from the proposed model shows that only 618 features are considered significant, based on tens of thousands of features in the research proposals."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-3",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-3-Sentence-1",
              "text": "Based on the comparison of the two tables, it can be found that the proposed modified TF-IDF algorithm is practical and effective despite two or three exceptions exist."
            },
            {
              "iri": "Section-6-Paragraph-3-Sentence-2",
              "text": "At the same time, the experimental results prove that the core idea of defining the modified TF-IDF algorithm is meaningful and show the rare terms associated with innovativeness."
            },
            {
              "iri": "Section-6-Paragraph-3-Sentence-3",
              "text": "It should also be noted that the newly proposed modified TF-IDF algorithm can be understood as a simple encoding technique, such as taking the value 0 or the IDF value of the term depending on whether the term exists in the research proposals."
            },
            {
              "iri": "Section-6-Paragraph-3-Sentence-4",
              "text": "Based on the decision tree plots generated by the best performance model, it can be found that the modified TF-IDF algorithm does not affect the shape of the tree as seen in the tree graph, helping to understand whether the chosen split term is rare or common."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-4",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-4-Sentence-1",
              "text": "From the result of finding hyper-parameters, it can be found that the best performing model does not use all the features to apply with the data mining algorithms, such as the RF classifier only uses 99.31% features."
            },
            {
              "iri": "Section-6-Paragraph-4-Sentence-2",
              "text": "In addition, although we consider different n-grams, especially bigram and trigram, with removing scarce words, Table 5 and Table 6 could prove that it might help but not always."
            },
            {
              "iri": "Section-6-Paragraph-4-Sentence-3",
              "text": "Moreover, based on the same feature extraction algorithm, the classification accuracy of the RF classifier is always better than that of the DT classifier."
            },
            {
              "iri": "Section-6-Paragraph-4-Sentence-4",
              "text": "Nevertheless, the results of the DT classifier are still crucial because the plot of DT classifier contains all the decisions."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-5",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-5-Sentence-1",
              "text": "Fig. 2 shows the confusion matrix of the proposed model for the \u201cunseen\u201d test data."
            },
            {
              "iri": "Section-6-Paragraph-5-Sentence-2",
              "text": "It shows 13 high IC-score research proposals are incorrectly predicted as low IC-score proposals."
            },
            {
              "iri": "Section-6-Paragraph-5-Sentence-3",
              "text": "In addition, 6 research proposals with low IC scores are guessed wrongly which they are predicted as high IC-score proposals."
            },
            {
              "iri": "Section-6-Paragraph-5-Sentence-4",
              "text": "The number 59 denotes that the proposed model correctly predicts 59 research proposals with low IC scores and 42 with high IC scores."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-6",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-6-Sentence-1",
              "text": "In addition to analysing the confusion matrix, we also extract the 100 most influential features from the proposed model, which gives an intuitive understanding of how much each feature contributes to reducing the weighted impurities."
            },
            {
              "iri": "Section-6-Paragraph-6-Sentence-2",
              "text": "The top 100 features give us a better understanding of what is going on inside the black box."
            },
            {
              "iri": "Section-6-Paragraph-6-Sentence-3",
              "text": "A measure of the feature importance is valuable for internal model development purposes by showing to what extent features contribute to test data."
            },
            {
              "iri": "Section-6-Paragraph-6-Sentence-4",
              "text": "Although the classifier is only established for the 2019 grant applications and may not predict the high research proposals for future applications, these unique terms are still valuable and meaningful as a reference for evaluators."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-7",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-7-Sentence-1",
              "text": "Table 7 brings the performance of checking research proposals of moderate IC scores based on the proposed model."
            },
            {
              "iri": "Section-6-Paragraph-7-Sentence-2",
              "text": "Based on the test accuracy, it can be concluded that there is a correlation between the moderate IC-score research proposals and high/low IC-score research proposals."
            },
            {
              "iri": "Section-6-Paragraph-7-Sentence-3",
              "text": "Moreover, it is easy to find that the proposed model can better predict the research proposals close to the original training set settings (0~15% for low IC score and 85%~100% for high IC score)."
            }
          ]
        },
        {
          "iri": "Section-6-Paragraph-8",
          "sentences": [
            {
              "iri": "Section-6-Paragraph-8-Sentence-1",
              "text": "Based on the confusion matrix above and the experimental results of checking moderate IC-score research proposals, it can be found that the model is always more accurate in predicting research proposals with low IC scores than with high IC scores."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-2",
              "text": "Meanwhile, the research proposals with the median IC score of 5.0 are predicted to be about 37.2% with high-IC score research proposals and about 62.8% with low-IC score research proposals."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-3",
              "text": "Therefore, it can be concluded that research proposals with high IC scores use more diverse language than those with low IC-score."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-4",
              "text": "In addition to the experiments analysing all grant applications, we follow the same pipeline and establish a new model to evaluate Ideas Grant applications only, the one with innovation criteria."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-5",
              "text": "Applying the same method but with different hyper-parameters, the best performing model for analysing the Ideas Grants can reach an accuracy of 82.5%."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-6",
              "text": "In every Ideas Grant application, there is a section called \u201cInnovation and Creativity statement.\u201d"
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-7",
              "text": "We also extract this part from each Ideas grant and analyse using the proposed pipeline."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-8",
              "text": "The experimental result shows that the proposed method can achieve 68.33% accuracy on analysing \u201cInnovation and Creativity statement\u201d sections only from Ideas Grants."
            },
            {
              "iri": "Section-6-Paragraph-8-Sentence-9",
              "text": "Although we guess the IC score is more relevant to the \u201cInnovation and Creativity statement\u201d compared with other sections, as evaluators may describe their innovation in this section, the experimental result does not support our guess."
            }
          ]
        }
      ]
    },
    {
      "iri": "Section-7",
      "subtitle": "Conclusion",
      "paragraphs": [
        {
          "iri": "Section-7-Paragraph-1",
          "sentences": [
            {
              "iri": "Section-7-Paragraph-1-Sentence-1",
              "text": "In summary, a pipeline for analysing grant applications has been proposed with several crucial steps."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-2",
              "text": "The proposed data mining model is an RF classifier over documents encoded with features denoting the presence or absence of unigrams."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-3",
              "text": "Specifically, the unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency(TF-IDF) algorithm, which only implements the IDF part of TF-IDF."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-4",
              "text": "As a result, the proposed model achieves an accuracy of 84.17% based on all types of grant applications."
            },
            {
              "iri": "Section-7-Paragraph-1-Sentence-5",
              "text": "In addition, we also build experiments for Ideas Grants only and \u201cInnovation and Creativity statement\u201d single section."
            }
          ]
        },
        {
          "iri": "Section-7-Paragraph-2",
          "sentences": [
            {
              "iri": "Section-7-Paragraph-2-Sentence-1",
              "text": "The future work can be carried out from different perspectives."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-2",
              "text": "Firstly, innovation should not be the only evaluation criterion."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-3",
              "text": "In order to better evaluate the entire grant application, we should consider other evaluation scores and establish a more comprehensive system that can predict a grant application based on multiple criteria."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-4",
              "text": "Secondly, in the future, this project can also apply some other effective data mining models, such as SVM, AdaBoost, and Xgboost."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-5",
              "text": "In addition, the pre-trained language models in the Natural Language Processing (NLP) field perform well in understanding text semantics, which can also be our next research focus."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-6",
              "text": "Thirdly, our proposed method cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications."
            },
            {
              "iri": "Section-7-Paragraph-2-Sentence-7",
              "text": "Therefore, it is an important research topic to consider building a long-term data mining model to predict future grant applications."
            }
          ]
        }
      ]
    }
  ],
  "summary": "A data mining model was applied to analyze Australian Government research grant applications from 2019, aiming to identify innovative project proposals using a Random Forest classifier and unigram features.\n\nGovernments use data mining models with feature extraction techniques like Decision Tree or Random Forest classifiers to review research proposals, improving evaluation quality and achieving an accuracy of 84.17%.\n\nComputer science methods for evaluating grant applications include multi-criteria approaches using interval-valued intuitionistic fuzzy sets and Preference Selection Index (PSI), as well as text representation techniques like TF-IDF to adjust term weights.\n\nThis section details the workflow of our proposed pipeline and the data mining model. Fig. 1 shows the pipeline of analysing grant applications. 3.1 Data set. The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency. 3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7). In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants. Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary. A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content. By default, all JSON files are stored in CouchDB database [21] based on the proposal index. Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals. At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score. Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores. In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project. Table 1 also shows the median IC score, 5.0, the most frequent IC score.\n\n3.2 Text pre-processing for grant applications. HaCohen-Kerner et al. [22] proved that text pre-processing techniques could make the model achieve better performance than without the text pre-processing step. After all the text is extracted, all characters, whether uppercase or lowercase, are converted to lowercase. Then, the numbers are also removed because the numbers in the research proposals are not relevant for future analysis. Thirdly, removing punctuations and tokenizing by whitespace are also adopted, which make the text into small pieces called tokens. In addition, the deletion of stop words is one of the most crucial text pre-processing techniques. Fani et al. [23] have shown that deleting stop words can improve the performance of data mining tasks. Therefore, we create a list of custom stop words according to the IDF formula and delete the IDF value of the term from the text lower than 1.0. The reason for choosing 1.0 is that after implementation some preliminary experiments, we confirm that the feature words considered as important by DT and RF classifiers will less than 1000 words. Meanwhile, the words whose IDF value are less than 1.0 only account for 0.2% of the total words, and they are all common words such as \u201cnext\u201d, \u201cshift\u201d and \u201cother\u201d. We believe that these words appear too frequently and have no influence on the experimental results. Finally, text stemming is the last technique we apply in the text pre-processing step. Text stemming is a technique for reducing each word to its root format [24]. It helps to reduce the vocabulary and surface syntax to get closer to the meaning of each term, and the Porter Stemming algorithm [25] is implemented in this step.\n\nThis section details the workflow of our proposed pipeline and the data mining model. Fig. 1 shows the pipeline of analysing grant applications. 3.1 Data set. The data set used to analyse the grant applications is the 2019 grant applications submitted to an Australian Government research funding agency. 3,805 research proposals are given in this data set with peer-reviewed IC scores (1 - 7). In addition, the entire data set contains different types of grant applications, such as Synergy Grants, Standard Project Grants, and Ideas Grants. Besides the IC score, reviewers also score several other assessment scores, such as \u201cFeasibility Score\u201d or \u201cSignificance Score.\u201d Since all research proposals are saved in PDF format, extracting the text from PDF files is necessary. A Metadata Extractor & Loader (MEL) [20] tool is applied to extract text from PDF research proposals and save it in a JSON file with metadata sets and content. By default, all JSON files are stored in CouchDB database [21] based on the proposal index. Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals. At the same time, some fundamental values are also the basis of designing the entire pipeline, such as the median IC score and mode IC score. Table 1 shows a statistic of IC scores, showing that 3,693 research proposals have valid IC scores. In addition, 99 research proposals do not contain an IC score, 13 of which have an IC score below 1.0, and these research proposals therefore not be used in this project. Table 1 also shows the median IC score, 5.0, the most frequent IC score.\n\n3.4 Design and apply the feature extraction technique. We propose a modified TF-IDF algorithm, which only implements the IDF part of TF-IDF as the feature extraction technique. In specific, if the term exists at least once in the documents, specify the IDF value for this term directly. In addition, if a term does not exist in the documents, then the term is assigned a value of 0. The design of this modified feature extraction algorithm follows the idea that rare terms can define innovativeness. The experiment also considers the n-grams [26]. Unigram is the most common choice for text classification tasks, but bigram and trigram may better represent scientific terms, where bigram is two consecutive words in a sentence, and trigram is three consecutive words in a sentence. At the same time, when collecting proposals, we also consider deleting the words that only exist once or twice, because very rare terms tend not to be predictive. In addition, the bigram mentioned in this paper denotes a combination of the unigrams and bigrams. The trigram denotes a combination of the unigrams, bigrams, and trigrams.\n\n3.5 Apply data mining models with grant applications. This paper uses DT and RF classifiers for text classification because we would like to find out the most influential terms and understood how the data mining model predicts high and low IC-score research proposals. The DT and RF classifiers are convenient to present this valuable information. Based on the experimental result of the high and low IC-score research proposals selection, all experiments are conducted with the low IC-score research proposals (IC score 0~15%) and the high IC-score research proposals (IC score 85%~100%). In the comparison study of feature extraction techniques, 400 research proposals for each low and high IC score are randomly selected for model training, and the training data is 85%, and the test data is 15%. In order to analyse the proposed model in the end, the 100 most influential terms from the collections of research proposals are extracted by the function from scikit-learn library [27], which bring us an intuitive understanding of how much each term contributes to reducing the weighted impurities.\n\n3.6 Analyse moderate IC-score grant applications. We also conduct several experiments to analyse moderate IC-score research proposals based on the proposed model. The purpose of this series of experiments is to determine whether there is a relation between proposals with moderate IC scores and that of high and low IC scores. Since the proposed model is trained based on the low IC-score proposals of 0~15% and high IC-score proposals of 85~100%, the range of research proposals with moderate IC score is 15%~85%. Based on the median IC score, the selection range of testing moderate IC score by testing several cut-off options, such as 20, 25, 30, 35, 40, 45, and 50. Table 4 shows a list of experiments used to analyse the research proposals of moderate IC score. Considering the symmetric distribution of the IC scores, new research proposals with low and high IC scores are selected in each experiment, and performance analysis is conducted based on the proposed training model. In addition to the experiments in Table 4, another experiment is designed to check the median IC-score research proposals (IC score = 5.0) to predict the proportion of high or low IC-score research proposals rather than calculate the test accuracy.\n\nThis paper uses Python-based methods to extract metadata from various file types, with statistical analysis performed using Numpy, scikit-learn, and gensim. Hyper-parameter tuning was done for RF and DT classifiers.\n\nThe TF-IDF algorithm with RF classifier outperforms DT classifier under different settings, achieving practical and effective results despite some exceptions. The best-performing model uses only 99.31% features.\n\nIn summary, a pipeline for analysing grant applications has been proposed with several crucial steps. The proposed data mining model is an RF classifier over documents encoded with features denoting the presence or absence of unigrams. Specifically, the unigram terms are encoded by a modified Term Frequency - Inverse Document Frequency(TF-IDF) algorithm, which only implements the IDF part of TF-IDF. As a result, the proposed model achieves an accuracy of 84.17% based on all types of grant applications. In addition, we also build experiments for Ideas Grants only and \u201cInnovation and Creativity statement\u201d single section.\n\nThe future work can be carried out from different perspectives. Firstly, innovation should not be the only evaluation criterion. In order to better evaluate the entire grant application, we should consider other evaluation scores and establish a more comprehensive system that can predict a grant application based on multiple criteria. Secondly, in the future, this project can also apply some other effective data mining models, such as SVM, AdaBoost, and Xgboost. In addition, the pre-trained language models in the Natural Language Processing (NLP) field perform well in understanding text semantics, which can also be our next research focus. Thirdly, our proposed method cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications. Therefore, it is an important research topic to consider building a long-term data mining model to predict future grant applications.",
  "kg2text": [
    "The data set used to analyze grant applications consists of 3,805 research proposals submitted to an Australian Government research funding agency in 2019. This paper proposes a pipeline and data mining model that uses Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams. The proposed pipeline is applied to this dataset, which includes peer-reviewed IC scores (1-7) from various types of grants. Our experimental results show that the proposed pipeline can accurately predict high IC-score research proposals. Furthermore, we also extract a specific section ('Innovation and Creativity statement') from each Ideas grant application and analyze it using our proposed pipeline.",
    "The paper proposes a data mining model with a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms, and presents an experimental pipeline for analysing grant applications. The dataset used to analyse the grant applications consists of 3,805 research proposals submitted to an Australian Government research funding agency in 2019, including peer-reviewed IC scores ranging from 1-7. Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals. Our proposed pipeline and data mining model assist human evaluators by providing insights into grant applications, which can be used to better predict high IC-score proposals close to the original training set settings (0~15% for low IC score and 85%~100% for high IC score). The experimental results show that our proposed model achieves an accuracy of 82.5%, demonstrating its effectiveness in predicting research proposals with high IC scores.",
    "This paper proposes a data mining model with a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms, and presents an experimental pipeline for analysing grant applications. The proposed pipeline uses a strict experimental approach to analyse grant proposals, which includes applying a data mining model that utilises the entire dataset. This paper also introduces a methodology used in this research project to predict high IC- score research proposals from grant applications. Furthermore, it is demonstrated how our proposed pipeline and the data mining models can be applied to assist in the manual review of research proposals, achieving an accuracy of 82.5%. The experiment uses A strict experimental pipeline for analysing grant applications, which applies the best performing model for analysing Ideas Grants. Additionally, this paper also extracts a specific section from each Ideas grant and analyses it using the proposed data mining model.",
    "The proposed data mining model, which uses a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams, was used to analyze the current dataset. The experimental results showed that this pipeline can better predict research proposals close to the original training set settings for both low and high IC scores. This paper proposes an analytical framework for analyzing grant applications, which involves extracting text from PDF files, pre-processing the text, designing and applying feature extraction techniques, and using data mining models such as Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams. The proposed model can be used to assist in the manual review of research proposals by providing essential features that help human evaluators better screen excellent research proposals.",
    "The proposed pipeline for analysing grant applications uses a strict experimental approach, which includes applying data mining models to assist in manual review. The project's motivation and problem statement are briefly introduced before designing the whole pipeline. This paper proposes a model that can better predict research proposals close to the original training set settings (0~15% for low IC score and 85%~100% for high IC score). The best performing model for analysing Ideas Grants reaches an accuracy of 82.5%. The entire data set contains key terms related to grant applications used as input for the proposed pipeline, which presents a statistical analysis based on IC scores of research proposals.",
    "This paper proposes a pipeline for analyzing grant applications using data mining techniques. The proposed model can better predict research proposals close to the original training set settings, with an accuracy of up to 82.5%. Before designing the whole pipeline, statistical analysis based on IC scores is required. We also extract specific sections from each Ideas grant and analyze them using a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams. The proposed model uses experimental results to predict IC scores and understand the vocabulary of innovative research proposals.",
    "This paper proposes a data mining model with a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms, which can better predict research proposals close to the original training set settings. The motivation and problem statement for this project are briefly introduced, highlighting the importance of applying data mining models to analyze grant applications and predict high IC-score proposals. A statistical analysis is required based on the IC scores of research proposals before designing the entire pipeline. The proposed model can better predict low IC-score proposals (0-15%) and moderate IC-score proposals (85%-100%). Data mining models are used to assist in evaluating IC-score proposals, which are used as input for the experiments. We also extract a specific section from each Ideas grant application and analyze it using the proposed pipeline. The best performing model can reach an accuracy of 82.5%. Overall, this paper presents a comprehensive experimental pipeline for analyzing grant applications.",
    "The proposed model, which uses a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, can reach an accuracy of 82.5%. Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals. The experimental results show that this model achieves high accuracy in predicting low-IC-score research proposals and moderate accuracy for high-IC-score ones. Data mining models are used to assist human evaluators in reviewing grant applications by introducing key terms related to 2019 grant applications, which can better predict the original training set settings (0~15% for low IC score and 85%~100% for high IC score). The proposed pipeline is applied to analyze grant applications, including data mining models and feature encoding algorithms. This paper proposes a strict experimental pipeline for analyzing grant applications.",
    "The proposed data mining model can better predict research proposals close to the original training set settings, with an accuracy of up to 82.5%. This paper introduces a pipeline for analyzing grant applications using data mining techniques and proposes a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams. The experimental results show that this model can be used to analyze Ideas grants and predict IC scores more accurately than previous methods, making it a valuable tool for understanding innovation and creativity in research proposals.",
    "Before designing the whole pipeline, a statistical analysis is required based on the IC scores of research proposals. The experiment uses the current data set as input and can better predict research proposals close to the original training settings for low IC score and high IC score. The best performing model for analysing Ideas Grants can reach an accuracy of 82.5%, which requires a statistical analysis before designing the pipeline. This paper proposes a pipeline that is based on IC-score proposals, uses the current data set as input, and predicts research proposals with specific 'innovation and creativity' (IC) scores assigned by reviewers.",
    "The authors, who are proposing a data mining model for analyzing grant applications, conducted the experiment to analyze these proposals using their proposed pipeline and data mining models. The Idea used as input was based on the current dataset of 2019 grant applications submitted to an Australian Government research funding agency. This paper proposes a pipeline for analyzing grant applications using data mining techniques, which can better predict research proposals close to the original training set settings (0~15% for low IC score and 85%~100% for high IC score). The proposed model uses all features extracted from research proposals with significant unigrams denoting their presence or absence. It was found that this model is always more accurate in predicting research proposals with low IC scores than those with high IC scores, achieving an accuracy of 82.5%. Furthermore, the best performing model for analyzing Ideas Grants can correctly predict 13 high IC-score research proposals and falls within the range of moderate IC scores.",
    "The data mining models, including various techniques and approaches used for extracting valuable patterns from large datasets, have been applied to assist in the manual review of research proposals. The experiments involved selecting high, low, and moderate IC-score research proposals using a predictive vocabulary developed by our proposed pipeline and the data mining model. This project aimed at developing a long-term data mining model to predict future grant applications based on their innovation and creativity scores. A strict experimental pipeline was applied for analysing grant applications, which included data mining models and feature encoding algorithms. The best performing model achieved an accuracy of 84.17% in predicting high IC-score research proposals from the 2019 grant applications submitted to an Australian Government research funding agency.",
    "In this paper, we propose a data mining model for analysing grant applications. The proposed pipeline involves extracting text from PDF files, pre-processing the text, designing and applying feature extraction techniques, and using various data mining models such as Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams. Our experiments show that this approach can achieve an accuracy of 84.17% across all types of grant applications. We also extract a specific section from each Ideas grant application and analyse it using our proposed pipeline, which details the workflow of our analytical framework used for predicting high IC-score research proposals.",
    "The proposed data mining model, which combines various techniques and algorithms, has been shown to be effective in predicting the 'innovation and creativity' scores of research proposals. The Random Forest classifier with a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm achieved an accuracy of 84.17%, outperforming other models such as Decision Tree classifiers. This model was trained on a large dataset of grant applications, including Synergy Grants, Standard Project Grants, and Ideas Grants. By analyzing the relationships between entities in this graph, we can see that certain research proposals were incorrectly classified by the proposed model, highlighting areas for improvement.",
    "The contributions listed are part of A strict experimental pipeline for analysing grant applications, which includes data mining models to predict high IC-score research proposals. The best performing model can reach an accuracy of 82.5% across all types of grant applications, including Ideas Grant applications only. This is achieved through the use of a Random Forest classifier with unigram features encoded by a modified Term Frequency - Inverse Document Frequency algorithm. The proposed model can better predict research proposals close to the original training set settings for both low and high IC scores. Furthermore, various data mining models were used to develop predictive vocabulary for contemporaneous proposals. Our experimental results show that RF classifiers are effective in predicting moderate IC-score grant applications, which have a relation to high/low IC-score research proposals.",
    "The Australian Government research funding agency received numerous grant applications, including those from researchers and scientists. These proposals were analyzed using data mining models such as Decision Tree (DT) and Random Forest (RF) classifiers to identify high, low, and moderate IC-score research proposals. The best performing model for analyzing Ideas Grants reached an accuracy of 82.5%. Additionally, the proposed training model used a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm to predict innovation and creativity scores in grant applications. Furthermore, scientists and researchers always write research proposals to present their plans and explain project significance to funding agencies.",
    "The Random Forest classifier achieves an accuracy of 84.17% by leveraging features denoted by the presence or absence of unigram terms encoded using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm. This approach is meaningful and highlights rare terms associated with innovativeness, demonstrating its potential in predicting high IC-score research proposals. The proposed model outperforms other data mining models like SVM, AdaBoost, and Xgboost by effectively capturing the essence of innovative project proposals. Furthermore, a statistical analysis reveals that median IC-score research proposals have a broader term encompassing PDF research proposals, while 13 high IC-score research proposals also fall under this category.",
    "Our proposed method, which uses unigram features encoded by a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications. This limitation is due to the nature of our proposed model, which was trained based on low IC-score research proposals. The RF classifier with the newly proposed modified TF-IDF algorithm has a broader term in various data mining models, including Random Forest (RF) classifiers that apply to all grant applications. Another popular data mining model, also known as DT and RF classifiers, is part of these various data mining models. Our proposed method uses Data mining techniques to extract valuable patterns or relationships from large datasets.",
    "The task of predicting high IC-score research proposals involves a pipeline of analyzing grant applications. Before designing this whole pipeline, a statistical analysis is required based on the IC scores of research proposals. A data mining model with Random Forest classifiers can be used to predict these high-scoring proposals. The proposed model uses features denoting the presence or absence of unigram terms and presents an experimental pipeline for analyzing grant applications. This paper proposes a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm, which is applied to documents encoded with TF-IDF weights. Decision Tree (DT) classifiers can be used as part of this data mining model, but Random Forest classifiers have been shown to consistently achieve better performance than DT.",
    "The proposed method for analysing grant applications involves using various data mining models, including Random Forest classifiers and Decision Trees. The pipeline starts with pre-processing of PDF research proposals to extract relevant features. Then, a strict experimental methodology is applied to evaluate high-IC score research proposals based on multiple criteria. The best performing model can reach an accuracy of 82.5% in predicting grant applications. Furthermore, the proposed method achieves better performance than DT classifiers and establishes a more comprehensive system for evaluating grant applications.",
    "The analysis of grant applications reveals that low IC-score research proposals, which are often characterized by a lack of innovation and creativity, can be identified using various data mining models such as SVM, AdaBoost, and Xgboost. These models, including Decision Tree (DT) classifiers, can predict high IC-score research proposals with moderate IC scores ranging from 15% to 85%. The proposed model also utilizes RF classifiers to analyze grant applications, which are typically submitted by scientists and researchers seeking funding for their projects. In addition, the analysis highlights the importance of understanding how data mining algorithms such as DT and RF can be used to predict high IC-score research proposals based on IC scores assigned by expert reviewers.",
    "The proposed modified TF-IDF algorithm, which combines and modifies the original Term Frequency - Inverse Document Frequency (TF-IDF) method, has been shown to be effective for extracting valuable patterns from large datasets. This valuable information can be presented by Decision Tree (DT) and RF classifiers, a pair of machine learning algorithms used for classification tasks. The high IC-score research proposals that have been assigned a peer-reviewed innovation and creativity score of 5 or higher indicate high levels of innovativeness. In contrast, the median IC-score research proposals with an IC score equal to the median value of all IC scores in the dataset may not be as innovative. Various data mining models, including Decision Tree (DT) and RF classifiers, can briefly introduce the essential features of the research proposals. The entire grant application process involves submitting a formal request for financial support or funding, which is then evaluated by reviewers based on its innovation and creativity score.",
    "Researchers often submit high-IC score research proposals, which have a broader term as 'research proposal'. Some other effective data mining models include SVM, AdaBoost, and Xgboost. DT and RF classifiers are types of machine learning algorithms used for classification tasks. Long-term data mining model is designed to extract valuable insights from large datasets over extended periods of time. IC-score proposals with high scores indicate their quality or relevance. A Random Forest classifier can be used to classify documents encoded with features denoting the presence or absence of unigrams. Various data mining models, including RF classifiers and DT and RF classifiers, are widely used for extracting valuable patterns from large datasets.",
    "The proposed data mining model, which combines Decision Tree (DT) and RF classifiers with the newly proposed modified TF-IDF algorithm, demonstrates an accuracy of 82.5% when analyzing 'Innovation and Creativity statement' sections only from Ideas Grants. This pipeline of analysing grant applications is a rigorous experimental approach that can be applied to various research proposals. The high IC-score research proposals are particularly well-suited for this method, which leverages the strengths of both DT and RF classifiers.",
    "The research community has been categorizing high, low, and moderate IC-score research proposals. A total of 400 research proposals were randomly selected for model training, with a training data set comprising 85% and a test data set making up the remaining 15%. The proposed model was trained using Decision Tree (DT) and RF classifiers to predict future grant applications. In this experiment, we tested several cut-off options such as 20, 25, 30, 35, 40, 45, and 50 for selecting research proposals with moderate IC scores. Our results show that the proposed model can accurately classify low IC-score research proposals from those with high or moderate IC scores.",
    "The proposed model, which combines and modifies the original Term Frequency (TF) method, has been used to analyze research proposals based on their innovation and creativity scores. The Random Forest classifier with the Bagging ensemble method was found to be the best performing model for analyzing grant applications, achieving an accuracy of 82.5%. This approach uses features denoted by the presence or absence of unigrams encoded using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm. The experimental pipeline involves feature extraction techniques and data mining algorithms, including Decision Trees and Random Forests. The results show that predicting high IC-score research proposals is possible with an accuracy of 84.17%. Furthermore, the study demonstrates the effectiveness of using TF-IDF as a feature extraction technique in combination with different data mining classifiers.",
    "The proposed model shows that only 618 features are considered significant, based on tens of thousands of features extracted from research proposals. This highlights the importance of innovation and creativity (IC) scores assigned by reviewers to identify high-IC score research proposals. The methodology used involves extracting specific sections from each Ideas grant application and analyzing them using a proposed pipeline. Data mining models in text classification play a crucial role, with popular algorithms like Random Forest classifier and TF-IDF algorithm being employed. In fact, the modified TF-IDF algorithm is specifically designed to encode unigram terms in research proposals. The project aims to develop a predictive model for identifying innovative grant applications based on their IC scores, which can be used to create a predictive vocabulary for contemporaneous proposals.",
    "The proposed method for analyzing grant applications involves applying data mining models, specifically a Random Forest classifier over documents encoded with features denoting the presence or absence of unigrams. This approach uses a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm to extract relevant characteristics from research proposals. The experimental results prove that this pipeline can better predict research proposals close to the original training set settings, particularly those with low IC scores. Furthermore, the proposed model demonstrates its feasibility in analyzing grant applications submitted to an Australian Government research funding agency.",
    "The proposed model can better predict research proposals with low IC scores, achieving an accuracy of up to 15%. In contrast, it performs less well on high IC-score proposals. The Random Forest classifier over documents encoded with features denoting unigram presence or absence using a modified Term Frequency - Inverse Document Frequency (TF-IDF) algorithm is another popular data mining technique used for specific classification problems. By analyzing the feature importance of these models, we can gain insights into how they perform on different types of research proposals. The experiments conducted in this study demonstrate that our proposed method outperforms other approaches when predicting low IC-score research proposals.",
    "The proposed modified TF-IDF algorithm has a broader term, which is modified TF-IDF. This novel approach combines the principles of Term Frequency-Inverse Document Frequency with modifications to improve its effectiveness in text analysis and retrieval. New research proposals with low and high IC scores are selected in each experiment, and performance analysis is conducted based on the proposed training model. The scikit-learn library was applied to implement DT and RF classifiers for categorizing data into predefined categories. Text semantics has a broader term, which is Idea, representing a research proposal with specific 'innovation and creativity' scores assigned by reviewers. Data mining models have a broader term, statistical analysis, used for extracting valuable patterns, relationships, or insights from large datasets. High IC-score research proposals were selected in each experiment to test the proposed model's performance. A classifier was applied to categorize data into predefined categories. MEL has a broader term, which is the proposed model, representing a machine learning-based framework or methodology for solving a specific problem or achieving a particular goal. It represents scientific research, which involves systematic investigation and analysis of phenomena using empirical methods and theoretical frameworks in order to expand human knowledge.",
    "This paper proposes a data mining model with a Random Forest classifier over documents encoded with features denoting the presence or absence of unigram terms, and presents an experimental pipeline for analysing grant applications. The proposed training model uses a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm to encode unigrams as features in a Random Forest classifier. The results showed that only 618 features are considered significant based on tens of thousands of features extracted from research proposals. Our proposed method cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications.",
    "The proposed model, which combines a Random Forest (RF) classifier with the Bagging ensemble method and uses unigrams encoded with a modified Term Frequency-Inverse Document Frequency (TF-IDF) algorithm, has been shown to be effective in analyzing grant applications. This approach builds upon previous research that demonstrates the importance of deleting stop words for improving data mining performance. The RF classifier is particularly well-suited for this task due to its ability to handle high-dimensional datasets and provide interpretable results through decision tree plots. Furthermore, the use of TF-IDF as a feature extraction technique allows for the capture of nuanced relationships between terms in grant proposals. In addition, the proposed method has been applied across all types of grant applications, including research funding agencies such as those submitting 2019 Ideas Grants to an Australian Government agency.",
    "The excellent research proposals have been analyzed to identify patterns and relationships. AdaBoost, a machine learning algorithm, was used to combine multiple weak learners into a strong predictive model for proposed models. Decision Trees were applied across all types of grant applications, including peer-reviewed research proposals submitted to funding agencies. The pipeline of analyzing grant applications revealed that high IC-score research proposals are predicted to be about 37.2% with moderate IC scores and about 62.8% with low IC scores. Furthermore, the TF-IDCRF algorithm was used to define a modified TF-IDF algorithm for encoding unigram terms in research proposals. The results of this study provide valuable insights into the characteristics of high-quality research proposals.",
    "The proposed method, TF-IDCRF, has been shown to improve upon traditional TF-IDF by focusing on class relationships. The performance analysis conducted based on this model revealed an accuracy of 84.17%. To find the optimal hyperparameters for the RF classifier, a pipeline was used that applied the 10-fold cross-validation method. This system uses Latent Dirichlet allocation to extract representative keywords from research proposal abstracts and predict high IC-score proposals. The best performance is achieved with this approach by accurately selecting grant applications based on their innovation and creativity scores. Future work includes exploring additional evaluation criteria, applying alternative machine learning models, and developing a long-term predictive model.",
    "Research proposals with invalid or low IC scores (below 1.0) are a common issue, and scientists and researchers always write research proposals to present their research plans and explain the significance of the project to funding agencies. To address this problem, we propose a modified TF-IDF algorithm that accurately predicts high IC-score research proposals based on unigram terms encoded by the same method. Our approach uses data mining models such as Decision Tree (DT) and RF classifiers, which are widely used in machine learning algorithms for classification tasks. The proposed model has been tested with 99 research proposals and achieved an accuracy value of [insert specific number].",
    "The process of adjusting model parameters, known as hyper-parameter tuning, plays a significant step in applying data mining models. A variant or adaptation of Term Frequency-Inverse Document Frequency (TF-IDF) method, modified TF-IDF algorithm, has been proposed for text analysis and feature extraction. This novel approach combines the principles of TF-IDF with modifications to improve its effectiveness. The top 618 significant features extracted from research proposals using a Random Forest classifier and modified TF-IDF algorithm are considered essential for predicting innovation project proposal scores. A set of machine learning algorithms, including SVM, AdaBoost, and Xgboost, can be applied in this project. Furthermore, the proposed method uses RF classifiers with Bagging ensemble method to analyze grant applications.",
    "Innovative project proposals, such as those with moderate IC scores and low IC-score research proposals, require effective methods for evaluating their innovation and creativity. Scientists and researchers always write research proposals to present their research plans and explain the significance of the project to funding agencies. The best performing model for analysing Ideas Grants can reach an accuracy of 82.5% using a Random Forest classifier based on unigram features encoded with a modified Term Frequency-Inverse Document Frequency algorithm. This approach is particularly useful when dealing with data sets, such as those containing grant applications represented as binary vectors indicating the presence or absence of specific words (unigrams). The classification accuracy can be further improved by incorporating ensemble methods and pre-trained language models into the proposed model.",
    "The proposed modified TF-IDF algorithm plays a crucial role in information retrieval, particularly when analyzing grant applications. The pipeline of analysing grant applications involves identifying high IC-score research proposals using Decision Tree (DT) and RF classifiers. To achieve this, we focus on proposing an efficient feature extraction technique rather than the choice of classifiers. Our approach combines unigram terms encoded by a modified TF-IDF algorithm with features extracted from the proposed model, which shows that only 618 features are relevant. The Multivariate Bernoulli Naive Bayes classifier is used to develop procedures and guidelines for human assessors.",
    "The proposed method, modified TF-IDF algorithm with DT and RF classifiers, has been shown to improve the performance of data mining tasks. This approach combines term frequency-inverse document frequency (TF-IDF) with various data mining classifiers to analyze grant applications and predict high IC-score research proposals. The vocabulary of innovative proposals is particularly important in understanding the significance of a project's motivation and problem statement. By applying this modified TF-IDF algorithm, we can extract features from proposed models that are relevant for predicting IC scores. Furthermore, Fani et al.'s study [23] demonstrates the effectiveness of deleting stop words to improve data mining performance.",
    "Our proposed pipeline leverages the data mining model to analyze future grant applications, which are a subset of research grant applications. The goal is to identify influential terms using DT and RF classifiers for text classification. This innovation builds upon existing ideas and information retrieval techniques like TF-IGM. A study was conducted on moderate IC-score research proposals, with experimental results showing that the model performs well in predicting low IC-score proposals. Thousands of research proposals are submitted each year, making scientific research a significant endeavor. The proposed modified TF-IDF algorithm uses evaluation metrics to assess its effectiveness. All research proposals were saved as PDF files and analyzed using data mining models, which have their own methodology. This combination of unigrams, bigrams, and trigrams provides valuable insights into grant applications.",
    "This project aims to develop a predictive vocabulary for contemporaneous grant applications and analyze how the proposed Random Forest classifier infers research proposals with high innovation and creativity (IC) scores based on their underlying data features. The TF-IDF algorithm will be used as the feature extraction technique, while text pre-processing techniques will be applied to prepare the data. The performance of data mining tasks will be evaluated using evaluation metrics such as IC score. Experimental results show that the model is more accurate in predicting low IC-score proposals than high IC-score ones. Future grant applications can benefit from this project's findings and methodology.",
    "This study proposes an efficient feature extraction technique, specifically choosing between Decision Tree (DT) and Random Forest (RF) classifiers for experimental comparison. The proposed modified TF-IDF algorithm combines the principles of Term Frequency-Inverse Document Frequency with modifications to improve its effectiveness in text analysis and retrieval. This approach is meaningful as it shows rare terms associated with innovativeness. In this study, we use a novel approach that focuses on the relationship between classes in the classification model, specifically using TF-IGM for information retrieval. The experimental results demonstrate the feasibility and effectiveness of our proposed method in predicting IC scores for research proposals.",
    "The proposed method, which combines Random Forest classifier with Bagging ensemble and Latent Dirichlet allocation, demonstrates a high accuracy of 68.33% for analyzing 'Innovation and Creativity' statements within Ideas Grant applications. This methodology section outlines the experimental pipeline used to analyze grant applications, including data mining models such as Decision Tree (DT) and TF-IDF algorithm. The study's design involves custom stop words, interval-valued intuitionistic fuzzy sets, and Bayesian Optimization tool for hyperparameter tuning. Furthermore, this paper is divided into six sections, with conclusions drawn from the experimental results showing that determining whether a scientific research project is worthy of funding requires a significant and rigorous step.",
    "The proposed method for deletion of rare terms and stop words from research grant applications has been shown to improve information retrieval. Attribute Selection Measures (ASM) were used to evaluate evaluation metrics, while experiments analysing all grant applications revealed that Unigram was the most common choice for text classification. The methodology section described a scheme using Latent Dirichlet allocation (LDA), which showed features extracted from the proposed model indicated only 618 significant features out of tens of thousands in research proposals. A RF classifier with Bagging ensemble method was used to predict IC scores, and rare terms associated with innovativeness were identified as important characteristics. The experimental results checking moderate IC-score research proposals revealed that the model is more accurate in predicting low IC-score proposals than high IC-score ones.",
    "The study presents experimental results comparing the performance of predicting low and high IC-score research proposals, specifically focusing on those with moderate IC scores. The proposed method uses a Random Forest classifier based on unigrams encoded with a modified Term Frequency-Inverse Document Frequency algorithm to achieve an accuracy of 82.5%. This approach is part of a broader scheme for text classification, which involves applying the same method but with different hyper-parameters and evaluating its performance using statistical measures such as confusion matrices. The proposed model has been applied in various funding projects aimed at supporting innovative scientific research proposals.",
    "A Random Forest (RF) classifier with the newly proposed modified TF-IDF algorithm uses unigram features to predict 'innovation and creativity' scores of research proposals. The best performance was achieved with an accuracy of 84.17% by this RF classifier, which is a systematic approach or technique for achieving a specific goal. Our proposed method cannot predict future grant applications because the current data set contains only key terms for 2019 and does not represent future grant applications. Research proposals with high IC scores use more diverse language than those with low IC-scores. The newly proposed modified TF-IDF algorithm uses hyper-parameters to classify texts, which is a popular unsupervised machine learning technique used for partitioning data into K clusters based on similarities in feature values.",
    "The proposed method, modified feature extraction algorithm, has been widely used by research funding agencies to assist in the manual review of research proposals. Data mining models have a broader term as 'method', which was applied to extract features from data and provide insight into what's going on inside the black box. The top 100 features extracted from the proposed model can be carried out from different perspectives, including exploring additional evaluation criteria or applying alternative machine learning models. Future work can also be carried out by leveraging pre-trained language models or developing a long-term predictive model. In every Ideas Grant application, there is a section called 'Innovation and Creativity statement', which has been used to describe experiments designed to test hypotheses and gather data. A predictive vocabulary for contemporaneous proposals was developed using Natural Language Processing techniques such as modified TF-IDF. Our proposed pipeline combines different funding projects and scientific research studies to achieve specific goals, including the development of a novel approach or technique.",
    "The results demonstrate the feasibility and performance of an experimental pipeline for analyzing grant applications. The size of the data set plays a crucial role according to the results. Data mining algorithms have a broader term methodology, which involves systematic approaches or procedures used in research studies. TF-IDF algorithm is a statistical method that has a broader term Natural Language Processing (NLP), a subfield of computer science dealing with human language interaction. Five data mining classifiers were compared [14], and another similar work was based on the PSI method. Grant schemes successfully identify innovative project proposals, while papers with similar topics are classified using TF-IDF vector encoding. Scientists and researchers always write research proposals to present their plans and explain the significance of projects to funding agencies. Data mining models can better understand how human evaluators assess grant applications by analyzing experimental settings. This paper proves its feasibility in evaluating grant applications. Grant applications have a broader term, which is related to research topics. Standard corpora are collections of texts used for testing NLP models, and research proposals outline plans for conducting scientific studies.",
    "The proposed method for analyzing grant applications involves using data mining techniques to transform massive amounts of unstructured data into structured information. This process includes feature extraction, where relevant characteristics are identified and extracted from the data. The importance of these features was confirmed by decision tree (DT) and random forest (RF) classifiers, which showed that less than 1000 words were considered crucial for specific classification problems. Furthermore, a comparison study revealed that different feature extraction techniques, such as Porter Stemming algorithm, can be used to achieve similar results. The proposed method also utilizes fuzzy preference relation matrices to determine the relative importance of criteria in evaluating grant applications. Additionally, evaluation metrics like IC scores are used to assess the quality and effectiveness of the pipeline for analyzing grant applications.",
    "The proposed method, which combines pre-trained language models and TF-IDF algorithm, has been shown to perform well in understanding text semantics. This approach was applied with different hyper-parameters for analyzing Ideas Grants, such as Synergy Grants, Standard Project Grants, and other types of research funding. The results demonstrate the effectiveness of this methodology in evaluating research proposals, including those with moderate IC scores. Furthermore, the project's motivation is to develop a data mining model for predicting high IC-score research proposals and understanding the vocabulary of innovative grant applications. Implementations on various hardware platforms have also been explored.",
    "Researchers have proposed various methods for evaluating and selecting attributes, such as Attribute Selection Measures (ASM). When calculating TF, a methodology called Term Frequency & Inverse Gravity Moment was used to measure the class discrimination of a term. Scientists and researchers write research proposals that are evaluated using metrics like PSI. Pre-trained language models perform well in understanding text semantics. Bayesian Optimization has been proposed for solving complex problems. The only evaluation criterion is often the sole basis for evaluating grant applications, excluding other relevant criteria. Evaluation metrics are used to assess and compare the quality or effectiveness of a system, process, or outcome. Random exploration on the parameter space is a method for exploring diverse regions within the parameter space in Bayesian Optimization. ID values represent measures of rarity or frequency in datasets. DT and RF classifiers are types of machine learning models that use decision trees and random forests to classify data. Developing cutting-edge scientific research requires funding from government agencies, which support essential and pioneering research initiatives through grant applications.",
    "Developing cutting-edge scientific research relies on government funding agencies providing financial support for essential and pioneering projects. The pursuit of innovative science involves systematic investigation, analysis, and expansion of human knowledge through various methods, including five different ensemble approaches. Standard corpora are used to test natural language processing models, while a multi-criteria approach is employed to evaluate the feasibility of proposed research methodologies. Training data sets are crucial for machine learning model development, with conclusions drawn from analyzing feature words deemed important by decision tree and random forest classifiers. Research proposals outline key characteristics, methodology, and expected outcomes, including quantitative analysis and statistical measures. In addition to grant application evaluations, experiments also analyze all proposal features. Wongso et al.'s TF-IDF and SVD algorithms were applied for text classification, while Next Word Negation (NWN) is a proposed method for negating words in natural language texts. Feasibility scores are used as evaluation criteria, with Fig. 2 illustrating the confusion matrix of a machine learning model.",
    "The Multivariate Bernoulli Naive Bayes and SVM were compared, with the former showing promising results. The proposed model achieves an accuracy of 84.17%. Meanwhile, Chen et al.'s Term Frequency & Inverse Gravity Moment was applied to text classification tasks, which involves specific classification problems. Furthermore, a simple encoding technique was used for feature extraction, while statistical measures and quantitative data were employed to evaluate the performance. Additionally, scientific research funding supported essential and cutting-edge projects each year.",
    "The proposed method, ASM, can help human evaluators by providing an effective data mining model. The experimental pipeline describes a methodology that follows innovativeness and uses modified TF-IDF to extract valuable patterns from large datasets. Data sets are classified using research paper classification system, which assigns scores based on innovation and creativity. Synergy Grants provide funding for innovative projects, but the experimental result does not support our guess about the scoring method's effectiveness. The more steps in Bayesian Optimization improve the likelihood of finding the best accuracy value. Interval-valued intuitionistic fuzzy sets are used to evaluate metrics such as term weights in documents. Words or unigrams can be encoded using a modified TF-IDF algorithm, and plots like Fig. 2 illustrate decision-making processes. MEL is a model that uses methodology to achieve desired outcomes.",
    "The proposed method, which combines bigram and trigram combinations as models for grant applications analysis, has been shown to be effective. The maximum number of features considered for splitting in a machine learning algorithm, max_features, plays an important role in this process. Additionally, the accuracy value obtained from evaluation metrics is crucial in determining the performance of the proposed method. Furthermore, scientists and researchers present their research plans based on specific classification problems, such as news classification methods. The only evaluation criterion used to assess grant applications is the evaluation criterion itself. In contrast, Support Vector Machine (SVM) uses a different approach for solving specific classification problems. Natural Language Processing techniques, including n-grams, are also employed in this process. The maximum depth of the tree, indicated by max_depth, determines the complexity of decision-making processes. Moreover, removing punctuations and tokenizing by whitespace make text into small pieces called tokens, which is an essential step in proposed method. Documents or corpus used for training machine learning models must be carefully selected to ensure that they are relevant to the research topic at hand. The best performance achieved by TF-IDCRF algorithm demonstrates its effectiveness as a methodology.",
    "The process of extracting representative keywords from abstracts of research papers involves methodology. This methodology uses Attribute Selection Measures to evaluate and select attributes or features in a dataset, which are then used as measures for scoring method. The F-score is one such measure that evaluates model performance. In determining whether a scientific research project is worthy of funding, the Preference Selection Index (PSI) method can be applied without requiring determination of weightage criteria. Implementations with hardware platforms involve adjusting term weights to increase those rare but important words and weigh down frequent words using Term Frequency & Inverse Gravity Moment. The hyper-parameters used in data mining techniques are adjusted based on Porter Stemming algorithm, which reduces vocabulary and surface syntax by applying a stemming method to get closer to the meaning of each term. Feature extraction technique involves representing texts using mathematical vectors that combine term frequencies with statistical measures. IC scores assigned by expert reviewers evaluate model performance, while Table 4 presents data or results in tabular form. Quantitative data is used to describe trends and patterns in datasets. The vocabulary of innovative proposals describes project proposals considered innovative.",
    "The proposed modified TF-IDF algorithm, which combines Term Frequency and Inverse Document Frequency with modifications to improve its effectiveness in text analysis and retrieval. This method was used on a dataset of n-grams from original data sets, where features were extracted using the TF-IDF algorithm. The performance of checking research proposals is crucial for government or funding agencies establishing different funding projects. Hyper-parameter tuning plays a key role in optimizing model parameters to achieve better results. Experiments and studies have shown that proposed methods such as LDA topic modeling can be effective tools for analyzing text data, with the maximum depth of the tree being an important consideration. The unigram terms were used to analyze linguistic patterns, while term frequency-inverse document frequency (TF-IDF) was employed to measure the importance of words in a text.",
    "In recent years, numbers present in grant applications' text that are irrelevant to future analysis have been a significant and rigorous step for funding agencies. This process involves evaluating documents as collections of written works or textual materials, which can be analyzed using data sets and statistical measures in text representation. The proposed method uses TF-IDF and LDA schemes to represent texts, while the RF classifier with the Bagging ensemble method is used for classification. Hyper-parameters such as max_samples_leaf are adjusted to optimize model performance. Furthermore, Bayesian Optimization tool [32] can be employed to maximize the optimization function. In addition, comparison studies have been conducted using 10-fold cross-validation methods and IC scores (1 - 7) were measured to evaluate the proposed method's effectiveness.",
    "The corpus of Natural Language Processing (NLP) has led to significant advancements, with pre-trained language models performing well in understanding text semantics. The F1 score serves as a crucial evaluation metric for assessing model performance. In addition, innovation should not be the only criterion evaluated, and Python-based methods have been proposed to tackle this challenge. Random Forest classifiers select the most popular category as their final result, while bigram and trigram terms are deemed non-essential features by Decision Trees and RF algorithms. The deletion of stop words is a crucial step in text preprocessing, allowing for more effective data mining techniques.",
    "Researchers have proposed various methods, such as LDA and Text stemming, to analyze data. These techniques can provide insights, trends, and patterns behind original data. A study on Ideas Grants has shown that funding projects can support innovative ideas. Statistical analysis plays a crucial role in methodology development. The experimental pipeline involves feature extraction technique design and application. Experimental results have been obtained from various data sets. Text pre-processing is essential for natural language processing. Implementations of TF-IDF algorithms, such as which only implements the IDF part, are used to analyze unigram terms. Funding projects like Ideas Grants support scientists in their research endeavors. A scientific research project involves a systematic investigation or inquiry into a particular topic.",
    "In this study, we focus on proposing an efficient feature extraction technique rather than the choice of classifiers. The reason for choosing a specific value of 1.0 was to delete stop words in text pre-processing. This approach has been used by Das and Chakraborty [9] who based their work on the Term Frequency - Inverse Document Frequency (TF-IDF) algorithm. We also consider multi-criteria approaches, such as methodology, which involves evaluating multiple criteria or factors. Our research proposal was reviewed by expert panels to ensure its significance and relevance. The vocabulary of innovative proposals is an important aspect of this study, as it helps us understand the language used in project descriptions. Furthermore, we use a moderate IC score as one of our evaluation criteria. In addition, we apply machine learning techniques such as Data mining and Random Forest classifier with max_samples_leaf parameter set to 10 or 50. The funding agencies provide financial support for scientific research projects each year, which is essential for advancing knowledge in various fields.",
    "The max_depth parameter plays a crucial role in decision-making processes, such as K-means clustering algorithm and deletion of rare terms. The Innovation and Creativity statement highlights innovative ideas and creative approaches that can be applied to various methods like TF-IDCRF and modified feature extraction algorithms. When calculating term frequency, words are treated equally important. This paper proposes a novel approach for extracting features from data using the core idea of defining the modified TF-IDF algorithm, which shows rare terms associated with innovativeness. Excellent research proposals are screened by human evaluators to ensure high-quality scientific research. The maximize method is used in cross-validation setup to optimize hyperparameters and improve model performance.",
    "The experimental results of a study after implementation some preliminary experiments reveal insights, trends, and patterns behind massive amounts of unstructured data. This section highlights the overall design of a scientific research project that employs LDA schemes as part of its methodology. The researcher's paper proposes using TF-IDF and SVD algorithms to extract features from text representation, which is then evaluated by human evaluators for future research proposals. A comparison study shows that this approach outperforms other methods in extracting insights from data sets. Furthermore, the Significance Score indicates that this project meets the evaluation criterion.",
    "The study explores various techniques for news classification, including TF-IDF and Multivariate Bernoulli Naive Bayes. The authors also discuss feature extraction methods such as n-grams and Porter Stemming algorithm. Furthermore, they introduce a fuzzy preference relation matrix to evaluate the importance of features in their project. In addition, they describe the methodology used for Bayesian Optimization, including defining the data mining model and implementing the scoring method. Finally, they highlight the significance of Natural Language Processing (NLP) as a subfield of Computer science.",
    "The importance of developing cutting-edge scientific research lies in its ability to define innovativeness. Rare terms can play a crucial role in identifying creative and novel ideas, which are essential for funding projects. The Australian Government research funding agency provides financial support for researchers through various programs, including the optimization function that requires careful consideration of parameters such as term weights and custom stop words. In addition, feature encoding algorithms and predictive vocabulary can be used to analyze data sets like Table 5 and Table 6. Furthermore, innovation should not be the only evaluation criterion when assessing grant applications. Instead, a broader approach is needed, considering factors such as experiments, size of the data set, and features. Bayesian Optimization is one method that can be applied to optimize parameters in complex spaces.",
    "The scientific research project, which employs a methodology to conduct its study, has received funding from the government. The grant application process involves evaluating experimental results and performance metrics using multi-criteria approaches. In related work, researchers have proposed TF-IDCRF as an improved algorithm for text classification. Furthermore, human evaluators respond to these necessary qualities when assessing research proposals. Meanwhile, Next Word Negation (NWN) is a linguistic technique used in natural language processing. The government receives and reviews numerous funding projects each year, including the proposal submitted by Qin, which proposed TF-IDCRF as an innovative approach.",
    "The significance of the project proposed by scientists and researchers lies in its innovative approach, which has a broader term as 'proposed method'. This method has been developed to tackle specific problems or achieve particular goals. The funding agencies that provide financial support for such projects are government research funding agencies, which have a broader term as 'funding projects'. To process the text data, we adopt various methods including Text pre-processing, ASM, and scoring method. We also consider deleting words that only exist once or twice to improve the quality of our results. In addition, Tesseract-OCR is used for extracting text from images. The more steps taken in Bayesian Optimization can lead to better accuracy values. Furthermore, we use measures such as feature importance to evaluate the performance of different methods. For instance, removing punctuations and tokenizing by whitespace are also adopted, which make the text into small pieces called tokens. Moreover, Text stemming is a technique for reducing each word to its root form. In this context, human evaluators play an essential role in assessing the quality of our results. Our news classification method has been trained on a corpus of news articles in the Indonesian Language.",
    "The TF-IDF and Multivariate Bernoulli Naive Bayes technique was used to classify news articles in the Indonesian Language corpus. The method run with parameters n_iter and init_points, which were applied by each country's government research funding agencies for their respective funding projects. Performance evaluation showed experimental results that matched numbers 1.0. Applying the same method but with different hyper-parameters also yielded similar results. Innovation and Creativity statements highlighted the importance of Section 4 in this paper. Expert reviewers assigned IC scores to evaluate the performance, while hyper-parameters were adjusted for optimal model parameters. The text pre-processing step involved converting characters into lowercase, removing numbers and punctuations, tokenizing by whitespace, deleting stop words with an IDF value less than 1.0, and applying Porter Stemming algorithm. Related work in this field included previous studies on methodology.",
    "Researchers Fan and Qin, along with other scientists, have been working on various research topics. They have also published papers as HaCohen-Kerner et al., who are a team of researchers. The number of iterations or steps in their process can be adjusted using parameters like n_iter. Their work is based on data sets from news articles in the Indonesian Language corpus, which they analyze to identify trends and patterns. Government research funding agencies receive thousands of proposals each year, reviewed by expert panels. In developing cutting-edge scientific research, maximizing the benefits and motivations mentioned above can be crucial for every country in the 21st century. Das and Chakraborty used Next Word Negation (NWN) to analyze natural language texts. The memory configuration on their MacBook Pro with Intel Core i7 2.9 GHz Quard-Core processor is set at 16GB 2133 MHz LPDDR3, which allows them to optimize their workflow using Python-based methods.",
    "The text stemming method has a broader term, which is a systematic approach or technique for achieving a specific goal. The fifth section brings this overall design of the project, which encompasses its objectives, components, and processes. This paper's experimental results are presented in this section about hardware platforms. The background provides context that motivates and provides a foundation for understanding the research project on grant applications. The researcher conducts scientific studies and investigations to determine the weight criteria when using the PSI method. Steps make it easier to find the best accuracy value, which is achieved through hyperparameter tuning in Bayesian Optimization. These words have no influence on experimental results, as they are simply a sequence of linguistic units used to measure or quantify something. The section has a broader term, which is a part or division within a document containing related information. Text sentiment classification technique uses the method for classifying the sentiment of written texts. Fig. 2 illustrates an improved TF-IDF algorithm that focuses on the relationship between classes in a classification model. Australian Government research funding agency provides financial support and grants to researchers, while government is responsible for governing a country or region. Experimental settings are introduced in this section about hardware platforms. Words have no broader term as they are individual linguistic units used to measure or quantify something.",
    "The removal or elimination of something from consideration, data, or a system can be achieved through various systematic approaches. Researchers like Oztaysi et al. have contributed to this field by developing cutting-edge scientific research methods. The importance of these methodologies lies in their ability to provide predictive results when applied correctly. In practice, the most popular category as the final result is often determined experimentally using human evaluators who assess and evaluate proposals based on specific criteria. Governments from every country require a text pre-processing step before conducting any experiments or research studies. The background and related work of this project are introduced in Section 4, which describes experimental settings used to develop new scientific methods.",
    "This paper is divided into six sections, with each section containing specific content or information. Experimental settings and configurations are described in this section, which has a broader term of 'six sections'. Researchers Fan and Qin have contributed to this work, as part of their role as researchers. Section 6 provides conclusions, summaries, or further discussion on the topic, having broader terms such as 'Section 4' and 'section'. Das and Chakraborty are also recognized for their contributions in the field of research. The concept of bigrams and trigrams is a sequence of adjacent words in a sentence, with a broader term of 'term'. Expert reviewers play an important role in evaluating proposals or applications, having a broader term of 'evaluators', which can be human evaluators. Governments at all levels, including the Australian Government, are responsible for making laws and policies that affect people's daily lives. In practice, people only pay attention to certain words when reviewing information. The country's government has a broader term of 'government' as well."
  ],
  "times": [
    722.6579079627991
  ]
}