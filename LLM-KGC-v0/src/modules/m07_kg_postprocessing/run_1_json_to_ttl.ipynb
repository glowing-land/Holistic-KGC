{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Stage 0) Metadata Knowledge Graph Construction\n",
    "Input: `LLM-KGC_input.json`\n",
    "\n",
    "Output: `LLM-KGC_input.ttl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from rdflib import Graph, Namespace, Literal, RDF, RDFS, URIRef\n",
    "from rdflib.namespace import DC, OWL, XSD, SKOS\n",
    "import time\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('kg.json', 'r') as file:\n",
    "    paper = json.load(file)\n",
    "\n",
    "start_time = time.time()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ontology Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define namespaces\n",
    "ASKG_DATA = Namespace(\"https://www.anu.edu.au/data/scholarly/\")\n",
    "ASKG_ONTO = Namespace(\"https://www.anu.edu.au/onto/scholarly#\")\n",
    "# WD = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "# DOMO = Namespace(\"https://www.anu.edu.au/onto/domo#\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "\n",
    "# Create a new RDF graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind namespaces to prefixes\n",
    "g.bind(\"askg-data\", ASKG_DATA)\n",
    "g.bind(\"askg-onto\", ASKG_ONTO)\n",
    "g.bind(\"dc\", DC)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdf\", RDF)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "# g.bind(\"wd\", WD) # wd:entity\n",
    "# g.bind(\"domo\", DOMO) # domo:keyword\n",
    "g.bind(\"skos\", SKOS) # skos:broader\n",
    "g.bind(\"xsd\", XSD) # ^^xsd:string\n",
    "g.bind(\"schema\", SCHEMA) # schema:text\n",
    "\n",
    "# # Define RDF classes\n",
    "# g.add((ASKG_ONTO.Paper, RDF.type, OWL.Class))\n",
    "# g.add((ASKG_ONTO.Section, RDF.type, OWL.Class))\n",
    "# g.add((ASKG_ONTO.Paragraph, RDF.type, OWL.Class))\n",
    "# g.add((ASKG_ONTO.Sentence, RDF.type, OWL.Class))\n",
    "\n",
    "\n",
    "# # Define RDF properties\n",
    "# g.add((ASKG_ONTO.hasAuthor, RDF.type, RDF.Property))\n",
    "# g.add((ASKG_ONTO.hasKeyword, RDF.type, RDF.Property))\n",
    "# g.add((ASKG_ONTO.hasSection, RDF.type, RDF.Property))\n",
    "# g.add((ASKG_ONTO.hasParagraph, RDF.type, RDF.Property))\n",
    "# g.add((ASKG_ONTO.hasSentence, RDF.type, RDF.Property))\n",
    "# g.add((ASKG_ONTO.hasText, RDF.type, RDF.Property))\n",
    "\n",
    "# g.add((SCHEMA.text, RDF.type, RDF.Property))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From JSON to RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.2165839672088623 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paper\n",
    "paper_iri = ASKG_DATA[paper[\"iri\"]]\n",
    "# paper_iri = ASKG_DATA[\"Paper-1\"]\n",
    "\n",
    "\n",
    "def get_iri(local_iri):\n",
    "    global paper_iri\n",
    "    return paper_iri + \"-\" + local_iri\n",
    "\n",
    "\n",
    "\n",
    "g.add((paper_iri, RDF.type, ASKG_ONTO.Paper))\n",
    "g.add((paper_iri, DC.title, Literal(paper[\"title\"], lang=\"en\")))\n",
    "\n",
    "for author in paper[\"authors\"]:\n",
    "    g.add((paper_iri, ASKG_ONTO.hasAuthor, Literal(author, lang=\"en\")))\n",
    "for keyword in paper[\"keywords\"]:\n",
    "    g.add((paper_iri, ASKG_ONTO.hasKeyword, Literal(keyword, lang=\"en\")))\n",
    "\n",
    "for section in paper[\"sections\"]:\n",
    "    section_iri = get_iri(section[\"iri\"])\n",
    "    g.add((section_iri, RDF.type, ASKG_ONTO.Section))\n",
    "    g.add((section_iri, DC.title, Literal(section[\"subtitle\"], lang=\"en\"))) \n",
    "\n",
    "    for paragraph in section[\"paragraphs\"]:\n",
    "        paragraph_iri = get_iri(paragraph[\"iri\"])\n",
    "        g.add((paragraph_iri, RDF.type, ASKG_ONTO.Paragraph))\n",
    "\n",
    "        for sentence in paragraph[\"sentences\"]:\n",
    "            sentence_iri = get_iri(sentence[\"iri\"])\n",
    "            g.add((sentence_iri, RDF.type, ASKG_ONTO.Sentence))\n",
    "            g.add((sentence_iri, ASKG_ONTO.hasText, Literal(sentence[\"text\"], lang=\"en\")))\n",
    "\n",
    "            g.add((paragraph_iri, ASKG_ONTO.hasSentence, sentence_iri))\n",
    "\n",
    "        g.add((section_iri, ASKG_ONTO.hasParagraph, paragraph_iri))\n",
    "    \n",
    "    g.add((paper_iri, ASKG_ONTO.hasSection, section_iri))\n",
    "\n",
    "\n",
    "g.add((ASKG_ONTO.NamedEntity, RDFS.subClassOf, ASKG_ONTO.Entity))\n",
    "g.add((ASKG_ONTO.GeneralTerm, RDFS.subClassOf, ASKG_ONTO.Entity))\n",
    "g.add((ASKG_ONTO.OtherEntity, RDFS.subClassOf, ASKG_ONTO.Entity))\n",
    "\n",
    "\n",
    "\n",
    "# Entities\n",
    "for entity_iri, entity in paper[\"nodes\"].items():\n",
    "    entity_iri = get_iri(entity_iri)\n",
    "    \n",
    "    g.add((entity_iri, RDFS.label, Literal(entity[\"label\"], lang=\"en\")))\n",
    "\n",
    "    for types in entity[\"types\"]:\n",
    "        g.add((entity_iri, ASKG_ONTO.hasTypeLabel, Literal(types, lang=\"en\")))\n",
    "    for alias in entity[\"aliases\"]:\n",
    "        g.add((entity_iri, SKOS.altLabel, Literal(alias, lang=\"en\")))\n",
    "\n",
    "    g.add((entity_iri, SCHEMA.description, Literal(entity[\"description\"], lang=\"en\")))\n",
    "\n",
    "    if entity[\"node_type\"] == \"named entity\":\n",
    "        g.add((entity_iri, RDF.type, ASKG_ONTO.NamedEntity))\n",
    "    elif entity[\"node_type\"] == \"general term\":\n",
    "        g.add((entity_iri, RDF.type, ASKG_ONTO.GeneralTerm))\n",
    "    elif entity[\"node_type\"] == \"other\":\n",
    "        g.add((entity_iri, RDF.type, ASKG_ONTO.OtherEntity))\n",
    "    else:\n",
    "        raise ValueError(\"Unknown entity type\")\n",
    "    \n",
    "    g.add((entity_iri, ASKG_ONTO.hasRelevanceScore, Literal(entity[\"relevance\"], datatype=XSD.float)))\n",
    "\n",
    "    for mention in entity[\"mentions\"]:\n",
    "        mention_iri = get_iri(mention[\"iri\"])\n",
    "        g.add((mention_iri, RDF.type, ASKG_ONTO.Mention))\n",
    "        g.add((mention_iri, RDFS.label, Literal(mention[\"local_name\"], lang=\"en\")))\n",
    "        sentence_mentioned_in = paper_iri + \"-\" + mention[\"reference\"]\n",
    "        g.add((mention_iri, ASKG_ONTO.mentionedIn, sentence_mentioned_in))\n",
    "        g.add((entity_iri, ASKG_ONTO.hasMention, mention_iri))\n",
    "\n",
    "\n",
    "\n",
    "# Predicates\n",
    "for predicate_iri, predicate in paper[\"predicates\"].items():\n",
    "    predicate_iri = get_iri(predicate_iri)\n",
    "    g.add((predicate_iri, RDF.type, ASKG_ONTO.Predicate))\n",
    "    g.add((predicate_iri, RDFS.label, Literal(predicate[\"label\"], lang=\"en\")))\n",
    "    g.add((predicate_iri, SCHEMA.description, Literal(predicate[\"description\"], lang=\"en\")))\n",
    "\n",
    "\n",
    "# Relations\n",
    "\n",
    "for triple in paper[\"triples\"]:\n",
    "    subject_iri = paper_iri + \"-\" + triple[0]\n",
    "    predicate_iri = paper_iri + \"-\" + triple[1]\n",
    "    object_iri = paper_iri + \"-\" + triple[2]\n",
    "\n",
    "    g.add((subject_iri, predicate_iri, object_iri))\n",
    "\n",
    "\n",
    "for triple in paper[\"triples_typing\"]:\n",
    "    subject_iri = paper_iri + \"-\" + triple[0]\n",
    "    predicate_iri = SKOS.broader\n",
    "    object_iri = paper_iri + \"-\" + triple[2]\n",
    "\n",
    "    g.add((subject_iri, predicate_iri, object_iri))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "with open('kg.ttl', 'wb') as f:\n",
    "    f.write(g.serialize(format='turtle').encode(\"utf-8\"))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDF Output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
